<xml><doc id="854" url="http://it.wikipedia.org/wiki/?curid=854" title="Anatolia">
Anatolia

Anatolia (from Greek , ' — "east" or "(sun)rise"), also known as Asia Minor (from ' "small Asia"; in modern ), Asian Turkey, Anatolian peninsula, Anatolian plateau, and Turkey, denotes the westernmost protrusion of Asia, comprising the majority of the Republic of Turkey. The region is bounded by the Black Sea to the north, the Mediterranean Sea to the south and the Aegean Sea to the west. The Sea of Marmara forms a connection between the Black and Aegean Seas through the Bosphorus and Dardanelles straits, and separates Anatolia from Thrace on the European mainland. Traditionally, Anatolia is considered to extend in the east to a line between the Gulf of İskenderun and the Black Sea, approximately corresponding to the western two-thirds of the Asian part of Turkey. However, since Anatolia is now often considered to be synonymous with Asian Turkey, its eastern and southeastern borders are widely taken to be the Turkish borders with the neighboring countries, which are Georgia, Armenia, Iran, Iraq and Syria, in clockwise direction.
Anatolia has been inhabited by many peoples throughout history, such as the Hattians, Hurrians, Hittites, Luwians, Phrygians, Lydians, Persians, Greeks, Assyrians, Mitanni, Scythians, Cimmerians, Urartians, Carians, Commagene, Cilicians, Arameans, Kaskians, Mushki, Palaic, Corduene, Armenians, Romans, Colchians, Iberians, Georgians, Kurds, Seljuk Turks, and Ottomans. Each culture left behind unique artifacts, still being uncovered by archaeologists.
Definition.
The Anatolian peninsula, also called Asia Minor, is bounded by the Black Sea to the north, the Mediterranean Sea to the south, the Aegean Sea to the west, and the Sea of Marmara to the northwest, which separates Anatolia from Thrace in Europe.
Traditionally, Anatolia is considered to extend in the east to an indefinite line running from the Gulf of İskenderun to the Black Sea, coterminous with the Anatolian Plateau. This traditional geographical definition is used, for example, in the latest edition of "Merriam-Webster's Geographical Dictionary", as well as the archeological community. To the southeast, it is bounded by the ranges that separate it from the Orontes valley in Greater Syria and the Mesopotamian plain. the former largely corresponding to the western part of the Armenian Highland, the latter to the northern part of the Mesopotamian plain. This wider definition of Anatolia has gained widespread currency outside of Turkey and has, for instance, been adopted by "Encyclopædia Britannica" and other encyclopedic and general reference publications.
History.
Anatolia has had many civilizations throughout history, such as the Hattians, Hurrians, Luwians, Hittites, Phrygians, Lydians, Persians, Greeks, Assyrians, Urartians, Cimmerians, Carians, Scythians, Corduene, Armenians, Romans, Georgians, Circassians, Kurds, Seljuk Turks and Ottomans. As a result, Anatolia is one of the archaeologically richest places on earth. Two of the Seven Wonders of the Ancient World were located in Anatolia: The Temple of Artemis in Ephesus and the Mausoleum at Halicarnassus.
Etymology.
The oldest known reference to Anatolia, "Land of the Hatti", was found for the first time on Mesopotamian cuneiform tablets from the period of the Akkadian Empire (2350–2150 BC). On those tablets the northern Akkadian Assyrian traders implored the help of the Akkadian king Sargon the Great. This appellation continued to exist for about 1500 years until approximately 620 BC, as stated in the chronicles of the Assyrian Empire.
Later, the Anatolian peninsula was given the name "Asia" (Ἀσία) by the Greeks, presumably after the name of the Assuwa league in western Anatolia. As the name Asia came to be extended to other areas east of the Mediterranean, the name for Anatolian became specified as Asia Minor ("Lesser Asia", Μικρὰ Ἀσία) in Late Antiquity.
The name "Anatolia" comes from the Greek ("") meaning the "East" or more literally "sunrise", comparable to the Latin terms "Levant" or "Orient" (and words for "east" in other languages). The precise reference of this term has varied over time, perhaps originally referring to the Ionian colonies on the west coast of Asia Minor.
In the Byzantine Empire, the Anatolic Theme (Aνατολικόν θέμα) was a "theme" covering the western and central parts of Turkey's present-day Central Anatolia Region.
The English-language name "Turkey" first appeared c. 1369. It is derived from the Medieval Latin "Turchia" (meaning "Land of the Turks", Turkish: "Türkiye"), which was originally used by the Europeans to define the Seljuk-controlled parts of Anatolia after the Battle of Manzikert in 1071; increasingly in common use starting with the Crusades. The Greek cognate of this name, "Tourkia" () was originally used by the Byzantines to define medieval Hungary (since pre-Magyar Hungary was occupied by proto-Turkic and Turkic tribes, such as the Huns, Avars, Bulgars, Kabars, Pechenegs and Cumans.) Similarly, the medieval Khazar Empire, a Turkic state on the northern shores of the Black and Caspian seas, was referred to as "Tourkia" ("Land of the Turks") in Byzantine sources. However, the Byzantines later began using this name to define the Seljuk-controlled parts of Anatolia in the centuries that followed the Battle of Manzikert in 1071.
The modern Turkish name of Anatolia is "Anadolu", which derives from the Greek name "Aνατολή" ("Anatolē").
Antiquity.
Neolithic Anatolia has been proposed as the homeland of the Indo-European language family, although linguists tend to favour a later origin in the steppes north of the Black Sea. However, it is clear that the Indo-European Anatolian languages had been present in Anatolia since at least the 19th century BC.
Eastern Anatolia contains the oldest monumental structures in the world. For example, the monumental structures at Göbekli Tepe were built by hunters and gatherers a thousand years before the development of agriculture. Eastern Anatolia, alongside Mesopotamia and the Levant, is also a heart region for the Neolithic Revolution, one of the earliest areas in which humans domesticated plants and animals. Neolithic sites such as Çatalhöyük, Çayönü, Nevalı Çori and Hacilar represent the world's oldest known agricultural towns.
The earliest historical records of Anatolia stem from the south east of the region, and are from the Mesopotamia- based Akkadian Empire during the reign of Sargon of Akkad in the 24th century BC. Scholars generally believe the earliest indigenous populations of Anatolia were the Hattians and Hurrians. The Hattians spoke a language of unclear affiliation, and the Hurrian language belongs to a small family called Hurro-Urartian, all these languages now being extinct; relationships with indigenous languages of the Caucasus have been proposed, but are not generally accepted. The region was famous for exporting various raw materials, and areas of Hattian and Hurrian-populated south east Anatolia were colonised by the Akkadians.
Unlike the Semitic Akkadians and their descendants, the Assyrians, whose Anatolian possessions were peripheral to their core lands in Mesopotamia, the Hittites were centred at Hattusa in north-central Anatolia by 2000 BC. They were speakers of an Indo-European language known as the "language of Nesa". Originating from Nesa, they conquered Hattusa in the 18th century BC, imposing themselves over Hattian and Hurrian- speaking populations. 
The Hittites adopted the cuneiform written script, invented in Mesopotamia. During the Late Bronze Age circa 2000 BC, they created an empire, the Hittite New Kingdom, which reached its height in the 14th century BC, controlling much of Asia Minor. The empire included a large part of Anatolia, north-western Syria and north west upper Mesopotamia. They failed to reach the Anatolian coasts of the Black Sea however, as another non-Indo-European people, the Kaskians, had established a kingdom there in the 17th century BC, displacing earlier Palaic speaking Indo-Europeans.
Much of the history of the Hittite Empire was concerned with warring with the rival empires of Egypt, Assyria and the Mitanni.
The Mitanni Empire was also an Indo-European (and Hurrian)-speaking and Anatolian based empire. The Mitanni appeared in the 17th century BC and spoke an Indo-Aryan language related to the Indo-European languages eventually to be found in India.
The Egyptians eventually withdrew from the region after failing to gain the upper hand over the Hittites, and becoming wary of the power of Assyria, which had destroyed the Mitanni Empire.
After 1180 BC, the Hittite empire disintegrated into several independent "Neo-Hittite" states, subsequent to losing much territory to the Middle Assyrian Empire and being finally overrun by the Phrygians, another Indo-European people who are believed to have migrated from the Balkans. The Phrygian expansion into southeast Anatolia was eventually halted by the Assyrians, who controlled that region. The general consensus amongst scholars is that Luwian was spoken—to a greater or lesser degree—across a large area of western Anatolia, including (possibly) Wilusa (= Troy), the Seha River Land (to be identified with the Hermos and/or Kaikos valley), and the kingdom of Mira-Kuwaliya with its core territory of the Maeander valley. From the 9th century BC, Luwian regions coalesced into a number of states such as Lydia, Caria and Lycia, all of which had Hellenic influence.
The north western coasts of Anatolia were inhabited by Greeks of the Achaean/Mycenaean culture from the 20th century BC, related to the Greeks of south eastern Europe and the Aegean.
Beginning with the Bronze Age collapse at the end of the 2nd millennium BC, the west coast of Anatolia was settled by Ionian Greeks, usurping the related but earlier Mycenaean Greeks. Over several centuries, numerous Ancient Greek city-states were established on the coasts of Anatolia. Greeks started Western philosophy on the western coast of Anatolia (Pre-Socratic philosophy).
Later during the 6th century BC, most of Anatolia was conquered by the Persian Achaemenid Empire, the Persians having usurped the Medes as the dominant dynasty in Iran. Also, in the 6th century BC, the Indo-European Armenians founded the Orontid Dynasty in Urartu. In 499 BC, the Ionian city-states on the west coast of Anatolia rebelled against Persian rule. The Ionian Revolt, as it became known, initiated the Greco-Persian Wars, which ended in a Greek victory in 449 BC, and the Ionian cities regained their independence. 
In 334 BC, the Macedonian Greek king Alexander the Great conquered the peninsula. Alexander's conquest opened up the interior of Asia Minor to Greek settlement and influence. Following the death of Alexander and the breakup of his empire, Anatolia was ruled by a series of Hellenistic kingdoms, such as the Attalids of Pergamum and the Seleucids, the latter controlling most of Anatolia. A period of peaceful Hellenization followed, such that the local Anatolian languages had been supplanted by Greek by the 1st century BC. In 133 BC the last Attalid King bequeathed his kingdom to the Roman Republic, and western and central Anatolia came under Roman control, but Hellenistic culture remained predominant. During the 1st century BC the Armenians established the powerful Armenian kingdom under Tigran who reigned throughout much of eastern Anatolia between the Caspian, Black Sea and Mediterranean. Areas of the south east such as Harran and the Hakkari mountains continued to be inhabited by remnants of the Assyrians, but these regions remained under Parthian and then Sassanid Persian rule.
Medieval and Renaissance periods.
After the division of the Roman Empire, Anatolia became part of the East Roman, or Byzantine Empire. Anatolia was one of the first places where Christianity spread, so that by the 4th century AD, western and central Anatolia were overwhelmingly Christian and Greek-speaking. For the next 600 years, while Imperial possessions in Europe were subjected to barbarian invasions, Anatolia would be the center of the Hellenic world. Byzantine control was challenged by Arab raids starting in the 8th century (see Byzantine–Arab Wars), but in the 9th and 10th century a resurgent Byzantine Empire regained its lost territories and even expanded beyond its traditional borders, into Armenia and Syria (ancient Aram). In the 10 years following the Battle of Manzikert in 1071, the Seljuk Turks from Central Asia established themselves over large areas of Anatolia, with particular concentrations around the north western rim. The Turkish language and the Islamic religion were gradually introduced as a result of the Seljuk conquest, and this period marks the start of Anatolia's slow transition from predominantly Christian and Greek-speaking, to predominantly Muslim and Turkish-speaking (although some ethnic groups such as Armenians, Greeks, Assyrians remained numerous and retained Christianity and their native languages). In the following century, the Byzantines managed to reassert their control in western and northern Anatolia. Control of Anatolia was then split between the Byzantine Empire and the Seljuk Sultanate of Rûm, with the Byzantine holdings gradually being reduced. In 1255, the Mongols swept through eastern and central Anatolia, and would remain until 1335. The Ilkhanate garrison was stationed near Ankara.
By the end of the 14th century, most of Anatolia was controlled by various Anatolian beyliks. Smyrna fell in 1330, and the last Byzantine stronghold in Anatolia, Philadelphia, fell in 1390. The Turkmen Beyliks were under the control of the Mongols, at least nominally, through declining Seljuk Sultans. The Beyliks did not mint coins in the names of their own leaders while they remained under the suzerainty of the Mongol Ilkhanids. The Osmanli ruler Osman I was the first Turkish ruler who minted coins in his own name in 1320s, for it bears the legend "Minted by Osman son of Ertugul". Since the minting of coins was a prerogative accorded in Islamic practice only to a sovereign, it can be considered that Osmanli became independent of the Mongol Khans.
After the decline of the Ilkhanate from 1335–1353, the Mongol Empire's legacy in the region was the Uyghur Eretna Dynasty that was overthrown by Kadi Burhan al-Din in 1381. Among the Turkmen leaders the Ottomans emerged as great power under Osman and his son Orhan I. The Anatolian beyliks were in turn absorbed into the rising Ottoman Empire during the 15th century. The Ottomans completed the conquest of the peninsula in 1517 with the taking of Halicarnassus (modern Bodrum) from the Knights of Saint John.
Modern times.
With the beginning of the slow decline of the Ottoman Empire in the early 19th century, and as a result of the expansionist policies of Czarist Russia in the Caucasus, many Muslim nations and groups in that region, mainly Circassians, Tatars, Azeris, Lezgis, Chechens and several Turkic groups left their ancestral homelands and settled in Anatolia. As the Ottoman Empire further shrank in the Balkan regions and then fragmented during the Balkan Wars, much of the non-Christian populations of its former possessions, mainly Balkan Muslims (Bosnians, Muslim Albanians, Turks, and Greek Muslims such as the Valahadhes from Greek Macedonia, Bulgaria, Northern Macedonia), were resettled in various parts of Anatolia, mostly in formerly Christian villages throughout Anatolia. 
A continuous reverse migration occurred since the early 19th century, when Greeks from Anatolia, Constantinopole and Pontus area migrated toward the newly independent Kingdom of Greece, and also towards the United States, southern part of the Russian Empire, Latin America and rest of Europe. Following the Treaty of Turkmenchay (1828) and the incorporation of the Eastern Armenia into the Russian Empire, another reverse migration involved the large Armenian population of Anatolia, which recorded significant migration rates from Western Armenia (Eastern Anatolia) toward the Russian Empire, especially toward the newly established Armenian provinces of the empire.
Anatolia remained multi-ethnic until the early 20th century (see the rise of nationalism under the Ottoman Empire). During World War I, the Armenian Genocide, the Greek genocide (especially in Pontus), and the Assyrian Genocide almost entirely removed the ancient indigenous communities of Armenian and Assyrian populations in Anatolia, as well as a large part of its ethnic Greek population. Following the Greco-Turkish War of 1919-1922, all remaining ethnic Anatolian Greeks were forced out during the 1923 population exchange between Greece and Turkey. Since the foundation of the Republic of Turkey in 1923, Anatolia has become Turkey, its inhabitants being mainly Turks and Kurds (see demographics of Turkey and history of Turkey).
Geography.
Geology.
Anatolia's terrain is structurally complex. A central massif composed of uplifted blocks and downfolded troughs, covered by recent deposits and giving the appearance of a plateau with rough terrain, is wedged between two folded mountain ranges that converge in the east. True lowland is confined to a few narrow coastal strips along the Aegean, Mediterranean, and Black Sea coasts. Flat or gently sloping land is rare and largely confined to the deltas of the Kızıl River, the coastal plains of Çukurova and the valley floors of the Gediz River and the Büyük Menderes River as well as some interior high plains in Anatolia, mainly around Lake Tuz (Salt Lake) and the Konya Basin ("Konya Ovasi").
Climate.
Anatolia has a varied range of climates. The central plateau is characterized by a continental climate, with hot summers and cold snowy winters. The south and west coasts enjoy a typical Mediterranean climate, with mild rainy winters, and warm dry summers. The Black Sea and Marmara coasts have temperate oceanic climate, with cool foggy summers and much rainfall throughout the year.
Ecoregions.
There is a diverse number of plant and animal communities.
The mountains and coastal plain of northern Anatolia experiences humid and mild climate. There are temperate broadleaf, mixed and coniferous forests. The central and eastern plateau, with its drier continental climate, has deciduous forests and forest steppes. Western and southern Anatolia, which have a Mediterranean climate, contaions Mediterranean forests, woodlands, and scrub ecoregions.
Demographics.
Almost 80% of the people currently residing in Anatolia are Turks. Kurds constitute a major community in southeastern Anatolia, and are the largest ethnic minority. Abkhazians, Albanians, Arabs, Arameans, Armenians, Assyrians, Bosniaks, Circassians, Gagauz, Georgians, Greeks, Hemshin, Jews, Laz, Levantines, Pomaks, Zazas and a number of other ethnic groups also live in Anatolia in smaller numbers.
References.
I

</doc>
<doc id="856" url="http://it.wikipedia.org/wiki/?curid=856" title="Apple Inc.">
Apple Inc.

Apple Inc., formerly Apple Computer, Inc., is an American multinational corporation headquartered in Cupertino, California that designs, develops, and sells consumer electronics, computer software and personal computers. Its best-known hardware products are the Mac line of computers, the iPod music player, the iPhone smartphone, and the iPad tablet computer. Its software includes the OS X and iOS operating systems, the iTunes media browser, the Safari web browser, and the iLife and iWork creativity and production suites. The company was founded on April 1, 1976, and incorporated as Apple Computer, Inc. on January 3, 1977. 
Apple is the world's second-largest information technology company by revenue after Samsung Electronics, and the world's third-largest mobile phone maker after Samsung and Nokia. "Fortune" magazine named Apple the most admired company in the United States in 2008, and in the world from 2008 to 2012. However, the company has received criticism for its contractors' labor practices, and for Apple's own environmental and business practices.
, Apple maintains 394 retail stores in fourteen countries as well as the online Apple Store and iTunes Store. It is the second-largest publicly traded corporation in the world by market capitalization, with an estimated value of US$414 billion as of January 2013. , the company had 72,800 permanent full-time employees and 3,300 temporary full-time employees worldwide. to sell the Apple I personal computer kit. The kits were hand-built by Wozniak and first shown to the public at the Homebrew Computer Club. The Apple I was sold as a motherboard (with CPU, RAM, and basic textual-video chips), which is less than what is today considered a complete personal computer. The Apple I went on sale in July 1976 and was market-priced at $666.66 ($ in dollars, adjusted for inflation.)
Apple was incorporated January 3, 1977, without Wayne, who sold his share of the company back to Jobs and Wozniak for $800. Multi-millionaire Mike Markkula provided essential business expertise and funding of $250,000 during the incorporation of Apple.
The Apple II was introduced on April 16, 1977, at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, due to its character cell-based color graphics and an open architecture. While early models used ordinary cassette tapes as storage devices, they were superseded by the introduction of a 5 1/4 inch floppy disk drive and interface, the Disk II.
The Apple II was chosen to be the desktop platform for the first "killer app" of the business world, VisiCalc, a spreadsheet program. VisiCalc created a business market for the Apple II and gave home users compatibility with the office, an additional reason to buy an Apple II.
By the end of the 1970s, Apple had a staff of computer designers and a production line. The company introduced the ill-fated Apple III in May 1980 in an attempt to compete with IBM and Microsoft in the business and corporate computing market.
Jobs and several Apple employees, including Jef Raskin, visited Xerox PARC in December 1979 to see the Xerox Alto. Xerox granted Apple engineers three days of access to the PARC facilities in return for the option to buy 100,000 shares (800,000 split-adjusted shares) of Apple at the pre-IPO price of $10 a share. Jobs was immediately convinced that all future computers would use a graphical user interface (GUI), and development of a GUI began for the Apple Lisa.
On December 12, 1980, Apple went public at $22 per share, generating more capital than any IPO since Ford Motor Company in 1956 and instantly creating more millionaires (about 300) than any company in history.
1981–85: Lisa and Macintosh.
Steve Jobs began working on the Apple Lisa in 1978, but in 1982, he was pushed from the Lisa team due to infighting. Jobs took over Jef Raskin's low-cost-computer project, the Macintosh. A race broke out between the Lisa team and the Macintosh team over which product would ship first. Lisa won the race in 1983 and became the first personal computer sold to the public with a GUI, but was a commercial failure due to its high price tag and limited software titles.
In 1984, Apple next launched the Macintosh. Its debut was announced by the now famous $1.5 million television commercial "1984". It was directed by Ridley Scott and was aired during the third quarter of Super Bowl XVIII on January 22, 1984. It is now hailed as a watershed event for Apple's success and a "masterpiece".
The Macintosh initially sold well, but follow-up sales were not strong due to its high price and limited range of software titles. The machine's fortunes changed with the introduction of the LaserWriter, the first PostScript laser printer to be offered at a reasonable price, and PageMaker, an early desktop publishing package. It has been suggested that the combination of these three products was responsible for the creation of the desktop publishing market. The Mac was particularly powerful in the desktop publishing market due to its advanced graphics capabilities, which had necessarily been built in to create the intuitive Macintosh GUI.
In 1985 a power struggle developed between Jobs and CEO John Sculley, who had been hired two years earlier. The Apple board of directors instructed Sculley to "contain" Jobs and limit his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from his leadership role at Apple. Sculley found out that Jobs had been attempting to organize a putsch and called a board meeting at which Apple's board of directors sided with Sculley and removed Jobs from his managerial duties.
1986–97: Decline.
The Macintosh Portable was introduced in 1989 and was designed to be just as powerful as a desktop Macintosh, but weighed a bulky with a 12-hour battery life. After the Macintosh Portable, Apple introduced the PowerBook in 1991. The same year, Apple introduced System 7, a major upgrade to the operating system which added color to the interface and introduced new networking capabilities. It remained the architectural basis for Mac OS until 2001.
The success of the PowerBook and other products brought increasing revenue.
During this time Apple experimented with a number of other failed consumer targeted products including digital cameras, portable CD audio players, speakers, video consoles, and TV appliances. Enormous resources were also invested in the problem-plagued Newton division based on John Sculley's unrealistic market forecasts. Ultimately, none of these products helped, as Apple's market share and stock prices continued to slide.
Apple saw the Apple II series as too expensive to produce, while taking away sales from the low end Macintosh. In 1990, Apple released the Macintosh LC with a single expansion slot for the Apple IIe Card to migrate Apple II users to the Macintosh platform. Apple relied on high profit margins and never developed a clear response. Instead, they sued Microsoft for using a graphical user interface similar to the Apple Lisa in Apple Computer, Inc. v. Microsoft Corporation. The lawsuit dragged on for years before it was finally dismissed. At the same time, a series of major product flops and missed deadlines sullied Apple's reputation, and Sculley was replaced as CEO by Michael Spindler.
By the early 1990s, Apple was developing alternative platforms to the Macintosh, such as the A/UX. Apple had also begun to experiment in providing a Mac-only online portal which they called eWorld, developed in collaboration with America Online and designed as a Mac-friendly alternative to other online services such as CompuServe. The Macintosh platform was itself becoming outdated because it was not built for multitasking, and several important software routines were programmed directly into the hardware. In addition, Apple was facing competition from OS/2 and UNIX vendors such as Sun Microsystems. The Macintosh would need to be replaced by a new platform, or reworked to run on more powerful hardware.
In 1994, Apple allied with IBM and Motorola in the AIM alliance. The goal was to create a new computing platform (the PowerPC Reference Platform), which would use IBM and Motorola hardware coupled with Apple's software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind, thus countering Microsoft. The same year, Apple introduced the Power Macintosh, the first of many Apple computers to use Motorola's PowerPC processor.
In 1996, Michael Spindler was replaced by Gil Amelio as CEO. Gil Amelio made many changes at Apple, including extensive layoffs. After numerous failed attempts to improve Mac OS, first with the Taligent project, then later with Copland and Gershwin, Amelio chose to purchase NeXT and its NeXTSTEP operating system, bringing Steve Jobs back to Apple as an advisor. On July 9, 1997, Gil Amelio was ousted by the board of directors after overseeing a three-year record-low stock price and crippling financial losses. Jobs became the interim CEO and began restructuring the company's product line.
At the 1997 Macworld Expo, Steve Jobs announced that Apple would join Microsoft to release new versions of Microsoft Office for the Macintosh, and that Microsoft made a $150 million investment in non-voting Apple stock.
On November 10, 1997, Apple introduced the Apple Online Store, tied to a new build-to-order manufacturing strategy.
1998–2005: Return to profitability.
On August 15, 1998, Apple introduced a new all-in-one computer reminiscent of the Macintosh 128K: the iMac. The iMac design team was led by Jonathan Ive, who would later design the iPod and the iPhone. The iMac featured modern technology and a unique design, and sold almost 800,000 units in its first five months.
Through this period, Apple purchased several companies to create a portfolio of professional and consumer-oriented digital production software. In 1998, Apple announced the purchase of Macromedia's Final Cut software, signaling its expansion into the digital video editing market. The following year, Apple released two video editing products: iMovie for consumers and, for professionals, Final Cut Pro, which has gone on to be a significant video-editing program, with 800,000 registered users in early 2007. In 2002, Apple purchased Nothing Real for their advanced digital compositing application Shake, as well as Emagic for their music productivity application Logic, which led to the development of their consumer-level GarageBand application. iPhoto's release the same year completed the iLife suite.
Mac OS X, based on NeXT's OPENSTEP and BSD Unix was released on March 24, 2001, after several years of development. Aimed at consumers and professionals alike, Mac OS X aimed to combine the stability, reliability and security of Unix with the ease of use afforded by an overhauled user interface. To aid users in migrating from Mac OS 9, the new operating system allowed the use of OS 9 applications through Mac OS X's Classic environment.
On May 19, 2001, Apple opened the first official Apple Retail Stores in Virginia and California. On July 9, they bought Spruce Technologies, a DVD authoring company. On October 23 of the same year, Apple announced the iPod portable digital audio player, and started selling it on November 10. The product was phenomenally successful — over 100 million units were sold within six years. In 2003, Apple's iTunes Store was introduced, offering online music downloads for $0.99 a song and integration with the iPod. The service quickly became the market leader in online music services, with over 5 billion downloads by June 19, 2008.
Since 2001, Apple's design team has progressively abandoned the use of translucent colored plastics first used in the iMac G3. This began with the titanium PowerBook and was followed by the white polycarbonate iBook and the flat-panel iMac.
2005–07: Transition to Intel.
At the Worldwide Developers Conference keynote address on June 6, 2005, Steve Jobs announced that Apple would begin producing Intel-based Mac computers in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006 Apple had transitioned the entire Mac product line to Intel chips, over one year sooner than announced. On April 29, 2009, "The Wall Street Journal" reported that Apple was building its own team of engineers to design microchips.
Apple also introduced Boot Camp to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.
Apple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. In January 2006, Apple's market cap surpassed that of Dell. Nine years prior, Dell's CEO Michael Dell said that if he ran Apple he would "shut it down and give the money back to the shareholders." Although Apple's market share in computers had grown, it remained far behind competitors using Microsoft Windows, with only about 8% of desktops and laptops in the US.
2007–11: Widespread success.
Apple achieved widespread success with its iPhone, iPod Touch and iPad products, which introduced innovations in mobile phones, portable music players and personal computers respectively. In addition, the implementation of a store for the purchase of software applications represented a new business model. Touch screens had been invented and seen in mobile devices before, but Apple was the first to achieve mass market adoption of such a user interface that included particular pre-programmed touch gestures. 
Delivering his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced that Apple Computer, Inc. would from that point on be known as Apple Inc., because computers were no longer the main focus of the company, which had shifted its emphasis to mobile electronic devices. The event also saw the announcement of the iPhone and the Apple TV. The following day, Apple shares hit $97.80, an all-time high at that point. In May, Apple's share price passed the $100 mark.
In an article posted on Apple's website on February 6, 2007, Steve Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management (DRM) (which would allow tracks to be played on third-party players), if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May. Other record labels followed later that year.
In July of the following year, Apple launched the App Store to sell third-party applications for the iPhone and iPod Touch. Within a month, the store sold 60 million applications and brought in $1 million daily on average, with Jobs speculating that the App Store could become a billion-dollar business for Apple. Three months later, it was announced that Apple had become the third-largest mobile handset supplier in the world due to the popularity of the iPhone.
On December 16, 2008, Apple announced that after over 20 years of attending Macworld, 2009 would be the last year Apple would be attending the Macworld Expo, and that Phil Schiller would deliver the 2009 keynote in lieu of the expected Jobs. Almost exactly one month later, on January 14, 2009, an internal Apple memo from Jobs announced that he would be taking a six-month leave of absence, until the end of June 2009, to allow him to better focus on his health and to allow the company to better focus on its products without having the rampant media speculating about his health. Despite Jobs' absence, Apple recorded its best non-holiday quarter (Q1 FY 2009) during the recession with a revenue of $8.16 billion and a profit of $1.21 billion.
After years of speculation and multiple rumored "leaks", Apple announced a large screen, tablet-like media device known as the iPad on January 27, 2010. The iPad runs the same touch based operating system that the iPhone uses and many of the same iPhone apps are compatible with the iPad. This gave the iPad a large app catalog on launch even with very little development time before the release. Later that year on April 3, 2010, the iPad was launched in the US and sold more than 300,000 units on that day, reaching 500,000 by the end of the first week. In May of the same year, Apple's market cap exceeded that of competitor Microsoft for the first time since 1989.
Apple released the fourth generation iPhone, which introduced video calling, multitasking, and a new uninsulated stainless steel design, which acts as the phone's antenna. Because of this antenna implementation, some iPhone 4 users reported a reduction in signal strength when the phone is held in specific ways. After a large amount of media coverage including mainstream news organizations, Apple held a press conference where they offered buyers a free rubber 'bumper' case, which had been proven to eliminate the signal reduction issue. Later that year Apple again refreshed its iPod line of MP3 players which introduced a multi-touch iPod Nano, iPod Touch with FaceTime, and iPod Shuffle with buttons which brought back the buttons of earlier generations.
In October 2010, Apple shares hit an all-time high, eclipsing $300. Additionally, on October 20, Apple updated their MacBook Air laptop, iLife suite of applications, and unveiled Mac OS X Lion, the latest installment in their Mac OS X operating system. On January 6, 2011, the company opened their Mac App Store, a digital software distribution platform, similar to the existing iOS App Store. Apple was featured in the documentary "Something Ventured" which premiered in 2011.
2011–present: Post–Steve Jobs era.
On January 17, 2011, Jobs announced in an internal Apple memo that he would take another medical leave of absence, for an indefinite period, to allow him to focus on his health. Chief operating officer Tim Cook assumed Jobs' day-to-day operations at Apple, although Jobs would still remain "involved in major strategic decisions for the company." Apple became the most valuable consumer-facing brand in the world. In June 2011, Steve Jobs surprisingly took the stage and unveiled iCloud, an online storage and syncing service for music, photos, files and software which replaced MobileMe, Apple's previous attempt at content syncing. This would be the last product launch Jobs would attend before his death. It has been argued that Apple has achieved such efficiency in its supply chain that the company operates as a monopsony (one buyer, many sellers), in that it can dictate terms to its suppliers. In July 2011, due to the American debt-ceiling crisis, Apple's financial reserves were briefly larger than those of the US Government. On August 24, 2011, Jobs resigned his position as CEO of Apple. He was replaced by Tim Cook and Jobs became Apple's chairman. Prior to this, Apple did not have a chairman and instead had two co-lead directors, Andrea Jung and Arthur D. Levinson, who continued with those titles until Levinson became Chairman of the Board in November. 
On October 4, 2011, Apple announced the iPhone 4S, which included an improved camera with 1080p video recording, a dual core A5 chip capable of 7 times faster graphics than the A4, an "intelligent software assistant" named Siri, and cloud-sourced data with iCloud. The following day, on October 5, 2011, Apple announced that Jobs had died, marking the end of an era for Apple Inc. The iPhone 4S was officially released on October 14, 2011.
On October 29, 2011, Apple purchased C3 Technologies, a mapping company, for $240 million, becoming the third mapping company Apple has purchased. On January 10, 2012, Apple paid $500 million to acquire Anobit, an Israeli hardware company that developed and supplies a proprietary memory signal processing technology that improves the performance of flash-memory used in iPhones and iPads.
On January 19, 2012, Apple's Phil Schiller introduced iBooks Textbooks for iOS and iBook Author for Mac OS X in New York City. This was the first major announcement by Apple since the passing of Steve Jobs, who stated in his biography that he wanted to reinvent the textbook and education. The 3rd generation iPad was announced on March 7, 2012. It includes a Retina display, a new CPU, a five megapixel camera, and 1080p video recording.
On a July 24, 2012, conference call with investors, Tim Cook said that he loved India, but that Apple was going to expect larger opportunities outside of India, citing the reason as the 30% sourcing requirement from India.
On August 20, 2012, Apple's rising stock rose the company's value to a world-record $624 billion dollars. This beat the non-inflation-adjusted record for market capitalization set by Microsoft in 1999. On August 24, 2012, a US jury ruled that Samsung should pay Apple $1.05 billion (£665m) in damages in an intellectual property lawsuit. Samsung said they will appeal the court ruling. 
On September 12, 2012, Apple unveiled the iPhone 5, featuring an enlarged screen, more powerful processors, and running iOS 6. The latter includes a new mapping application (replacing Google Maps) that has attracted some criticism. It was made available on September 21, 2012, and became Apple's biggest iPhone launch, with over 2 million pre-orders pushing back the delivery date to late October.
On October 23, 2012, Apple unveiled the iPad Mini, which features a 7.9-inch screen in contrast to the iPad's 9.7-inch screen. Apple also released a third-generation 13-inch MacBook Pro with a Retina display; the iPad 4, featuring a faster processor and a Lightning dock connector; After the launch of Apple's iPad mini and fourth generation iPad on November 3rd, 2012, Apple announced that they had sold 3 million iPads in three days of the launch, but it did not mention the sales figures of specific iPad models.
On November 10, 2012, Apple confirmed a global settlement that would dismiss all lawsuits between Apple and HTC up to that date, in favor of a ten year license agreement for current and future patents between the two companies.It is predicted that Apple will make $280 million a year from this deal with HTC.
In December 2012, in a TV interview for NBC's "Rock Center" and also aired on the "Today" morning show, Apple CEO Tim Cook said that in 2013 the company will produce one of its existing lines of Mac computers in the United States. In January 2013, Cook stated that he expected China to overtake the US as Apple's biggest market.
Products.
Mac.
Apple sells a variety of computer accessories for Macs, including Thunderbolt Display, Magic Mouse, Magic Trackpad, Wireless Keyboard, Battery Charger, the AirPort wireless networking products, and Time Capsule.
iPad.
On January 27, 2010, Apple introduced their much-anticipated media tablet, the iPad, running a modified version of iOS. It offers multi-touch interaction with multimedia formats including newspapers, magazines, ebooks, textbooks, photos, movies, TV shows videos, music, word processing documents, spreadsheets, video games, and most existing iPhone apps. It also includes a mobile version of Safari for web browsing, as well as access to the App Store, iTunes Library, iBookstore, contacts, and notepad. Content is downloadable via Wi-Fi and optional 3G service or synced through the user's computer. ATT was initially the sole US provider of 3G wireless access for the iPad.
On March 2, 2011, Apple introduced the iPad 2, which had a faster processor and two cameras on the front and back, respectively. It also added support for optional 3G service provided by Verizon in addition to the existing offering by ATT. However, the availability of the iPad 2 has been limited as a result of the devastating earthquake and ensuing tsunami in Japan in March 2011.
On March 7, 2012, Apple introduced the third-generation iPad, marketed as "the new iPad". It added LTE service from ATT or Verizon, the upgraded A5X processor, and the Retina display (2048 by 1536 resolution), originally implemented on the iPhone 4 and iPhone 4S. The dimensions and form factor remained relatively unchanged, with the new iPad being a fraction thicker and heavier than the previous version, and minor positioning changes.
On October 23, 2012, Apple introduced the fourth-generation iPad, marketed as the "iPad with Retina display". It added the upgraded A6X processor and replaced the traditional 30-pin dock connector with the all-digital Lightning connector. The iPad mini was also introduced, with a reduced 7.9-inch display and featuring much of the same internal specifications as the iPad 2.
Since its launch, iPad users have downloaded 3 billion apps, while the total App Store downloads is over 25 billion downloads.
iPod.
On October 23, 2001, Apple introduced the iPod digital music player. Several updated models have since been introduced, and the iPod brand is now the market leader in portable music players by a significant margin, with more than 350 million units shipped . Apple has partnered with Nike to offer the Nike+iPod Sports Kit, enabling runners to synchronize and monitor their runs with iTunes and the Nike+ website.
iPhone.
At the Macworld Conference  Expo in January 2007, Steve Jobs introduced the long-anticipated iPhone, a convergence of an Internet-enabled smartphone and iPod. The original iPhone was released on June 29, 2007 for $499 (4 GB) and $599 (8 GB) with an ATT contract. On February 5, 2008, it was updated to have 16 GB of memory, in addition to the 8 GB and 4 GB models. It combined a 2.5G quad band GSM and EDGE cellular phone with features found in handheld devices, running scaled-down versions of Apple's Mac OS X (dubbed iPhone OS, later renamed iOS), with various Mac OS X applications such as Safari and Mail. It also includes web-based and Dashboard apps such as Google Maps and Weather. The iPhone features a touchscreen display, Bluetooth, and Wi-Fi (both "b" and "g"). This version added support for 3G networking and assisted-GPS navigation. The flat silver back and large antenna square of the original model were eliminated in favor of a curved glossy black or white back. Following customer complaints, the previously-recessed headphone jack was changed to a flush jack for compatibility with more styles of headphones. Software capabilities were improved with the release of the App Store, providing applications for download that were compatible with the iPhone. On April 24, 2009, the App Store surpassed one billion downloads. At WWDC on June 8, 2009, Apple announced the iPhone 3GS. It provided an incremental update to the device, including faster internal components, support for faster 3G speeds, video recording capbility, and voice control.
At WWDC on June 7, 2010, Apple announced the iPhone 4, which the company describes as the "biggest leap we've taken" since the original model. It features an all-new design, a 960x640 display, the Apple A4 processor also used in the iPad, a gyroscope for enhanced gaming, 5MP camera with LED flash, front-facing VGA camera and FaceTime video calling. Shortly after its release, reception issues were discovered by consumers, due to the stainless steel band around the edge of the device, which also serves as the phone's cellular signal and Wi-Fi antenna. The issue was corrected by a "Bumper Case" distributed by Apple for free to all owners for a few months. In June 2011, Apple overtook Nokia to become the world's biggest smartphone maker by volume.
On October 4, 2011, Apple unveiled the iPhone 4S, which was released in the United States, Canada, Australia, United Kingdom, France, Germany, and Japan on October 14, 2011, with other countries set to follow later in the year. It features the Apple A5 processor, and is the first model offered by Sprint (joining ATT and Verizon Wireless as the United States carriers offering iPhone models). On October 19, 2011, Apple announced an agreement with C Spire Wireless to sell the iPhone 4S with that carrier in the near future, marking the first time the iPhone was officially supported on a regional carrier's network. Another notable feature of the iPhone 4S was Siri voice assistant technology, which Apple had acquired in 2010, as well as other features, including an updated 8MP camera with new optics. Apple sold 4 million iPhone 4S phones in the first three days of availability, making it the most successful launch of any mobile phone to date.
On September 12, 2012, Apple introduced the sixth-generation iPhone, the iPhone 5. It added a 4-inch display, 4G LTE connectivity, and the upgraded Apple A6 chip, among several other improvements. Two million iPhones were sold in the first twenty-four hours of pre-ordering and over 5 million handsets were sold in the first 3 days of its launch.
Apple TV.
At the 2007 Macworld conference, Jobs demonstrated the Apple TV, (previously known as the iTV), a set-top video device intended to bridge the sale of content from iTunes with high-definition televisions. The device links up to a user's TV and syncs, either via Wi-Fi or a wired network, with one computer's iTunes library and streams from an additional four. The Apple TV originally incorporated a 40 GB hard drive for storage, includes outputs for HDMI and component video, and plays video at a maximum resolution of 720p. On May 31, 2007 a 160 GB drive was released alongside the existing 40 GB model and on January 15, 2008 a software update was released, which allowed media to be purchased directly from the Apple TV. In September 2009, Apple discontinued the original 40 GB Apple TV and now continues to produce and sell the 160 GB Apple TV. On September 1, 2010, alongside the release of the new line of iPod devices for the year, Apple released a completely redesigned Apple TV. The new device is 1/4 the size, runs quieter, and replaces the need for a hard drive with media streaming from any iTunes library on the network along with 8 GB of flash memory to cache media downloaded. Apple with the Apple TV has added another device to its portfolio that runs on its A4 processor along with the iPad and the iPhone. The memory included in the device is the half of the iPhone 4 at 256 MB; the same as the iPad, iPhone 3GS, iPod touch 3G, and iPod touch 4G. It has HDMI out as the only video out source. Features include access to the iTunes Store to rent movies and TV shows (purchasing has been discontinued), streaming from internet video sources, including YouTube and Netflix, and media streaming from an iTunes library. Apple also reduced the price of the device to $99. A third generation of the device was introduced at an Apple event on March 7, 2012, with new features such as higher resolution (1080p) and a new user interface.
Software.
Apple develops its own operating system to run on Macs, OS X, the latest version being OS X Mountain Lion (version 10.8). Apple also independently develops computer software titles for its OS X operating system. Much of the software Apple develops is bundled with its computers. An example of this is the consumer-oriented iLife software package that bundles iMovie, iPhoto and GarageBand. For presentation, page layout and word processing, iWork is available, which includes Keynote, Pages, and Numbers. iTunes, QuickTime media player, Safari web browser, and Software Update are available as free downloads for both Mac OS X and Windows.
Apple also offers a range of professional software titles. Their range of server software includes the operating system OS X Server; Apple Remote Desktop, a remote systems management application; and Xsan, a Storage Area Network file system. For the professional creative market, there is Aperture for professional RAW-format photo processing; Final Cut Pro, a video production suite; Logic Pro, a comprehensive music toolkit; and Motion, an advanced effects composition program.
Apple also offers online services with iCloud, which provides cloud storage and syncing for a wide range of data, including email, contacts, calendars, photos and documents. It also offers iOS device backup, and is able to integrate directly with third-party apps for even greater functionality. iCloud is the fourth generation of online services provided by Apple, and was preceded by MobileMe, .Mac and iTools, all which met varying degrees of success.
Corporate identity.
Logo.
According to Steve Jobs, Apple was so named because Jobs was coming back from an apple farm, and he was on a fruitarian diet. He thought the name was "fun, spirited and not intimidating".
Apple's first logo, designed by Ron Wayne, depicts Sir Isaac Newton sitting under an apple tree. It was almost immediately replaced by Rob Janoff's "rainbow Apple", the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it. Janoff presented Jobs with several different monochromatic themes for the "bitten" logo, and Jobs immediately took a liking to it. While Jobs liked the logo, he insisted it be in color to humanize the company. The logo was designed with a bite so that it would not be confused with a cherry. The colored stripes were conceived to make the logo more accessible, and to represent the fact the Apple II could generate graphics in color. Both Janoff and Apple deny any homage to Turing in the design of the logo.
In 1998, with the roll-out of the new iMac, Apple discontinued the rainbow theme and began to use monochromatic themes, nearly identical in shape to its previous rainbow incarnation, on various products, packaging and advertising. An Aqua-themed version of the monochrome logo was used from 2001–2003, and a Glass-themed version has been used since 2003.
Steve Jobs and Steve Wozniak were Beatles fans, but Apple Inc. had trademark issues with Apple Corps Ltd., a multimedia company started by The Beatles in 1967, involving their name and logo. This resulted in a series of lawsuits and tension between the two companies. These issues ended with settling of their most recent lawsuit in 2007.
Advertising.
Apple's first slogan, "Byte into an Apple", was coined in the late 1970s. From 1997–2002, the slogan "Think Different" was used in advertising campaigns, and is still closely associated with Apple. Apple also has slogans for specific product lines — for example, "iThink, therefore iMac" was used in 1998 to promote the iMac, and "Say hello to iPhone" has been used in iPhone advertisements. "Hello" was also used to introduce the original Macintosh, Newton, iMac ("hello (again)"), and iPod.
Since the introduction of the Macintosh in 1984 with the 1984 Super Bowl commercial to the more modern 'Get a Mac' adverts, Apple has been recognized in the past for its efforts towards effective advertising and marketing for its products, though its advertising was criticized for the claims made by some later campaigns, particularly the 2005 Power Mac ads and iPhone ads in Britain.
Apple's product commercials gained fame for launching musicians into stardom as a result of their eye-popping graphics and catchy tunes. First, the company popularized Canadian singer Feist's "1234" song in its ad campaign. Apple has, however, supported the continuing existence of a network of Mac User Groups in most major and many minor centers of population where Mac computers are available.
Mac users would meet at the European Apple Expo and the San Francisco Macworld Conference  Expo trade shows where Apple traditionally introduced new products each year to the industry and public until Apple pulled out of both events. While the conferences continue, Apple does not have official representation there. Mac developers, in turn, continue to gather at the annual Apple Worldwide Developers Conference.
Apple Store openings can draw crowds of thousands, with some waiting in line as much as a day before the opening or flying in from other countries for the event. The New York City Fifth Avenue "Cube" store had a line as long as half a mile; a few Mac fans took the opportunity of the setting to propose marriage. The Ginza opening in Tokyo was estimated in the thousands with a line exceeding eight city blocks.
John Sculley told "The Guardian" newspaper in 1997: "People talk about technology, but Apple was a marketing company. It was the marketing company of the decade." Research in 2002 by NetRatings indicate that the average Apple consumer was usually more affluent and better educated than other PC company consumers. The research indicated that this correlation could stem from the fact that on average Apple Inc. products are more expensive than other PC products.
Corporate affairs.
During the Mac's early history Apple generally refused to adopt prevailing industry standards for hardware, instead creating their own. This trend was largely reversed in the late 1990s beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since adopted USB, AGP, HyperTransport, Wi-Fi, and other industry standards in its computers and was in some cases a leader in the adoption of standards such as USB. FireWire is an Apple-originated standard that has seen widespread industry adoption after it was standardized as IEEE 1394.
Ever since the first Apple Store opened, Apple has sold third-party accessories. For instance, at one point Nikon and Canon digital cameras were sold inside the store. Adobe, one of Apple's oldest software partners, also sells its Mac-compatible software, as does Microsoft, who sells Microsoft Office for the Mac. Books from John Wiley  Sons, who publishes the For Dummies series of instructional books, are a notable exception, however. The publisher's line of books were banned from Apple Stores in 2005 because Steve Jobs disagreed with their decision to publish an unauthorized Jobs biography, "iCon". After the launch of the iBookstore, Apple stopped selling physical books, both online and at the Apple Retail Stores.
Headquarters.
Apple Inc.'s world corporate headquarters are located in the middle of Silicon Valley, at 1–6 Infinite Loop, Cupertino, California. This Apple campus has six buildings that total and was built in 1993 by Sobrato Development Cos.
Apple created subsidiaries in low-tax places such as Ireland, the Netherlands, Luxembourg and the British Virgin Islands to cut the taxes it pays around the world. According to the "New York Times," Apple was among the first tech companies to designate overseas salespeople in high-tax countries in a manner that allowed the company to sell on behalf of low-tax subsidiaries on other continents, sidestepping income taxes. Apple was a pioneer of an accounting technique known as the "Double Irish With a Dutch Sandwich," which reduces taxes by routing profits through Irish subsidiaries and the Netherlands and then to the Caribbean. 
In 2006, Apple announced its intention to build a second campus on assembled from various contiguous plots (east of N Wolfe Road between Pruneridge Avenue and Vallco Parkway). Later acquisitions increased this to 175 acres. The new campus, also in Cupertino, will be about east of the current campus. The new campus building will be designed by Norman Foster.
On June 7, 2011, Steve Jobs gave a presentation to Cupertino City Council, detailing the architectural design of the new building and its environs. The new campus is planned to house up to 13,000 employees in one central four-storied circular building (with a café for 3,000 sitting people integrated) surrounded by extensive landscape (with parking mainly underground and the rest centralized in a parking structure). There will be additional buildings such as an auditorium, RD facilities, a fitness center and a dedicated generating plant as primary source of electricity (powered by natural gas and other more environmentally sound means).
Apple's headquarters for Europe, the Middle East and Africa (EMEA) are located in Cork in the south of Ireland. The facility, which opened in 1980, was Apple's first location outside of the United States. Apple Sales International, which deals with all of Apple's international sales outside of the USA, is located at Apple's campus in Cork along with Apple Distribution International, which similarly deals with Apple's international distribution network.
On April 20, 2012, Apple announced the addition of 500 new jobs to its European headquarters. This will bring the total workforce from around 2,800 to 3,300 employees. The company will build a new office block on its Hollyhill Campus to accommodate the additional staff.
Corporate culture.
Apple was one of several highly successful companies founded in the 1970s that bucked the traditional notions of what a corporate culture should look like in organizational hierarchy (flat versus tall, casual versus formal attire, etc.). Other highly successful firms with similar cultural aspects from the same period include Southwest Airlines and Microsoft. Originally, the company stood in opposition to staid competitors like IBM by default, thanks to the influence of its founders; Steve Jobs often walked around the office barefoot even after Apple was a Fortune 500 company. By the time of the "1984" TV ad, this trait had become a key way the company attempted to differentiate itself from its competitors. According to a 2011 report in "Fortune," this has resulted in a corporate culture more akin to a startup rather than a multinational corporation.
As the company has grown and been led by a series of chief executives, each with his own idea of what Apple should be, some of its original character has arguably been lost, but Apple still has a reputation for fostering individuality and excellence that reliably draws talented people into its employ. This was especially after Jobs' return. To recognize the best of its employees, Apple created the Apple Fellows program, awarding individuals who made extraordinary technical or leadership contributions to personal computing while at the company. The Apple Fellowship has so far been awarded to a few individuals including Bill Atkinson, Steve Capps, Rod Holt, Guy Kawasaki, Al Alcorn, Don Norman,
Numerous employees of Apple have cited that projects without Jobs' involvement often take longer than projects with his involvement. 
At Apple, employees are specialists who are not exposed to functions outside their area of expertise. Jobs saw this as a means of having best-in-class employees in every role. For instance, Ron Johnson who was Senior Vice President of Retail Operations until November 1, 2011, was responsible for site selection, in-store service, and store layout, yet he had no control of the inventory in his stores (which is done company wide by then-COO and now CEO Tim Cook who has a background in supply-chain management). This is the opposite of General Electric's corporate culture which has created well-rounded managers. The company previously advertised its products as being made in America up to the late 1990s, however as a result of outsourcing initiatives in the 2000s almost all of its manufacturing is now done abroad. According to a report by the New York Times, Apple insiders "believe the vast scale of overseas factories as well as the flexibility, diligence and industrial skills of foreign workers have so outpaced their American counterparts that “Made in the U.S.A.” is no longer a viable option for most Apple products".
Unlike other major US companies, Apple has a relatively simple compensation policy for executives, which does not include perks that other CEOs enjoy such as country club fees and private use of company aircraft. The company usually grants stock options to executives every other year.
Finance.
In its fiscal year ending in September 2011, Apple Inc. reported a total of $108 billion in annual revenues – a significant increase from its 2010 revenues of $65 billion – and nearly $82 billion in cash reserves. Apple achieved these results while losing market share in certain product categories. On March 19, 2012, Apple announced plans for a $2.65-per-share dividend beginning in fourth quarter of 2012, per approval by their board of directors.
On August 20, 2012, Apple closed at a record share price of $665.15. With 936,596,000 outstanding shares (as of June 30, 2012), it had a market capitalization of $622.98 billion. At the time, this was the highest nominal market capitalization ever reached by a publicly traded company, surpassing a record set by Microsoft in 1999.
British Conservative Party Member of Parliament Charlie Elphicke published research on October 30, 2012, which showed that some multinational companies, including Apple Inc., were making billions of pounds of profit in the UK, but were paying an effective tax rate to the UK Treasury of only 3 percent, well below standard corporation tax. He followed this research by calling on the Chancellor of the Exchequer George Osborne to force these multinationals, which also included Google and Coca-Cola, to state the effective rate of tax they pay on their UK revenues. Elphicke also said that government contracts should be withheld from multinationals who do not pay their fair share of UK tax.
Environmental record.
Greenpeace has campaigned against Apple on various environmental issues, including a global end-of-life take-back plan, non-recyclable hardware components and toxins within iPhone hardware. Since 2003 Greenpeace has campaigned against Apple's use of particular chemicals in its products, more specifically, the inclusion of PVC and BFRs in their products. On May 2, 2007, Steve Jobs released a report announcing plans to eliminate PVC and BFRs by the end of 2008. Apple has since eliminated PVC and BFRs across its product range, becoming the first laptop maker to do so.
In the first edition of the Greenpeace 'Green Electronics Guide', released in August 2006, Apple only scored 2.7/10.
The Environmental Protection Agency rates Apple highest amongst producers of notebook computers, and fairly well compared to producers of desktop computers and LCD displays.
In June 2007, Apple upgraded the MacBook Pro, replacing cold cathode fluorescent lamp (CCFL) backlit LCD displays with mercury-free LED backlit LCD displays and arsenic-free glass, Apple offers information about the emissions, materials, and electrical usage of each product.
In June 2009, Apple's iPhone 3GS was free of PVC, arsenic, BFRs and had an efficient power adapter.
In October 2009, Apple upgraded the iMac and MacBook, replacing the cold cathode fluorescent lamp (CCFL) backlit LCD displays with mercury-free LED backlit LCD displays and arsenic-free glass. This means all Apple computers have mercury free LED backlit displays, arsenic-free glass and are without PVC cables. All Apple computers also have EPEAT Gold status. This was an increase from May 2008, when Climate Counts only gave Apple 11 points out of 100, which placed the company last among electronics companies, at which time Climate Counts also labeled Apple with a "stuck icon", adding that Apple at the time was "a choice to avoid for the climate conscious consumer".
In October 2011, Chinese authorities have ordered an Apple supplier to close part of its plant in Suzhou after residents living nearby raised significant environmental concerns.
In November 2011, Apple featured in Greenpeace's Guide to Greener Electronics. which ranks electronics manufacturers on sustainability, climate and energy policy, and how "green" their products are. The company ranked 4th out of 15 electronics companies (moving up five places from the previous year) with a score of 4.6/10 down from 4.9. Greenpeace praises Apple's sustainability, noting that the company exceeded its 70% global recycling goal in 2010. It continues to score well on the products rating with all Apple products now being free of PVC vinyl plastic and brominated flame retardants. However, the guide criticizes Apple on the Energy criteria for not seeking external verification of its greenhouse gas emissions data and for not setting out any targets to reduce emissions.
In June 2012, Apple Inc. withdrew its products from the Electronic Product Environmental Assessment Tool (EPEAT) certification system, but reversed this decision in July.
Labor practices.
In 2006, the "Mail on Sunday" reported on the working conditions that existed at factories in China where the contract manufacturers Foxconn and Inventec produced the iPod. The article stated that one complex of factories that assembles the iPod (among other items) had over 200,000 workers that lived and worked in the factory, with employees regularly working more than 60 hours per week. The article also reported that workers made around $100 per month and were required to live pay for rent and food from the company, which generally amounted to a little over half of workers' earnings. 
Apple immediately launched an investigation and worked with their manufacturers to ensure acceptable working conditions. In 2007, Apple started yearly audits of all its suppliers regarding worker's rights, slowly raising standards and pruning suppliers that did not comply. Yearly progress reports have been published since 2008. In 2010, workers in China planned to sue iPhone contractors over poisoning by a cleaner used to clean LCD screens. One worker claimed that he and his coworkers had not been informed of possible occupational illnesses. After a spate of suicides in a Foxconn facility in China making iPads and iPhones, albeit at a lower rate than in China as a whole, workers were forced to sign a legally binding document guaranteeing that they would not kill themselves.
In 2011 Apple admitted that its suppliers' child labor practices in China had worsened.
Workers in factories producing Apple products have also been exposed to n-hexane, a neurotoxin that is a cheaper alternative than alcohol for cleaning the products.
Charitable causes.
As of 2012, Apple is listed as a partner of the Product RED campaign, together with other brands such as Nike, Girl, American Express and Converse. The campaign's mission is to prevent the transmission of HIV from mother to child by 2015 (its byline is "Fighting For An AIDS Free Generation").
In November 2012, Apple donated $2.5 million dollars to the American Red Cross to aid relief efforts after Hurricane Sandy.

</doc>
<doc id="857" url="http://it.wikipedia.org/wiki/?curid=857" title="Aberdeenshire">
Aberdeenshire

Aberdeenshire (, ) is one of the 32 unitary council areas in Scotland and a lieutenancy area. 
The present day Aberdeenshire council area does not include the City of Aberdeen, now a separate council area, from which its name derives. Together, the modern council area and the city formed historic Aberdeenshire - one of the counties of Scotland formerly used for local government purposes. Within these borders, the County of Aberdeen remains in existence as a registration county.
Aberdeenshire Council is headquartered at Woodhill House, in Aberdeen; the only Scottish council whose headquarters are based outwith its area's border. Aberdeenshire borders Angus and Perth and Kinross to the south, and Highland and Moray to the west.
Traditionally, it has been economically dependent upon the primary sector (agriculture, fishing, and forestry) and related
processing industries. Over the last 40 years, the development of the oil and gas industry and associated service sector has broadened Aberdeenshire’s economic base, and contributed to a rapid population growth of some 50% since 1975, while the land covered represents 8% of Scotland's overall territory.
History.
Aberdeenshire has a rich prehistoric and historic heritage. It is the locus of a large number of Neolithic and Bronze Age archaeological sites, including Longman Hill, Kempstone Hill, Catto Long Barrow and Cairn Lee. Since medieval times there have been a number of crossings of the Mounth (a spur of mountainous land that extends from the higher inland range to the North Sea slightly north of Stonehaven) through present day Aberdeenshire from the Scottish Lowlands to the Highlands. Some of the most well known and historically important trackways are the Causey Mounth and Elsick Mounth.
The present council area is named after the historic county of Aberdeen, which had different boundaries and was abolished in 1975 under the Local Government (Scotland) Act 1973. It was replaced by Grampian Regional Council and five district councils: Banff and Buchan, Gordon, Kincardine and Deeside, Moray and the City of Aberdeen. Local government functions were shared between the two levels. In 1996, under the Local Government etc (Scotland) Act 1994, the Banff and Buchan district, Gordon district and Kincardine and Deeside district were merged to form the present Aberdeenshire council area, with the other two districts becoming autonomous council areas.
Demographics.
The council area has a population of approximately 247,600, representing 4.7% of Scotland's total, a rise of over 50% from 1971. Aberdeenshire’s population has grown steadily over recent years, increasing by 9.1% since 2001. Over this period Scotland’s population grew by 3.8%.
Economy.
Aberdeenshire’s Gross Domestic Product (GDP) is estimated at £3,496m (2011), representing 5.2% of the Scottish total. Aberdeenshire’s economy is closely linked to Aberdeen City’s (GDP £7,906m) and in 2011 the region as a whole was calculated to contribute 16.8% of Scotland’s GDP. Between 2012 and 2014 the combined Aberdeenshire and Aberdeen City economic forecast GDP growth rate is 6.8%, the highest growth rate of any local authority area and above the Scottish rate of 4.8%.
A significant proportion of Aberdeenshire’s working residents commute to Aberdeen City for work, varying from 11.5% from Fraserburgh to 65% from Westhill.
Average Gross Weekly Earnings (for full time employees employed in work places in Aberdeenshire in 2011) are £570.60. This is lower than the Scottish average by £4.10 and a fall of 2.6% on the 2010 figure. The average gross weekly pay of people resident in Aberdeenshire is much higher, at £641.90, as many people commute out
of Aberdeenshire, principally into Aberdeen City.
Total employment (excluding farm data) in Aberdeenshire is estimated at 93,700 employees (Business Register and
Employment Survey 2009). The majority of employees work within the service sector, predominantly in public administration, education and health. Almost 19% of employment is within the public sector. Aberdeenshire’s economy remains closely linked to Aberdeen City’s and the North Sea oil industry, with many employees in oil related jobs.
The average monthly unemployment (claimant count) rate for Aberdeenshire in 2011 was 1.5%. This is lower than the average rates for Aberdeen City (2.3%), Scotland (4.2%) and the UK (3.8%).
Major Industries.
Energy - There is significant energy related infrastructure, presence and expertise in Aberdeenshire. Peterhead is an important centre for the energy industry. Peterhead Port, which includes an extensive new quay with adjacent lay down area at Smith Quay, is a major support location for North Sea oil and gas exploration and production and the fast growing global subsea sector. The Gas Terminal at St Fergus handles around 15% of the UK’s natural gas requirements and the Peterhead power station is looking to host the UK’s first carbon capture and storage power generation project.
Fishing - Aberdeenshire is Scotland's foremost fishing area. In 2010, catches landed at Aberdeenshire's ports accounted for over half the total fish landings of Scotland, and almost 45% in the UK. Peterhead and Fraserburgh ports, alongside Aberdeen City, provide much of the employment in these sectors.
Agriculture - Aberdeenshire is rich in arable land, with an estimated 9,000 people employed in the sector, and is best known for rearing livestock.
Tourism - this sector continues to grow, with a range of sights to be seen in the area. From the lively Cairngorm Mountain range, to the bustling fishing ports on the North-east coast, Aberdeenshire samples a bit of everything. Aberdeenshire also has rugged coastline to complete many sandy beaches, and is a hot spot for tourist activity throughout the year. Almost 1.3 million tourists visisted the region in 2011 - up 3% on the previous year.
Governance and politics.
The Council’s Revenue Budget for 2012/13 totals approx £548 million. The Education, Learning and Leisure Service takes the largest share of budget (52.3%), followed by Housing and Social Work (24.3%), Infrastructure Services (15.9%), Joint Boards (such as Fire and Police) and Misc services (7.9%) and Trading Activities (0.4%).
21.5% of the revenue is raised locally through the Council Tax. Average Band D Council Tax is £1,141 (2012/13), no change on the previous year.
The current Chief Executive of the Council is Colin Mackenzie and the elected Council Leader is Jim Gifford. Aberdeenshire also has a Provost, who is Councillor Jill Webster. 
The council has devolved power to six area committees: Banff and Buchan; Buchan; Formartine; Garioch; Marr; and Kincardine and Mearns. Each area committee takes decisions on local issues such as planning applications, and the split is meant to reflect the diverse circumstances of each area. (Boundary map)
Hydrology and climate.
There are numerous rivers and burns in Aberdeenshire, including Cowie Water, Carron Water, Burn of Muchalls, River Dee, River Don, River Ury, River Ythan, Water of Feugh, Burn of Myrehouse, Laeca Burn and Luther Water. Numerous bays and estuaries are found along the seacoast of Aberdeenshire, including Banff Bay, Ythan Estuary, Stonehaven Bay and Thornyhive Bay. Summers are mild and winters are typically cold in Aberdeenshire; Coastal temperatures are moderated by the North Sea such that coastal areas are typically cooler in the summer and warmer in winter than inland locations. Coastal areas are also subject to haar, or coastal fog.

</doc>
<doc id="859" url="http://it.wikipedia.org/wiki/?curid=859" title="Aztlan Underground">
Aztlan Underground

Aztlan Underground is a fusion band from Los Angeles. Since early 1989, Aztlan Underground has played Rapcore. Indigenous drums, flutes, and rattles are commonplace in its musical compositions.
This unique sound is the backdrop for the band's message of dignity for indigenous people, all of humanity, and Earth. Aztlan Underground has been cultivating a grass roots audience across the country, which has become a large and loyal underground following. Their music includes spoken word pieces and elements of punk, hip hop, rock, funk, jazz, and indigenous music, among others.
The artists are Chenek "DJ Bean" (turntables, samples and percussion), Yaotl (vocals, indigenous percussion), Joe "Peps" (bass, rattles), Alonzo Beas (guitars, synth), Caxo (drums, indigenous percussion), and Bulldog (vocals, flute).
Aztlan Underground appeared on television on Culture Clash on Fox in 1993, was part of "Breaking Out", a concert on pay per view in 1998, and was featured in the independent films "Algun Dia" and "Frontierlandia".
The band has been mentioned or featured in various newspapers and magazines: the Vancouver Sun, Northshore News (Vancouver, Canada newspaper), New Times (Los Angeles weekly entertainment newspaper), BLU Magazine (underground hip hop magazine), BAM Magazine (Southern California), La Banda Elastica Magazine, and the Los Angeles Times Calendar section. It is also the subject of a chapter in "It's Not About A Salary", by Brian Cross. They also opened for Rage Against the Machine in Mexico City.
It was nominated in the New Times 1998 "Best Latin Influenced" category, the BAM Magazine 1999 "Best Rock en Español" category, and the LA Weekly 1999 "Best Hip Hop" category.
Aztlan Underground were signed to a Basque record label in 1999 which enabled them to tour Spain extensively and perform in France and Portugal.
Other parts of the world that Aztlan Underground have performed include Canada, Australia, and Venezuela.
The band completed their third album and released it exclusively digital on August 29, 2009. The band is set to begin writing a new record this year.
Aztlan Underground were nominated for four Native American Music Award categories for the Nammys 2010. See Nammys.com
Discography.
"Decolonize".
Year:1995
"Sub-Verses".
Year:1998
"Aztlan Underground".
Year:2009

</doc>
<doc id="863" url="http://it.wikipedia.org/wiki/?curid=863" title="American Civil War">
American Civil War

The American Civil War, also known as the War between the States or simply the Civil War (see naming), was a civil war fought from 1861 to 1865 between the United States (the "Union" or the "North") and several Southern slave states that had declared their secession and formed the Confederate States of America (the "Confederacy" or the "South"). The war had its origin in the fractious issue of slavery, and, after four years of bloody combat (mostly in the South), the Confederacy was defeated, slavery was abolished, and the difficult Reconstruction process of restoring unity and guaranteeing rights to the freed slaves began. 
In the presidential election of 1860, Republicans led by Abraham Lincoln opposed expanding slavery into United States' territories. Lincoln won but before his inauguration on March 4, 1861, seven cotton-based slave states formed the Confederacy. Outgoing Democrat James Buchanan and the incoming Republicans rejected the legality of secession. Lincoln’s inaugural address insisted his administration would not initiate civil war, leading eight remaining slave states to reject immediate calls for secession. A Peace Conference failed to find a compromise. Both sides prepared for war. The Confederates assumed that European countries were so dependent on "King Cotton" for its industry that they would intervene; none did and none recognized the new Confederate States of America. 
Hostilities began on April 12, 1861, when Confederate forces fired upon Fort Sumter, a key fort held by Union troops in South Carolina. Lincoln called for the creation of an army to retake it; meanwhile, four border slave states joined the Confederacy, bringing their total to eleven. The Union soon controlled the border states and established a naval blockade that crippled the southern economy. The Eastern Theater was inconclusive in 1861–62. The Fall of 1862 Confederate campaign into Maryland ended at the Battle of Antietam, dissuading British intervention. and an undetermined number of civilian casualties. Historian John Huddleston estimates the death toll at ten percent of all Northern males 20–45 years old, and 30 percent of all Southern white males aged 18–40. Slavery was the central source of escalating political tension in the 1850s. The Republican Party was determined to prevent any spread of slavery, and many Southern leaders had threatened secession if the Republican candidate, Lincoln, won the 1860 election. Following Lincoln's victory, many Southern whites felt that disunion had become their only option.
While not all Southerners saw themselves as fighting to preserve slavery, most of the officers and over a third of the rank and file in Lee's army had close family ties to slavery. To Northerners, in contrast, the motivation was primarily to preserve the Union, not to abolish slavery.
Abraham Lincoln consistently made preserving the Union the central goal of the war, though he increasingly saw slavery as a crucial issue and made ending it an additional goal. Lincoln's decision to issue the Emancipation Proclamation angered both Peace Democrats ("Copperheads") and War Democrats, but energized most Republicans. By warning that free blacks would flood the North, Democrats made gains in the 1862 elections, but they did not gain control of Congress. The Republicans' counterargument that slavery was the mainstay of the enemy steadily gained support, with the Democrats losing decisively in the 1863 elections in Ohio when they tried to resurrect anti-black sentiment.
Slavery.
The slavery issue was primarily about whether the system of slavery was an anachronistic evil that was incompatible with Republicanism in the United States, or a state system protected by the Constitution. The strategy of the anti-slavery forces was to stop the expansion and thus put slavery on a path to gradual extinction. To the white South, this strategy trampled their Constitutional rights. Slavery was gradually phased out of existence in the North and was fading in the border states and urban areas, but expanded in highly profitable cotton states of the Deep South.
Despite compromises in 1820 and 1850, the slavery issues exploded in the 1850s. Causes include controversy over admitting Missouri as a slave state in 1820, the acquisition of Texas as a slave state in 1845 and the status of slavery in western territories won as a result of the Mexican–American War and the resulting Compromise of 1850. Irreconcilable disagreements over slavery ended the Whig and Know Nothing parties, and split the Democratic Party between North and South, while the new Republican Party angered slavery interests by demanding an end to its expansion. Most observers believed that without expansion slavery would eventually die out; Lincoln argued this in 1845 and 1858. Following the U.S. victory over Mexico, Northerners attempted to exclude slavery from conquered territories in the Wilmot Proviso; it never passed. Northern (and British) readers recoiled in anger at the horrors of slavery as described in the novel and play "Uncle Tom’s Cabin" (1852) by abolitionist Harriet Beecher Stowe.
Meanwhile, the South of the 1850s saw an increasing number of slaves leave the border states through sale, manumission and escape. During this same period, slave-holding border states had more free African-Americans and European immigrants than the lower South, which increased Southern fears that slavery was threatened with rapid extinction in this area. With tobacco and cotton wearing out the soil, the South believed it needed to expand slavery. The Deep South had advocates arguing to reopen the international slave trade to populate territory that was to be newly opened to slavery. Southern demands for a slave code to ensure slavery in the territories repeatedly split the Democratic Party between North and South by widening margins. 
To settle the dispute over slavery expansion, Abolitionists and proslavery elements sent their partisans into Kansas, both using ballots and bullets. In the 1850s, a miniature civil war in Bleeding Kansas led pro-South Presidents Franklin Pierce and James Buchanan to attempt a forced admission of Kansas as a slave state. The 1857 Congressional rejection of the pro-slavery Lecompton Constitution was the first multi-party solid-North vote, and that solid vote was anti-slavery to support the democratic majority voting in the Kansas Territory. Violence on behalf of Southern honor reached the floor of the Senate when a Southern Congressmen, Preston Brooks, physically assaulted Republican Senator Charles Sumner when he ridiculed prominent slaveholders as pimps for slavery.
The earlier political party structure failed to make accommodation among sectional differences. Disagreements over slavery caused the Whig and "Know-Nothing" parties to collapse. In 1860, the last national political party, the Democratic Party, split along sectional lines. Anti-slavery Northerners mobilized in 1860 behind moderate Abraham Lincoln because he was most likely to carry the doubtful western states. In 1857, the Supreme Court’s "Dred Scott" decision ended the Congressional compromise for Popular Sovereignty in Kansas. Slavery in the territories was a property right of any settler, regardless of the majority there. Chief Justice Taney’s decision said that slaves were “so far inferior that they had no rights which the white man was bound to respect”. The decision overturned the Missouri Compromise which banned slavery in territory north of the 36°30' parallel. 
Republicans denounced the "Dred Scott" decision and promised to overturn it; Abraham Lincoln warned that the next “Dred Scott” decision could threaten the Northern states with slavery. The Republican party platform called slavery “a national evil”, and Lincoln believed it would die a natural death if it were contained. The Democrat Stephen A. Douglas developed the Freeport Doctrine to appeal to North and South. Congress could not decide either for or against slavery before a territory was settled. The anti-slavery majority in Kansas could stop slavery with its own local laws if their police laws did not protect slavery introduction. Most 1850 political battles followed the arguments of Lincoln and Douglas, focusing on the issue of slavery expansion in the territories. 
But political debate was cut short throughout the South with Northern abolitionist John Brown's 1859 raid at Harpers Ferry Armory in an attempt to incite slave insurrections. The Southern political defense of slavery transformed into widespread expansion of local militias for armed defense of their "peculiar" domestic institution. Lincoln’s assessment of the political issue for the 1860 elections was that, "This question of Slavery was more important than any other; indeed, so much more important has it become that no other national question can even get a hearing just at present." The Republicans gained majorities in both House and Senate for the first time since Democrats in the 1856 elections, they were to be seated in numbers which Lincoln might use to govern, a national parliamentary majority even before pro-slavery House and Senate seats vacated. Meanwhile, Southern Vice President, Alexander Stephens, in the "Cornerstone Speech," declared the new confederate "Constitution has put at rest forever all the agitating questions relating to our peculiar institutions—African slavery as it exists among us—the proper status of the negro in our form of civilization. This was the immediate cause of the late rupture and present revolution."
Considering the relative weight given to causes of the Civil War by contemporary actors, historians such as Chandra Manning argue that both Union and Confederate fighting soldiers believed slavery to be the cause of the Civil War. Union men mainly believed the war was to bring emancipation to the slaves. Confederates fought to protect southern society, and slavery as an integral part of it. Addressing the causes, Eric Foner would relate a historical context with multidimensional political, social and economic variables. The several causes united in the moment by a consolidating nationalism. A social movement that was individualist, egalitarian and perfectionist grew to a political democratic majority attacking slavery, and slavery’s defense in the Southern pre-industrial traditional society brought the two sides to war.
Sectionalism.
Sectionalism refers to the different economies, social structure, customs and political values of the North and South. Of the states carved out of these territories by 1845, all had entered the union as slave states: Louisiana, Missouri, Arkansas, Florida and Texas, as well as the southern portions of Alabama and Mississippi. And with the conquest of northern Mexico, including California, in 1848, slaveholding interests looked forward to the institution flourishing in these lands as well. Southerners also anticipated garnering slaves and slave states in Cuba and Central America. Northern free soil interests vigorously sought to curtail any further expansion of slave soil. It was these territorial disputes that the proslavery and antislavery forces collided over. 
The existence of slavery in the southern states was far less politically polarizing than the explosive question of the territorial expansion of the institution westward. Moreover, Americans were informed by two well-established readings of the Constitution regarding human bondage: first, that the slave states had complete autonomy over the institution within their boundaries, and second, that the domestic slave trade – trade among the states – was immune to federal interference. The only feasible strategy available to attack slavery was to restrict its expansion into the new territories. Slaveholding interests fully grasped the danger that this strategy posed to them. Both the South and the North drew the same conclusion: “The power to decide the question of slavery for the territories was the power to determine the future of slavery itself.” 
By 1860, four doctrines had emerged to answer the question of federal control in the territories, and they all claimed to be sanctioned by the Constitution, implicitly or explicitly. Two of the “conservative” doctrines emphasized the written text and historical precedents of the founding document (specifically, the Northwest Ordinance and the Missouri Compromise), while the other two doctrines developed arguments that transcended the Constitution. 
The first of these “conservative” theories, represented by the Constitutional Union Party, argued that the historical designation of free and slave apportionments in territories should become a Constitutional mandate. The Crittenden Compromise of 1860 was an expression of this view. 
The second doctrine of Congressional preeminence, championed by Abraham Lincoln and the Republican Party, insisted that the Constitution did not bind legislators to a policy of balance – that slavery could be excluded altogether in a territory at the discretion of Congress – with one caveat: the due process clause of the Fifth Amendment must apply. In other words, Congress could restrict human bondage, but never establish it. The Kansas-Nebraska Act of 1854 legislated this doctrine.
The fourth in this quartet is the theory of state sovereignty (“states’ rights”), named after the South Carolinian political theorist and statesman John C. Calhoun. Rejecting the arguments for federal authority or self-government, state sovereignty would empower states to promote the expansion of slavery as part of the Federal Union under the US Constitution – and not merely as an argument for secession. The basic premise was that all authority regarding matters of slavery in the territories resided in each state. The role of the federal government was merely to enable the implementation of state laws when residents of the states entered the territories. The Calhoun doctrine asserted that the federal government in the territories was only the agent of the several sovereign states, and hence incapable of forbidding the bringing into any territory of anything that was legal property in any state. State sovereignty, in other words, gave the laws of the slaveholding states "extra-jurisdictional" effect. 
“States’ rights” was an ideology formulated and applied as a means of advancing slave state interests through federal authority. As historian Thomas L. Krannawitter points out, “he Southern demand for federal slave protection represented a demand for an unprecedented expansion of federal power.” 
By 1860, these four doctrines comprised the major ideologies presented to the American public on the matters of slavery, the territories and the US Constitution.
National elections.
Beginning in the American Revolution and accelerating after the War of 1812, the people of the United States grew in their sense of country as an important example to the world of a national republic of political liberty and personal rights. Previous regional independence movements such as the Greek revolt in the Ottoman Empire, division and redivision in the Latin American political map, and the British-French Crimean triumph leading to an interest in redrawing Europe along cultural differences, all conspired to make for a time of upheaval and uncertainty about the basis of the nation-state. In the world of 19th century self-made Americans, growing in prosperity, population and expanding westward, "freedom" could mean personal liberty or property rights. The unresolved difference would cause failure—first in their political institutions, then in their civil life together.
Nationalism and honor.
Nationalism was a powerful force in the early 19th century, with famous spokesmen such as Andrew Jackson and Daniel Webster. While practically all Northerners supported the Union, Southerners were split between those loyal to the entire United States (called "unionists") and those loyal primarily to the southern region and then the Confederacy.
however at least four states - South Carolina,
Mississippi,
Georgia,
and Texas
- also passed lengthy and detailed explanations of their causes for secession, all of which laid the blame squarely on the influence over the northern states of the movement to abolish slavery, something regarded as a Constitutional right by the slaveholding states.
Union states.
Twenty-three states remained loyal to the Union: California, Connecticut, Delaware, Illinois, Indiana, Iowa, Kansas, Kentucky, Maine, Maryland, Massachusetts, Michigan, Minnesota, Missouri, New Hampshire, New Jersey, New York, Ohio, Oregon, Pennsylvania, Rhode Island, Vermont, and Wisconsin. During the war, Nevada and West Virginia joined as new states of the Union. Tennessee and Louisiana were returned to Union military control early in the war.
The territories of Colorado, Dakota, Nebraska, Nevada, New Mexico, Utah, and Washington fought on the Union side. Several slave-holding Native American tribes supported the Confederacy, giving the Indian Territory (now Oklahoma) a small, bloody civil war.
Battle of Fort Sumter.
Ft. Sumter was located in the middle of the harbor of Charleston, SC where the U.S. forts garrison had withdrawn to avoid incidents with local militias in the streets of the city. Unlike Buchanan who allowed commanders to relinquish possession to avoid bloodshed, Lincoln required Maj. Anderson to hold on until fired upon. Jefferson Davis ordered the surrender of the fort. Anderson gave a conditional reply which the Confederate government rejected, and Davis ordered Beauregard to attack the fort before a relief expedition could arrive. Troops under P. G. T. Beauregard bombarded Fort Sumter on April 12–13, forcing its capitulation. On April 15, Lincoln's Secretary of War then called on Governors for 75,000 volunteers to recapture the fort and other federal property. 
Mobilization.
As the first seven states began organizing a Confederacy in Montgomery, the entire US army numbered 16,000, however Northern governors had begun to mobilize their militias. The Confederate Congress authorized the new nation up to 100,000 troops sent by governors as early as February in the opinion of historian E. Merton Coulter. After Fort Sumter, Lincoln called out 75,000 three-month volunteers, by May Jefferson Davis was pushing for 100,000 men under arms for one year or the duration, and that was answered in kind by the U.S. Congress. 
In the first year of the war, both sides had far more volunteers than they could effectively train and equip. After the initial enthusiasm faded, reliance on the cohort of young men who came of age every year and wanted to join was not enough. Both sides used a draft law—conscription—as a device to encourage or force volunteering; relatively few were actually drafted and served. The Confederacy passed a draft law in April 1862 for young men aged 18 to 35; overseers of slaves, government officials, and clergymen were exempt.
When the Emancipation Proclamation went into effect in January 1863, ex-slaves were energetically recruited by the states, and used to meet the state quotas. States and local communities offered higher and higher cash bonuses for white volunteers. Congress tightened the law in March 1863. Men selected in the draft could provide substitutes or, until mid-1864, pay commutation money. Many eligibles pooled their money to cover the cost of anyone drafted. Families used the substitute provision to select which man should go into the army and which should stay home. There was much evasion and overt resistance to the draft, especially in Catholic areas. The great draft riot in New York City in July 1863 involved Irish immigrants who had been signed up as citizens to swell the machine vote, not realizing it made them liable for the draft.
War on the water.
The small U.S. Navy of 1861 was rapidly enlarged to 6,000 officers and 45,000 men in 1865, with 671 vessels, having a tonnage of 510,396. Its mission was to blockade Confederate ports, take control of the river system, defend against Confederate raiders on the high seas, and be ready for a possible war with the British Royal Navy.
Meanwhile, the main riverine war was fought in the West, where a series of major rivers gave access to the Confederate heartland, if the U.S. Navy could take control. In the East, the Navy supplied and moved army forces about, and occasionally shelled Confederate installations.
Union blockade.
By early 1861, General Winfield Scott had devised the Anaconda Plan to win the war with as little bloodshed as possible. Scott argued that a Union blockade of the main ports would weaken the Confederate economy. Lincoln adopted parts of the plan, but he overruled Scott's caution about 90-day volunteers. Public opinion however demanded an immediate attack by the army to capture Richmond.
Confederate countermeasures.
The Confederacy responded to the blockade by building or converting more than 130 vessels, including twenty-six ironclads and floating batteries. Only half of these saw active service. Many were equipped with ram bows, creating “ram fever” among Union squadrons wherever they threatened. But in the face of overwhelming Union superiority, they were unsuccessful. 
The Confederacy experimented with a submarine, but it did not work well, and with building an ironclad ship, the CSS "Virginia" based on rebuilding a sunken Union ship the "Merrimac". On its first foray on March 8, 1862, the "Virginia" decimated the Union's wooden fleet, but the next day the first Union ironclad the USS "Monitor" showed up to challenge it. The Battle of the Ironclads was a draw, but it marks the worldwide transition to ironclad warships. The Confederacy lost the "Virginia" when the ship was scuttled to prevent capture, and the Union built many copies of the "Monitor". Lacking the technology to build effective warships, the Confederacy attempted to obtain warships from Britain.
Blockade runners.
British investors built small, very fast, steam-driven blockade runners that traded arms and luxuries brought in from Britain through Bermuda, Cuba, and the Bahamas in return for high-priced cotton. The ships were so small that only a small amount of cotton went out. When the Union Navy seized a blockade runner, the ship and cargo were condemned as a Prize of war and sold with the proceeds given to the Navy sailors; the captured crewmen were mostly British and they were simply released. The Southern economy nearly collapsed during the war. There were multiple reasons for the severe deterioration of food supplies, especially in cities, the failure of Southern railroads, the loss of control of the main rivers, foraging by Northern armies, and the seizure of animals and crops by Confederate armies. Historians agree that the blockade was a major factor in ruining the Confederate economy. However, Wise argues that they provided just enough of a lifeline to allow Lee to continue fighting for additional months, thanks to fresh supplies of 400,000 rifles, lead, blankets, and boots that the homefront economy could no longer supply.
Economic impact.
Surdam argues that the blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of very few lives in combat. Practically, the entire Confederate cotton crop was useless (although was sold to Union traders), costing the Confederacy its main source of income. Critical imports were very scarce and the coastal trade was largely ended as well The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried it. Merchant ships owned in Europe could not get insurance and were too slow to evade the blockade; they simply stopped calling at Confederate ports. 
To fight an offensive war the Confederacy purchased ships from Britain, converted them to warships, and raided American merchants ships in the Atlantic and Pacific oceans. Insurance rates skyrocketed and the American flag virtually disappeared from international waters. However, the same ships were reflagged with European flags and continued unmolested. After the war, the U.S. demanded that Britain pay for the damage done, and Britain paid the U.S. $15 million in 1871.
Rivers.
The 1862 Union strategy called for simultaneous advances along four axes. McClellan would lead the main thrust in Virginia towards Richmond. Ohio forces were to advance through Kentucky into Tennessee, the Missouri Department would drive south along the Mississippi River, and the westernmost attack would originate from Kansas. 
Ulysses Grant used river transport and Andrew Foote’s gunboats of the Western Flotilla to threaten the Confederacy's “Gilbraltar of the West” at Columbus, Kentucky. Grant was rebuffed at Belmont, but cut off Columbus. The Confederates, lacking their own gunboats, were forced to retreat and the Union took control of western Kentucky in March 1862. 
In addition to ocean-going warships coming up the Mississippi, the Union Navy used timberclads, tinclads, and armored gunboats. Shipyards at Cairo, Illinois, and St. Louis built new boats or modified steamboats for action. They took control of the Red, Tennessee, Cumberland, Mississippi, and Ohio rivers after victories at Fort Henry and Fort Donelson, and supplied Grant's forces as he moved into Tennessee. At Shiloh, (Pittsburg Landing) in Tennessee in April 1862, the Confederate made a surprise attack that pushed Union forces against the river as night fell. Overnight, the Navy landed additional reinforcements, and Grant counter-attacked. Grant and the Union won a decisive victory – the first battle with the high casualty rates that would repeat over and over.
Memphis fell to Union forces and became a key base for further advances south along the Mississippi River. In April 1862, US Naval forces under Farragut ran past Confederate defenses south of New Orleans. Confederates abandoned the city, which gave the Union a critical anchor in the deep South. Naval forces assisted Grant in his long, complex campaign that resulted in the surrender of Vicksburg in July 1863, and full Union control of the Mississippi soon after.
Eastern theater.
Because of the fierce resistance of a few initial Confederate forces at Manassas, Virginia, in July 1861, a march by Union troops under the command of Maj. Gen. Irvin McDowell on the Confederate forces there was halted in the First Battle of Bull Run, or "First Manassas", Roving Confederate bands such as Quantrill's Raiders terrorized the countryside, striking both military installations and civilian settlements. 
By 1864, these violent activities harmed the nationwide anti-war movement organizing against the re-election of Lincoln. The "Sons of Liberty" and "Order of the American Knights" attacked pro-Union people, elected officeholders, and unarmed uniformed soldiers. These partisans could not be entirely driven out of the state of Missouri until an entire regular Union infantry division was engaged. Missouri not only stayed in the Union, Lincoln took 70 percent of the vote for re-election. 
Areas south and west of Missouri saw numerous small-scale military actions which sought to control Indian Territory and New Mexico Territory for the Union. Confederate incursions into New Mexico were repulsed in 1862, the exiled Arizona government withdrew into Texas. In the Indian Territory, civil war broke out inside the tribes. About 12,000 Indian warriors fought for the Confederacy, and smaller numbers for the Union. The most prominent Cherokee was Brigadier General Stand Watie, the last Confederate general to surrender.
After the fall of Vicksburg in July 1863, General Kirby Smith in Texas was informed by Jefferson Davis that he could expect no further help from east of the Mississippi River. Although he lacked resources to beat Union armies, he built up a formidable arsenal at Tyler, along with his own Kirby Smithdom economy, a virtual "independent fiefdom" in Texas, including railroad construction and international smuggling. The Union in turn did not directly engage him. Its 1864 Red River Campaign to take Shreveport, Louisiana was a failure and Texas remained in Confederate hands throughout the war.
End of war.
Conquest of Virginia.
At the beginning of 1864, Lincoln made Grant commander of all Union armies. Grant made his headquarters with the Army of the Potomac, and put Maj. Gen. William Tecumseh Sherman in command of most of the western armies. Grant understood the concept of total war and believed, along with Lincoln and Sherman, that only the utter defeat of Confederate forces and their economic base would end the war. On June 23, 1865, Cherokee leader Stand Watie was the last Confederate General to surrender his forces.
Diplomacy.
Europe in the 1860s was more fragmented than it had been since before the American Revolution. France was in a weakened state while Britain was still shocked by their poor performance in the Crimean War. Civil War historian Shelby Foote expressed this view succinctly: "I think that the North fought that war with one hand behind its back...If there had been more Southern victories, and a lot more, the North simply would have brought that other hand out from behind its back. I don't think the South ever had a chance to win that War."
One reason for the high number of battle deaths during the war was the use of Napoleonic tactics, such as charging. With the advent of more accurate rifled barrels, Minié balls and (near the end of the war for the Union army) repeating firearms such as the Spencer Repeating Rifle and the Henry Repeating Rifle, soldiers were mowed down when standing in lines in the open. This led to the adoption of trench warfare, a style of fighting that defined the better part of World War I.
The wealth amassed in slaves and slavery for the Confederacy's 3.5 million blacks effectively ended when Union armies arrived; they were nearly all freed by the Emancipation Proclamation. Slaves in the border states and those located in some former Confederate territory occupied prior to the Emancipation Proclamation were freed by state action or (on December 18, 1865) by the Thirteenth Amendment. 
The war destroyed much of the wealth that had existed in the South. All accumulated investment in Confederate bonds was forfeit. Income per person in the South dropped to less than 40% than that of the North, a condition which lasted until well into the 20th century. Southern influence in the US federal government, previously considerable, was greatly diminished until the latter half of the 20th century. About 190,000 volunteered, further enhancing the numerical advantage the Union armies enjoyed over the Confederates, who did not dare emulate the equivalent manpower source for fear of fundamentally undermining the legitimacy of slavery.
During the Civil War, sentiment concerning slaves, enslavement and emancipation in the United States was divided. In 1861, Lincoln worried that premature attempts at emancipation would mean the loss of the border states, and that "to lose Kentucky is nearly the same as to lose the whole game." Copperheads and some War Democrats opposed emancipation, although the latter eventually accepted it as part of total war needed to save the Union. 
At first, Lincoln reversed attempts at emancipation by Secretary of War Simon Cameron and Generals John C. Frémont (in Missouri) and David Hunter (in South Carolina, Georgia and Florida) to keep the loyalty of the border states and the War Democrats. Lincoln warned the border states that a more radical type of emancipation would happen if his gradual plan based on compensated emancipation and voluntary colonization was rejected. But only the District of Columbia accepted Lincoln's gradual plan, which was enacted by Congress. When Lincoln told his cabinet about his proposed emancipation proclamation, Seward advised Lincoln to wait for a victory before issuing it, as to do otherwise would seem like "our last shriek on the retreat". Lincoln laid the groundwork for public support in an open letter published letter to abolitionist Horace Greeley’s newspaper.
In September 1862, the Battle of Antietam provided this opportunity, and the subsequent War Governors' Conference added support for the proclamation. Lincoln issued his preliminary Emancipation Proclamation on September 22, 1862, and his final Emancipation Proclamation on January 1, 1863. In his letter to Hodges, Lincoln explained his belief that "If slavery is not wrong, nothing is wrong ... And yet I have never understood that the Presidency conferred upon me an unrestricted right to act officially upon this judgment and feeling ... I claim not to have controlled events, but confess plainly that events have controlled me." 
Lincoln's moderate approach succeeded in getting border states, War Democrats and emancipated slaves fighting on the same side for the Union. The Union-controlled border states (Kentucky, Missouri, Maryland, Delaware and West Virginia) and Union controlled regions around New Orleans, Norfolk and elsewhere, were not covered by the Emancipation Proclamation. All abolished slavery on their own, except Kentucky and Delaware. 
Since the Emancipation Proclamation was based on the President's war powers, it only included territory held by Confederates at the time. However, the Proclamation became a symbol of the Union's growing commitment to add emancipation to the Union's definition of liberty. The Emancipation Proclamation greatly reduced the Confederacy's hope of getting aid from Britain or France. By late 1864, Lincoln was playing a leading role in getting Congress to vote for the Thirteenth Amendment, which made emancipation universal and permanent.
Reconstruction.
Reconstruction began during the war, with the Emancipation Proclamation of January 1, 1863 and continued to 1877. It comprised multiple complex methods to resolve the war, the most important of which were the three "Reconstruction Amendments" to the Constitution which remain in effect to the present time: the 13th (1865), the 14th (1868) and the 15th (1870). From the Union perspective, the goals of Reconstruction were to guarantee the Union victory on the battlefield by reuniting the Union; to guarantee a "republican form of government for the ex-Confederate states; and to permanently end slavery--and prevent semi-slavery status.
President Johnson took a lenient approach and saw the achievement of the main war goals as realized in 1865, when each ex-rebel state repudiated secession and ratified the Thirteenth Amendment. Radical Republicans, led by Thaddeus Stevens and Charles Sumner, took a much more skeptical view. They came to the fore after the 1866 elections and undid much of Johnson's work. They used the Army to dissolve Southern state governments and hold new elections with Freedmen voting. The result was a Republican coalition that took power in ten states for varying lengths of time, staying in power with the help of U.S. Army units. Meanwhile the Freedman's Bureau, part of the Army, played a major role in helping the blacks, while paramilitary groups such as the first Ku Klux Klan used violence to thwart these efforts.
The "Liberal Republicans", who argued the war goals had been achieved and Reconstruction should end, ran a ticket in 1872 but were decisively defeated when Grant was reelected. In 1874 Democrats took control of Congress and opposed reconstruction. The disputed 1876 election was resolved by the Compromise of 1877 which put Republican Rutherford B. Hayes in the White House. He pulled out the last federal troops and the last Republican state governments in the South collapsed; historians consider it the end of the Civil War and Reconstruction era.
Memory and historiography.
The Civil War is one of the central events in America's collective memory. There are innumerable statues, commemorations, books and archival collections. The memory includes the home front, military affairs, the treatment of soldiers, both living and dead, in the war's aftermath, depictions of the war in literature and art, evaluations of heroes and villains, and considerations of the moral and political lessons of the war. The last theme includes moral evaluations of racism and slavery, heroism in combat and behind the lines, and the issues of democracy and minority rights, as well as the notion of an "Empire of Liberty" influencing the world. Memory of the war in the white South crystallized in the myth of the "Lost Cause", which shaped regional identity and race relations for generations.
150th anniversary.
The year 2011 included the American Civil War's 150th anniversary. Many in the South attempted to incorporate both black history and white perspectives. A Harris Poll given in March 2011 suggested that Americans were still uniquely divided over the results and appropriate memorials to acknowledge the occasion. While traditionally American films of the Civil War feature "brother versus brother" themes film treatments of the war are evolving to include African American characters. Benard Simelton, president of the Alabama NAACP, said celebrating the Civil War is like celebrating the "Holocaust". In reference to slavery, Simelton said that black "rights were taken away" and that blacks "were treated as less than human beings." National Park historian Bob Sutton said that slavery was the "principal cause" of the war. Sutton also claimed that the issue of state rights was incorporated by the Confederacy as a justification for the war in order to get recognition from Britain. Sutton went on to mention that during the 100th anniversary of the Civil War white southerners focused on the genius of southern generals, rather than slavery. In Virginia during the fall of 2010, a conference took place that addressed the slavery issue. During November 2010, black Civil War reenactors from around the country participated in a parade at Harrisburg, Pennsylvania.
Hollywood.
Hollywood's take on the war has been especially influential in shaping public memory, as seen in such films as "Birth of a Nation", "Gone with the Wind", and "Glory".
See also.
General reference 
Union (Federals) 
Confederacy (Rebels) 
Ethnic articles 
Topical articles 
National articles 
Commemorative articles 

</doc>
<doc id="864" url="http://it.wikipedia.org/wiki/?curid=864" title="Andy Warhol">
Andy Warhol

Andy Warhol (August 6, 1928 – February 22, 1987) was an American artist who was a leading figure in the visual art movement known as pop art. His works explore the relationship between artistic expression, celebrity culture and advertisement that flourished by the 1960s. After a successful career as a commercial illustrator, Warhol became a renowned and sometimes controversial artist. The Andy Warhol Museum in his native city, Pittsburgh, Pennsylvania, holds an extensive permanent collection of art and archives. It is the largest museum in the United States dedicated to a single artist.
Warhol's art encompassed many forms of media, including hand drawing, painting, printmaking, photography, silk screening, sculpture, film, and music. He was also a pioneer in computer-generated art using Amiga computers that were introduced in 1984, two years before his death. He founded "Interview Magazine" and was the author of numerous books, including "The Philosophy of Andy Warhol" and "". He is also notable as a gay man who lived openly as such before the gay liberation movement. His studio, The Factory, was a famous gathering place that brought together distinguished intellectuals, drag queens, playwrights, Bohemian street people, Hollywood celebrities, and wealthy patrons.
Warhol has been the subject of numerous retrospective exhibitions, books, and feature and documentary films. He coined the widely used expression "15 minutes of fame". Many of his creations are very collectible and highly valuable. The highest price ever paid for a Warhol painting is US$100 million for a 1963 canvas titled "Eight Elvises." The private transaction was reported in a 2009 article in "The Economist", which described Warhol as the "bellwether of the art market". Warhol's works include some of the most expensive paintings ever sold.
Early life (1928–1949).
Andy Warhol (né Andrej Varhola, Jr.) was born on August 6, 1928 in Pittsburgh, Pennsylvania. He was the fourth child of Ondrej Varhola (Americanized as Andrew Warhola, Sr., 1889–1942) and Júlia (née Zavacká, 1892–1972), whose first child was born in their homeland and died before their move to the U.S. Andy had two older brothers, Paul, born in 1923, and John, born in 1925.
His parents were working-class Lemko emigrants from Mikó (now called Miková), located in today’s northeastern Slovakia, part of the former Austro-Hungarian Empire. Warhol's father immigrated to the United States in 1914, and his mother joined him in 1921, after the death of Warhol's grandparents. Warhol's father worked in a coal mine. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. The family was Byzantine Catholic and attended St. John Chrysostom Byzantine Catholic Church. Andy Warhol had two older brothers—Pavol (Paul), the oldest, was born in Slovakia; Ján was born in Pittsburgh. Pavol's son, James Warhola, became a successful children's book illustrator. About 1939, he started to collect autographed cards of film stars.
In third grade, Warhol had Sydenham's chorea (also known as St. Vitus’ Dance), the nervous system disease that causes involuntary movements of the extremities, which is believed to be a complication of scarlet fever which causes skin pigmentation blotchiness. He became a hypochondriac, developing a fear of hospitals and doctors. Often bedridden as a child, he became an outcast at school and bonded with his mother. At times when he was confined to bed, he drew, listened to the radio and collected pictures of movie stars around his bed. Warhol later described this period as very important in the development of his personality, skill-set and preferences. When Warhol was 13, his father died in an accident.
As a teenager, Warhol graduated from Schenley High School in 1945. After graduating from high school, his intentions were to study art education at the University of Pittsburgh in the hope of becoming an art teacher, but his plans changed and he enrolled in the Carnegie Institute of Technology in pursuit of an art career as a commercial illustrator. In 1949, he earned a Bachelor of Fine Arts in Graphic Design.
Warhol was an early adopter of the silk screen printmaking process as a technique for making paintings. His earliest silkscreening in painting involved hand-drawn images though this soon progressed to the use of photographically derived silkscreening in paintings. Prior to entering the field of fine art, Warhol's commercial art background also involved innovative techniques for image making that were somewhat related to printmaking techniques. When rendering commercial objects for advertising Warhol devised a technique that resulted in a characteristic image. His imagery used in advertising was often executed by means of applying ink to paper and then blotting the ink while still wet. This was akin to a printmaking process on the most rudimentary scale. Warhol's work both as a commercial artist and later a fine artist displays a casual approach to image making, in which chance plays a role and mistakes and unintentional marks are tolerated. The resulting imagery in both Warhol's commercial art and later in his fine art endeavors is often replete with imperfection—smudges and smears can often be found. In his book "POPism" Warhol says, ""... when you do something exactly wrong, you always turn up something.""
1960s.
He began exhibiting his work during the 1950s. He held exhibitions at the Hugo Gallery, and the Bodley Gallery in New York City and in California his first West Coast gallery exhibition was on July 9, 1962, in the Ferus Gallery of Los Angeles. The exhibition marked his West Coast debut of pop art.
Andy Warhol's first New York solo pop art exhibition was hosted at Eleanor Ward's Stable Gallery November 6–24, 1962. The exhibit included the works "Marilyn Diptych", "100 Soup Cans", "100 Coke Bottles" and "100 Dollar Bills". At the Stable Gallery exhibit, the artist met for the first time poet John Giorno who would star in Warhol's first film, "Sleep", in 1963.
New York's Museum of Modern Art hosted a Symposium on pop art in December 1962 during which artists like Warhol were attacked for "capitulating" to consumerism. Critics were scandalized by Warhol's open embrace of market culture. This symposium set the tone for Warhol's reception. Throughout the decade it became increasingly clear that there had been a profound change in the culture of the art world, and that Warhol was at the center of that shift.
A pivotal event was the 1964 exhibit "The American Supermarket", a show held in Paul Bianchini's Upper East Side gallery. The show was presented as a typical U.S. small supermarket environment, except that everything in it—from the produce, canned goods, meat, posters on the wall, etc.—was created by six prominent pop artists of the time, among them the controversial (and like-minded) Billy Apple, Mary Inman, and Robert Watts. Warhol's painting of a can of Campbell's soup cost $1,500 while each autographed can sold for $6. The exhibit was one of the first mass events that directly confronted the general public with both pop art and the perennial question of what art is.
As an advertisement illustrator in the 1950s, Warhol used assistants to increase his productivity. Collaboration would remain a defining (and controversial) aspect of his working methods throughout his career; this was particularly true in the 1960s. One of the most important collaborators during this period was Gerard Malanga. Malanga assisted the artist with the production of silkscreens, films, sculpture, and other works at "The Factory," Warhol's aluminum foil-and-silver-paint-lined studio on 47th Street (later moved to Broadway). Other members of Warhol's Factory crowd included Freddie Herko, Ondine, Ronald Tavel, Mary Woronov, Billy Name, and Brigid Berlin (from whom he apparently got the idea to tape-record his phone conversations).
During the 1960s, Warhol also groomed a retinue of bohemian eccentrics upon whom he bestowed the designation "Superstars", including Nico, Joe Dallesandro, Edie Sedgwick, Viva, Ultra Violet, Holly Woodlawn, Jackie Curtis and Candy Darling. These people all participated in the Factory films, and some—like Berlin—remained friends with Warhol until his death. Important figures in the New York underground art/cinema world, such as writer John Giorno and film-maker Jack Smith, also appear in Warhol films of the 1960s, revealing Warhol's connections to a diverse range of artistic scenes during this time.
Attempted murder (1968).
On June 3, 1968, Valerie Solanas shot Warhol and Mario Amaya, art critic and curator, at Warhol's studio. Before the shooting, Solanas had been a marginal figure in the Factory scene. She authored the "S.C.U.M. Manifesto", a separatist feminist attack on males. Solanas appears in the 1968 Warhol film "I, a Man". Earlier on the day of the attack, Solanas had been turned away from the Factory after asking for the return of a script she had given to Warhol. The script had apparently been misplaced.
Amaya received only minor injuries and was released from the hospital later the same day. Warhol, however, was seriously wounded by the attack and barely survived: surgeons opened his chest and massaged his heart to help stimulate its movement again. He suffered physical effects for the rest of his life, including being required to wear a surgical corset.
Solanas was arrested the day after the assault. By way of explanation, she said that Warhol "had too much control over my life." She was eventually sentenced to three years under the control of the Department of Corrections. After the shooting, the Factory scene became much more tightly controlled, and for many the "Factory 60s" ended.
1970s.
Compared to the success and scandal of Warhol's work in the 1960s, the 1970s were a much quieter decade, as he became more entrepreneurial. According to Bob Colacello, Warhol devoted much of his time to rounding up new, rich patrons for portrait commissions—including Shah of Iran Mohammad Reza Pahlavi, his wife Empress Farah Pahlavi, his sister Princess Ashraf Pahlavi, Mick Jagger, Liza Minnelli, John Lennon, Diana Ross, and Brigitte Bardot. Warhol's famous portrait of Chinese Communist leader Mao Zedong was created in 1973. He also founded, with Gerard Malanga, "Interview" magazine, and published "The Philosophy of Andy Warhol" (1975). An idea expressed in the book: "Making money is art, and working is art and good business is the best art." 
Warhol used to socialize at various nightspots in New York City, including Max's Kansas City; and, later in the 1970s, Studio 54. He was generally regarded as quiet, shy, and a meticulous observer. Art critic Robert Hughes called him "the white mole of Union Square."
With his longtime friend Stuart Pivar, Warhol founded the New York Academy of Art in 1979.
1980s.
Warhol had a re-emergence of critical and financial success in the 1980s, partially due to his affiliation and friendships with a number of prolific younger artists, who were dominating the "bull market" of 1980s New York art: Jean-Michel Basquiat, Julian Schnabel, David Salle and other so-called Neo-Expressionists, as well as members of the Transavantgarde movement in Europe, including Francesco Clemente and Enzo Cucchi.
By this period, Warhol was being criticized for becoming merely a "business artist". In 1979, reviewers disliked his exhibits of portraits of 1970s personalities and celebrities, calling them superficial, facile and commercial, with no depth or indication of the significance of the subjects. They also criticized his 1980 exhibit of 10 portraits at the Jewish Museum in New York, entitled "Jewish Geniuses", which Warhol—who was uninterested in Judaism and Jews—had described in his diary as "They're going to sell."
Death.
Warhol died in New York City at 6:32 am on February 22, 1987. According to news reports, he had been making good recovery from a routine gallbladder surgery at New York Hospital before dying in his sleep from a sudden post-operative cardiac arrhythmia. Prior to his diagnosis and operation, Warhol delayed having his recurring gallbladder problems checked, as he was afraid to enter hospitals and see doctors. His family sued the hospital for inadequate care, saying that the arrhythmia was caused by improper care and water intoxication.
Warhol's body was taken back to Pittsburgh by his brothers for burial. The wake was at Thomas P. Kunsak Funeral Home and was an open-coffin ceremony. The coffin was a solid bronze casket with gold plated rails and white upholstery. Warhol was dressed in a black cashmere suit, a paisley tie, a platinum wig, and sunglasses. He was posed holding a small prayer book and a red rose. The funeral liturgy was held at the Holy Ghost Byzantine Catholic Church on Pittsburgh's North Side. The eulogy was given by Monsignor Peter Tay. Yoko Ono, and John Richardson were speakers. The coffin was covered with white roses and asparagus ferns. After the liturgy, the coffin was driven to St. John the Baptist Byzantine Catholic Cemetery in Bethel Park, a south suburb of Pittsburgh.
At the grave, the priest said a brief prayer and sprinkled holy water on the casket. Before the coffin was lowered, Paige Powell dropped a copy of "Interview" magazine, an "Interview" t-shirt, and a bottle of the Estee Lauder perfume "Beautiful" into the grave. Warhol was buried next to his mother and father. A memorial service was held in Manhattan for Warhol on April 1, 1987, at St. Patrick's Cathedral, New York.
Warhol's will dictated that his entire estate—with the exception of a few modest legacies to family members—would go to create a foundation dedicated to the "advancement of the visual arts". Warhol had so many possessions that it took Sotheby's nine days to auction his estate after his death; the auction grossed more than US$20 million.
In 1987, in accordance with Warhol's will, the Andy Warhol Foundation for the Visual Arts began. The Foundation serves as the official Estate of Andy Warhol, but also has a mission "to foster innovative artistic expression and the creative process" and is "focused primarily on supporting work of a challenging and often experimental nature."
The Artists Rights Society is the U.S. copyright representative for the Andy Warhol Foundation for the Visual Arts for all Warhol works with the exception of Warhol film stills. The U.S. copyright representative for Warhol film stills is the Warhol Museum in Pittsburgh. Additionally, the Andy Warhol Foundation for the Visual Arts has agreements in place for its image archive. All digital images of Warhol are exclusively managed by Corbis, while all transparency images of Warhol are managed by Art Resource.
The Andy Warhol Foundation released its 20th Anniversary Annual Report as a three-volume set in 2007: Vol. I, 1987–2007; Vol. II, Grants  Exhibitions; and Vol. III, Legacy Program. The Foundation remains one of the largest grant-giving organizations for the visual arts in the U.S.
Works.
Paintings.
By the beginning of the 1960s, Warhol had become a very successful commercial illustrator. His detailed and elegant drawings for I. Miller shoes were particularly popular. They consisted mainly of "blotted ink" drawings (or monoprints), a technique which he applied in much of his early art. Although many artists of this period worked in commercial art, most did so discreetly. Warhol was so successful, however, that his profile as an illustrator seemed to undermine his efforts to be taken seriously as an artist.
Pop art was an experimental form that several artists were independently adopting; some of these pioneers, such as Roy Lichtenstein, would later become synonymous with the movement. Warhol, who would become famous as the "Pope of Pop", turned to this new style, where popular subjects could be part of the artist's palette. His early paintings show images taken from cartoons and advertisements, hand-painted with paint drips. Marilyn Monroe was a pop art painting that Warhol had done and it was very popular. Those drips emulated the style of successful abstract expressionists (such as Willem de Kooning). Warhol's first pop art paintings were displayed in April 1961, serving as the backdrop for New York Department Store Bronwit Teller's window display. This was the same stage his Pop Art contemporaries Jasper Johns, James Rosenquist and Robert Rauschenberg had also once graced. Eventually, Warhol pared his image vocabulary down to the icon itself—to brand names, celebrities, dollar signs—and removed all traces of the artist's "hand" in the production of his paintings.
To him, part of defining a niche was defining his subject matter. Cartoons were already being used by Lichtenstein, typography by Jasper Johns, and so on; Warhol wanted a distinguishing subject. His friends suggested he should paint the things he loved the most. It was the gallerist Muriel Latow who came up with the ideas for both the soup cans and Warhol's dollar paintings. On November 23, 1961 Warhol wrote Latow a check for $50 which, according to the 2009 Warhol biography, "Pop, The Genius of Warhol", was payment for coming up with the idea of the soup cans as subject matter.
For his first major exhibition Warhol painted his famous cans of Campbell's Soup, which he claimed to have had for lunch for most of his life. The work sold for $10,000 at an auction on November 17, 1971, at Sotheby's New York—a minimal amount for the artist whose paintings sell for over $6 million more recently.
He loved celebrities, so he painted them as well. From these beginnings he developed his later style and subjects. Instead of working on a signature subject matter, as he started out to do, he worked more and more on a signature style, slowly eliminating the handmade from the artistic process. Warhol frequently used silk-screening; his later drawings were traced from slide projections. At the height of his fame as a painter, Warhol had several assistants who produced his silk-screen multiples, following his directions to make different versions and variations.
In 1979, Warhol was commissioned by BMW to paint a Group 4 race version of the then elite supercar BMW M1 for the fourth installment in the BMW Art Car Project. Unlike the three artists before him, Warhol declined the use of a small scale practice model, instead opting to immediately paint directly onto the full scale automobile. It was indicated that Warhol spent only a total of 23 minutes to paint the entire car.
Warhol produced both comic and serious works; his subject could be a soup can or an electric chair. Warhol used the same techniques—silkscreens, reproduced serially, and often painted with bright colors—whether he painted celebrities, everyday objects, or images of suicide, car crashes, and disasters, as in the 1962–1963 "Death and Disaster" series. The "Death and Disaster" paintings included "Red Car Crash", "Purple Jumping Man", and "Orange Disaster."
The unifying element in Warhol's work is his deadpan Keatonesque style—artistically and personally affectless. This was mirrored by Warhol's own demeanor, as he often played "dumb" to the media, and refused to explain his work. The artist was famous for having said that all you need to know about him and his works is already there, "Just look at the surface of my paintings and films and me, and there I am. There's nothing behind it."
Warhol's first portrait of "Basquiat" (1982) is a black photosilkscreen over an oxidized copper "piss painting".
After many years of silkscreen, oxidation, photography, etc., Warhol returned to painting with a brush in hand in a series of over 50 large collaborative works done with Jean-Michel Basquiat between 1984 and 1986. Despite negative criticism when these were first shown, Warhol called some of them "masterpieces," and they were influential for his later work.
The influence of the large collaborations with Basquiat can be seen in Warhol's "The Last Supper" cycle, his last and possibly his largest series, seen by some as "arguably his greatest," but by others as “wishy-washy, religiose” and “spiritless." It is also the largest series of religious-themed works by any U.S. artist.
A self-portrait by Andy Warhol (1963–1964), which sold in New York at the May Post-War and Contemporary evening sale in Christie's, fetched $38.4 million.
On May 9, 2012, his classic painting "Double Elvis (Ferus Type)" sold at auction at Sotheby's in New York for US$33 million dollars. With commission, the sale price totaled US$37,042,500, short of the $50 million that Sotheby's had predicted the painting might bring. The piece (silkscreen ink and spray paint on canvas) shows Elvis Presley in a gunslinger pose. It was first exhibited in 1963 at the Ferus Gallery in Los Angeles. Warhol made 22 versions of the "Double Elvis," nine of which are held in museums.
Films.
Warhol worked across a wide range of media—painting, photography, drawing, and sculpture. In addition, he was a highly prolific filmmaker. Between 1963 and 1968, he made more than 60 films, plus some 500 short black-and-white "screen test" portraits of Factory visitors. One of his most famous films, "Sleep", monitors poet John Giorno sleeping for six hours. The 35-minute film "Blow Job" is one continuous shot of the face of DeVeren Bookwalter supposedly receiving oral sex from filmmaker Willard Maas, although the camera never tilts down to see this. Another, "Empire" (1964), consists of eight hours of footage of the Empire State Building in New York City at dusk. The film "Eat" consists of a man eating a mushroom for 45 minutes. Warhol attended the 1962 premiere of the static composition by LaMonte Young called "Trio for Strings" and subsequently created his famous series of static films including "Kiss", "Eat", and "Sleep" (for which Young initially was commissioned to provide music). Uwe Husslein cites filmmaker Jonas Mekas, who accompanied Warhol to the Trio premiere, and who claims Warhol's static films were directly inspired by the performance.
"Batman Dracula" is a 1964 film that was produced and directed by Warhol, without the permission of DC Comics. It was screened only at his art exhibits. A fan of the Batman series, Warhol's movie was an "homage" to the series, and is considered the first appearance of a blatantly campy Batman. The film was until recently thought to have been lost, until scenes from the picture were shown at some length in the 2006 documentary "Jack Smith and the Destruction of Atlantis".
Warhol's 1965 film "Vinyl" is an adaptation of Anthony Burgess' popular dystopian novel "A Clockwork Orange". Others record improvised encounters between Factory regulars such as Brigid Berlin, Viva, Edie Sedgwick, Candy Darling, Holly Woodlawn, Ondine, Nico, and Jackie Curtis. Legendary underground artist Jack Smith appears in the film "Camp".
His most popular and critically successful film was "Chelsea Girls" (1966). The film was highly innovative in that it consisted of two 16 mm-films being projected simultaneously, with two different stories being shown in tandem. From the projection booth, the sound would be raised for one film to elucidate that "story" while it was lowered for the other. The multiplication of images evoked Warhol's seminal silk-screen works of the early 1960s.
Other important films include "Bike Boy", "My Hustler", and "Lonesome Cowboys", a raunchy pseudo-western. These and other titles document gay underground and camp culture, and continue to feature prominently in scholarship about sexuality and art. "Blue Movie"—a film in which Warhol superstar Viva makes love and fools around in bed with a man for 33 minutes of the film's playing-time—was Warhol's last film as director. The film was at the time scandalous for its frank approach to a sexual encounter. For many years Viva refused to allow it to be screened. It was publicly screened in New York in 2005 for the first time in over thirty years.
After his June 3, 1968, shooting, a reclusive Warhol relinquished his personal involvement in filmmaking. His acolyte and assistant director, Paul Morrissey, took over the film-making chores for the Factory collective, steering Warhol-branded cinema towards more mainstream, narrative-based, B-movie exploitation fare with "Flesh", "Trash", and "Heat". All of these films, including the later "Andy Warhol's Dracula" and "Andy Warhol's Frankenstein", were far more mainstream than anything Warhol as a director had attempted. These latter "Warhol" films starred Joe Dallesandro—more of a Morrissey star than a true Warhol superstar.
In the early 1970s, most of the films directed by Warhol were pulled out of circulation by Warhol and the people around him who ran his business. After Warhol's death, the films were slowly restored by the Whitney Museum and are occasionally projected at museums and film festivals. Few of the Warhol-directed films are available on video or DVD.
Music.
In the mid-1960s, Warhol adopted the band the Velvet Underground, making them a crucial element of the Exploding Plastic Inevitable multimedia performance art show. Warhol, with Paul Morrissey, acted as the band's manager, introducing them to Nico (who would perform with the band at Warhol's request). In 1966 he "produced" their first album "The Velvet Underground  Nico", as well as providing its album art. His actual participation in the album's production amounted to simply paying for the studio time. After the band's first album, Warhol and band leader Lou Reed started to disagree more about the direction the band should take, and their artistic friendship ended. In 1989, after Warhol's death, Reed and John Cale re-united for the first time since 1972 to write, perform, record and release the concept album "Songs for Drella", a tribute to Warhol.
Warhol designed many album covers for various artists starting with the photographic cover of John Wallowitch's debut album, "This Is John Wallowitch!!!" (1964). He designed the cover art for the Rolling Stones albums "Sticky Fingers" (1971) and "Love You Live" (1977), and the John Cale albums "The Academy in Peril" (1972) and "Honi Soit" in 1981. In 1975, Warhol was commissioned to do several portraits of Mick Jagger, and in 1982 he designed the album cover for the Diana Ross album Silk Electric. One of his last works was a portrait of Aretha Franklin for the cover of her 1986 gold album "Aretha", which was done in the style of the "Reigning Queens" series he had completed the year before.
Warhol strongly influenced the New Wave/punk rock band Devo, as well as David Bowie. Bowie recorded a song called "Andy Warhol" for his 1971 album "Hunky Dory". Lou Reed wrote the song "Andy's Chest", about Valerie Solanas, the woman who shot Warhol, in 1968. He recorded it with the Velvet Underground, and this version was released on the VU album in 1985.
Books and print.
Beginning in the early 1950s, Warhol produced several unbound portfolios of his work.
The first of several bound self-published books by Warhol was "25 Cats Name Sam and One Blue Pussy", printed in 1954 by Seymour Berlin on Arches brand watermarked paper using his blotted line technique for the lithographs. The original edition was limited to 190 numbered, hand colored copies, using Dr. Martin's ink washes. Most of these were given by Warhol as gifts to clients and friends. Copy No. 4, inscribed "Jerry" on the front cover and given to Geraldine Stutz, was used for a facsimile printing in 1987 and the original was auctioned in May 2006 for US $35,000 by Doyle New York.
Warhol created the fashion magazine "Interview" that is still published today. The loopy title script on the cover is thought to be either his own handwriting or that of his mother, Julia Warhola, who would often do text work for his early commercial pieces.
Other media.
Although Andy Warhol is most known for his paintings and films, he authored works in many different media.
Producer and product.
Warhol had assistance in producing his paintings. This is also true of his film-making and commercial enterprises.
He founded the gossip magazine "Interview", a stage for celebrities he "endorsed" and a business staffed by his friends. He collaborated with others on all of his books (some of which were written with Pat Hackett.) He adopted the young painter Jean-Michel Basquiat, and the band The Velvet Underground, presenting them to the public as his latest interest, and collaborating with them. One might even say that he produced people (as in the Warholian "Superstar" and the Warholian portrait). He endorsed products, appeared in commercials, and made frequent celebrity guest appearances on television shows and in films (he appeared in everything from "Love Boat" to "Saturday Night Live" and the Richard Pryor movie, "Dynamite Chicken").
In this respect Warhol was a fan of "Art Business" and "Business Art"—he, in fact, wrote about his interest in thinking about art as business in "The Philosophy of Andy Warhol from A to B and Back Again".
Personal life.
Sexuality.
Warhol was gay. When interviewed in 1980, he indicated that he was still a virgin—biographer Bob Colacello who was present at the interview felt it was probably true and that what little sex he had was probably "a mixture of voyeurism and masturbation—to use his [Andy's] word "abstract"". Warhol's assertion of virginity would seem to be contradicted by an incident recounted by one biographer, his hospital treatment in 1960 for condylomata, a sexually transmitted disease. The fact that Warhol's homosexuality influenced his work and shaped his relationship to the art world is a major subject of scholarship on the artist and is an issue that Warhol himself addressed in interviews, in conversation with his contemporaries, and in his publications ("e.g.", "Popism: The Warhol 1960s"). Throughout his career, Warhol produced erotic photography and drawings of male nudes. Many of his most famous works (portraits of Liza Minnelli, Judy Garland, and Elizabeth Taylor, and films like "Blow Job," "My Hustler" and "Lonesome Cowboys") draw from gay underground culture and/or openly explore the complexity of sexuality and desire. As has been addressed by a range of scholars, many of his films premiered in gay porn theaters. The first works that he submitted to a fine art gallery, homoerotic drawings of male nudes, were rejected for being too openly gay. In "Popism", furthermore, the artist recalls a conversation with the film maker Emile de Antonio about the difficulty Warhol had being accepted socially by the then more famous (but closeted) gay artists Jasper Johns and Robert Rauschenberg. De Antonio explained that Warhol was "too swish and that upsets them." In response to this, Warhol writes, "There was nothing I could say to that. It was all too true. So I decided I just wasn't going to care, because those were all the things that I didn't want to change anyway, that I didn't think I 'should' want to change... Other people could change their attitudes but not me". In exploring Warhol's biography, many turn to this period—the late 1950s and early 1960s—as a key moment in the development of his persona. Some have suggested that his frequent refusal to comment on his work, to speak about himself (confining himself in interviews to responses like "Um, no" and "Um, yes", and often allowing others to speak for him)—and even the evolution of his pop style—can be traced to the years when Warhol was first dismissed by the inner circles of the New York art world.
Religious beliefs.
Warhol was a practicing Ruthenian Rite Catholic. He regularly volunteered at homeless shelters in New York, particularly during the busier times of the year, and described himself as a religious person. Many of Warhol's later works depicted religious subjects, including two series, "Details of Renaissance Paintings" (1984) and "The Last Supper" (1986). In addition, a body of religious-themed works was found posthumously in his estate.
Movies about Warhol.
In 1979, Warhol appeared as himself in the film "Cocaine Cowboys".
After his death, Warhol was portrayed by Crispin Glover in Oliver Stone's film "The Doors" (1991), by David Bowie in "Basquiat", a film by Julian Schnabel, and by Jared Harris in the film "I Shot Andy Warhol" directed by Mary Harron (1996). Warhol appears as a character in Michael Daugherty's 1997 opera "Jackie O". Actor Mark Bringleson makes a brief cameo as Warhol in "" (1997). Many films by avant-garde cineast Jonas Mekas have caught the moments of Andy's life. Sean Gregory Sullivan depicted Warhol in the 1998 film "54". Guy Pearce portrayed Warhol in the 2007 film, "Factory Girl", about Edie Sedgwick's life. Actor Greg Travis portrays Warhol in a brief scene from the 2009 film "Watchmen". In the 2012 film Men in Black III Andy Warhol turns out to really be undercover MIB Agent W (played by Bill Hader). Warhol is throwing a party at The Factory in 1969, where he is looked up by MIB Agents K and J (J from the future). Agent W is desperate to end his undercover job ( "I'm so out of ideas I'm painting soup cans and bananas, for Christ sakes!" and "You gotta fake my death, okay? I can't listen to sitar music anymore.")
Gus Van Sant was planning a version of Warhol's life with River Phoenix in the lead role just before Phoenix's death in 1993.

</doc>
<doc id="868" url="http://it.wikipedia.org/wiki/?curid=868" title="Alp Arslan">
Alp Arslan

Alp Arslan (Persian: آلپ ارسلان; full name: "Diya ad-Dunya wa ad-Din Adud ad-Dawlah Abu Shuja Muhammad Alp Arslan ibn Dawud") (20 January 1029 – 15 December 1072) was the second Sultan of the Seljuq Empire and great-grandson of Seljuq, the eponymous founder of the dynasty. His real name was "Muhammad bin Dawud Chaghri", and for his military prowess, personal valour, and fighting skills he obtained the surname "Alp Arslan", which means "Heroic Lion" in Turkish.
Career.
He succeeded his father Çağrı Bey as governor of Khorasan in 1059. When his uncle Tughril died he was succeeded by Suleiman, Alp Arslan's brother. Alp Arslan and his uncle Kutalmish both contested this succession. Alp Arslan defeated Kutalmish for the throne and succeeded on 27 April 1064 as sultan of Great Seljuq, and thus became sole monarch of Persia from the river Oxus to the Tigris.
In consolidating his empire and subduing contending factions he was ably assisted by Nizam ul-Mulk, his vizier, and one of the most eminent statesmen in early Muslim history. With peace and security established in his dominions, he convoked an assembly of the states and declared his son Malik Shah I his heir and successor. With the hope of capturing Caesarea Mazaca, the capital of Cappadocia, he placed himself at the head of the Turkish cavalry, crossed the Euphrates and entered and invaded the city. He then marched into Armenia and Georgia, which he conquered in 1064.
Byzantine struggle.
In 1068, en route to Syria, Alp Arslan Oush invaded the Byzantine Empire. The Emperor Romanos IV Diogenes, assuming the command in person, met the invaders in Cilicia. In three arduous campaigns, the first two of which were conducted by the emperor himself while the third was directed by Manuel Comnenos (great-uncle of Emperor Manuel Comnenos), the Turks were defeated in detail in 1070 and driven across the Euphrates. In 1071 Romanos again took the field and advanced with possibly 30,000 men, including a contingent of the Cuman Turks as well as contingents of Franks and Normans, under Ursel de Baieul, into Armenia.
At Manzikert, on the Murat River, north of Lake Van, Diogenes was met by Alp Arslan. The sultan proposed terms of peace, which were rejected by the emperor, and the two forces met in the Battle of Manzikert. The Cuman mercenaries among the Byzantine forces immediately defected to the Turkish side; and, seeing this, "the Western mercenaries rode off and took no part in the battle." The Byzantines were totally routed.
Alp Arslan's victories changed the balance in near Asia completely in favour of the Seljuq Turks and Sunni Muslims. While the Byzantine Empire was to continue for nearly another four centuries, and the Crusades would contest the issue for some time, the victory at Manzikert signalled the beginning of Turkish ascendancy in Anatolia. Most historians, including Edward Gibbon, date the defeat at Manzikert as the beginning of the end of the Eastern Roman Empire. Certainly the entry of Turkic farmers following their horsemen ended the themes in Anatolia which had furnished the Empire with men and treasure.
State organization.
Alp Arslan's strength lay in the military realm. Domestic affairs were handled by his able vizier, Nizam al-Mulk, the founder of the administrative organization which characterized and strengthened the sultanate during the reigns of Alp Arslan and his son, Malik Shah. Military fiefs, governed by Seljuq princes, were established to provide support for the soldiery and to accommodate the nomadic Turks to the established Anatolian agricultural scene. This type of military fiefdom enabled the nomadic Turks to draw on the resources of the sedentary Persians, Turks and other established cultures within the Seljuq realm, and allowed Alp Arslan to field a huge standing army, without depending on tribute from conquest to pay his soldiery. He not only had enough food from his subjects to maintain his military, but the taxes collected from traders and merchants added to his coffers sufficiently to fund his continuous wars.
According to the poet Saadi Shirazi: "Arslan possessed a fort, which raised at the height of Alwand, from all were those within its walls, for its roads were a labyrinth, like the curls of a bride. From a learned traveler Arslan once inquired: "Didst thou ever, in thy wanderings, see a fort as strong as this?". "Splendid it is," was the travelers reply, "but methinks not it confers much strength. Before thee, did not other kings possess it for a while, then pass away? After thee, will not other kings assume control, and eat the fruits of the tree of thy hope?""
"In the estimation of the wise, the world is a false gem that passes each moment from one hand to another." (the fort was sacked by the Mongols led by Hulagu).
Suleiman ibn Kutalmish was the son of the contender for Arslan's throne; he was appointed governor of the north-western provinces and assigned to completing invasion of Anatolia. An explanation for this choice can only be conjectured from Ibn al-Athir’s account of the battle between Alp-Arslan and Kutalmish, in which he writes that Alp-Arslan wept for the latter's death and greatly mourned the loss of his kinsman.
Death.
As he lay dying, Alp Arslan whispered to his son that his vanity had killed him. "Alas," he is recorded to have said, "surrounded by great warriors devoted to my cause, guarded night and day by them, I should have allowed them to do their job. I had been warned against trying to protect myself, and against letting my courage get in the way of my good sense. I forgot those warnings, and here I lie, dying in agony. Remember well the lessons learned, and do not allow your vanity to overreach your good sense..."
Legacy.
Alp Arslan's conquest of Anatolia from the Byzantines is also seen as one of the pivotal precursors to the launch of the crusades.
From 2002 to July 2008 under Turkmen calendar reform, the month of August was named after Alp Arslan.

</doc>
<doc id="869" url="http://it.wikipedia.org/wiki/?curid=869" title="American Film Institute">
American Film Institute

The American Film Institute (AFI) is an independent non-profit organization created by the National Endowment for the Arts, which was established in 1967 when President Lyndon B. Johnson signed the National Foundation on the Arts and the Humanities Act.
The American Film Institute operated the National Film Theatre in Washington D.C.'s Kennedy Center until 1998. Prior to Kennedy Center, it screened films in the auditorium of the National Gallery of Art. In April 2003, AFI re-opened the 1938 AFI Silver theatre in Silver Spring, Maryland just north of Washington.
History.
The American Film Institute was founded in 1967 as a national arts organization to preserve the legacy of American film heritage, educate the next generation of filmmakers and honor the artists and their work. The National Endowment for the Arts and Humanities recommended creating AFI “to enrich and nurture the art of film in America” with initial funding from the National Endowment for the Arts, the Motion Picture Association of America and the Ford Foundation. The original 22-member Board of Trustees included Chair Gregory Peck and Vice Chair Sidney Poitier as well as Francis Ford Coppola, Arthur Schlesinger, Jr., Jack Valenti and other representatives from the arts and academia. In addition, Ten Moments of Significance, documenting the year’s media milestones, are entered into an ongoing almanac.
AFI 100 Years… series.
The popular AFI 100 Years… series, which ran from 1998 to 2008, and created jury-selected lists of America’s best movies in categories including Musicals, Laughs and Thrills, drove new generations to experience classic American films. The juries consisted of over 1,500 artists, scholars, critics and historians, with movies selected based on the film’s popularity over time, historical significance and cultural impact. "Citizen Kane" was voted the greatest American film twice.
AFI Film Festivals.
AFI operates two film festivals: AFI FEST in Los Angeles, CA, and AFI-Discovery Channel SILVERDOCS documentary festival in Silver Spring, MD. AFI FEST is the only film festival in the US to hold FIAPF (Fédération Internationale des Associations de Producteurs de Films) accreditation.
AFI Silver Theatre and Cultural Center.
As the largest nonprofit exhibitor in the United States, AFI screens films regularly at the AFI Silver Theatre and Cultural Center in Silver Spring, MD, and the ArcLight Cinemas and Skirball Cultural Center in Los Angeles, CA. Programming at the AFI Silver Theatre consists of an eclectic mix of retrospectives, festivals and first-run features as well as community events and educational activities.
AFI Digital Content Lab.
The AFI Digital Content Lab is a research and development facility for digital media located on the LA campus. The lab explores and creates digital entertainment prototypes for film, television, video games, broadband and mobile phones.
AFI ScreenNation.
AFI ScreenNation is a Web site featuring AFI-produced educational materials and tips for new filmmakers to share work, receive recognition and compete for prizes.

</doc>
<doc id="872" url="http://it.wikipedia.org/wiki/?curid=872" title="Akira Kurosawa">
Akira Kurosawa

Kurosawa entered the Japanese film industry in 1936, following a brief stint as a painter. After years of working on numerous films as an assistant director and scriptwriter, he made his debut as a director in 1943, during World War II with the popular action film "Sanshiro Sugata" (a.k.a. "Judo Saga"). After the war, the critically acclaimed "Drunken Angel" (1948), in which Kurosawa cast then-unknown actor Toshiro Mifune in a starring role, cemented the director's reputation as one of the most important young filmmakers in Japan. The two men would go on to collaborate on another 15 films.
"Rashomon", which premiered in Tokyo in August 1950, and which also starred Mifune, became, on September 10, 1951, the surprise winner of the Golden Lion at the Venice Film Festival and was subsequently released in Europe and North America. The commercial and critical success of this film opened up Western film markets for the first time to the products of the Japanese film industry, which in turn led to international recognition for other Japanese filmmakers. Throughout the 1950s and early 1960s, Kurosawa directed approximately a film a year, including a number of highly regarded films such as "Ikiru" (1952), "Seven Samurai" (1954) and "Yojimbo" (1961). After the mid-1960s, he became much less prolific, but his later work—including his final two epics, "Kagemusha" (1980) and "Ran" (1985)—continued to win awards, including the Palme d'Or for "Kagemusha", though more often abroad than in Japan.
In 1990, he accepted the Academy Award for Lifetime Achievement. Posthumously, he was named "Asian of the Century" in the "Arts, Literature, and Culture" category by "AsianWeek" magazine and CNN, cited as "one of the people who contributed most to the betterment of Asia in the past 100 years".
Life and career.
Childhood and youth (1910–1935).
Kurosawa was born on 23 March 1910 in Ōimachi in the Ōmori district of Tokyo. His father Isamu, a member of a former samurai family from the Akita Prefecture, worked as the director of the Army's Physical Education Institute's lower secondary school, while his mother Shima came from a merchant's family living in Osaka. Akira was the eighth and youngest child of the moderately wealthy family, with two of his siblings already grown up at the time of his birth and one deceased, leaving Kurosawa to grow up with three sisters and a brother.
In addition to promoting physical exercise, Isamu Kurosawa was open to western traditions and considered theater and motion pictures to have educational merit. He encouraged his children to watch films; young Akira viewed his first movies at the age of six. An important formative influence was his elementary school teacher Mr Tachikawa, whose progressive educational practices ignited in his young pupil first a love of drawing and then an interest in education in general. During this time, the boy also studied calligraphy and Kendo swordsmanship.
Another major childhood influence was Heigo Kurosawa, Akira's older brother by four years. In the aftermath of the Great Kantō earthquake of 1923, which devastated Tokyo, Heigo took the 13-year-old Akira to view the devastation. When the younger brother wanted to look away from the human corpses and animal carcasses scattered everywhere, Heigo forbade him to do so, instead encouraging Akira to face his fears by confronting them directly. Some commentators have suggested that this incident would influence Kurosawa's later artistic career, as the director was seldom hesitant to confront unpleasant truths in his work.
Heigo was academically gifted, but soon after failing to secure a place in Tokyo's foremost high school, he began to detach himself from the rest of the family, preferring to concentrate on his interest in foreign literature. moved in with him, and the two brothers became inseparable. Through Heigo, Akira devoured not only films but also theater and circus performances, while exhibiting his paintings and working for the left-wing Proletarian Artists' League. However, he was never able to make a living with his art, and, as he began to perceive most of the proletarian movement as "putting unfulfilled political ideals directly onto the canvas", he lost his enthusiasm for painting.
With the increasing production of talking pictures in the early 1930s, film narrators like Heigo began to lose work, and Akira moved back in with his parents. In July 1933, Heigo committed suicide. Kurosawa has commented on the lasting sense of loss he felt at his brother's death and the chapter of his autobiography that describes it—written nearly half a century after the event—is titled, "A Story I Don't Want to Tell." Only four months later, Kurosawa's eldest brother also died, leaving Akira, at age 23, the only one of the Kurosawa brothers still living, together with his three surviving sisters.
During his five years as an assistant director, Kurosawa worked under numerous directors, but by far the most important figure in his development was Kajiro Yamamoto. Of his 24 films as A.D., he worked on 17 under Yamamoto, many of them comedies featuring the popular actor Kenichi Enomoto, known as "Enoken." Yamamoto nurtured Kurosawa's talent, promoting him directly from third assistant director to chief assistant director after a year. Kurosawa's responsibilities increased, and he worked at tasks ranging from stage construction and film development to location scouting, script polishing, rehearsals, lighting, dubbing, editing and second-unit directing. In the last of Kurosawa's films as an assistant director, "Horse" ("Uma", 1941), Kurosawa took over most of the production, as Yamamoto was occupied with the shooting of another film.
One important piece of advice Yamamoto gave Kurosawa was that a good director needed to master screenwriting. Kurosawa soon realized that the potential earnings from his scripts were much higher than what he was paid as an assistant director. Kurosawa would later write or co-write all of his own films. He also frequently wrote screenplays for other directors. This outside scriptwriting would serve Kurosawa as a lucrative sideline lasting well into the 1960s, long after he became world-famous.
Wartime films and marriage (1942–1945).
In the two years following the release of "Horse" in 1941, Kurosawa searched for a story he could use to launch his directing career. Towards the end of 1942, about a year after the beginning of Japan's war with the United States, novelist Tsuneo Tomita published his Musashi Miyamoto inspired judo novel, "Sanshiro Sugata", the advertisements for which intrigued Kurosawa. He bought the book on its publication day, devoured it in one sitting, and immediately asked Toho to secure the film rights. Kurosawa's initial instinct proved correct as, within a few days, three other major Japanese studios also offered to buy the rights. Toho prevailed, and Kurosawa began pre-production on his debut work as director.
Shooting of "Sanshiro Sugata" began on location in Yokohama in December 1942. Production proceeded smoothly, but getting the completed film past the censors was an entirely different matter. The censorship considered the work too "British-American" (an accusation tantamount, at that time, to a charge of treason), and it was only through the intervention of director Yasujirō Ozu, who championed the film, that "Sanshiro Sugata" was finally accepted for release on March 25, 1943. (Kurosawa had just turned 33.) The movie became both a critical and commercial success. Nevertheless, the censorship office would later decide to cut out some 18 minutes of footage, much of which is now considered lost.
He next turned to the subject of wartime female factory workers in "The Most Beautiful", a propaganda film which he shot in a semi-documentary style in early 1944. In order to coax realistic performances from his actresses, the director had them live in a real factory during the shoot, eat the factory food and call each other by their character names. He would use similar methods with his performers throughout his career.
During production, the actress playing the leader of the factory workers, Yōko Yaguchi, was chosen by her colleagues to present their demands to the director. She and Kurosawa were constantly at loggerheads, and it was through these arguments that the two, paradoxically, became close. They married on May 21, 1945, with Yaguchi two months pregnant (she never resumed her acting career), and the couple would remain together until her death in 1985. They would have two children: a son, Hisao, born December 20, 1945, who would serve as producer on some of his father's last projects, and Kazuko, born April 29, 1954, who would become a costume designer.
Shortly before his marriage, Kurosawa was pressured by the studio against his will to direct a sequel to his debut film. The often blatantly propagandistic "Sanshiro Sugata Part II", which premiered in May 1945, is generally considered one of his very weakest pictures.
Kurosawa decided to write the script for a film that would be both censor-friendly and less expensive to produce. "The Men Who Tread on the Tiger's Tail", based on the Kabuki play "Kanjinchō" and starring the comedian Enoken, with whom Kurosawa had often worked during his assistant director days, was completed in September 1945. By this time, Japan had surrendered and the occupation of Japan had begun. The new American censors interpreted the values allegedly promoted in the picture as overly "feudal" and banned the work. (It would not be released until 1952, the year another Kurosawa film, "Ikiru", was also released.) Ironically, while in production, the film had already been savaged by Japanese wartime censors as too Western and "democratic" (they particularly disliked the comic porter played by Enoken), so the movie most probably would not have seen the light of day even if the war had continued beyond its completion.
First postwar works (1946–1950).
The war now ended, Kurosawa, absorbing the democratic ideals of the Occupation, sought to make films that would establish a new respect towards the individual and the self. The first such film, "No Regrets for Our Youth" (1946), inspired by both the 1933 Takigawa incident and the Hotsumi Ozaki wartime spy case, criticized Japan's prewar regime for its political oppression. Atypically for the director, the heroic central character is a woman, Yukie (Setsuko Hara), born into upper-middle-class privilege, who comes to question her values in a time of political crisis. The original script had to be extensively rewritten and, because of its controversial theme (and because the protagonist was a woman), the completed work divided critics, but it nevertheless managed to win the approval of audiences, who turned variations on the film's title ("No regrets for...") into something of a postwar catchphrase.
His next film, "One Wonderful Sunday" premiered in July 1947 to mixed reviews. It is a relatively uncomplicated and sentimental love story dealing with an impoverished postwar couple trying to enjoy, within the devastation of postwar Tokyo, their one weekly day off. The movie bears the influence of Frank Capra, D. W. Griffith and F. W. Murnau. Another film released in 1947 with Kurosawa's involvement was the action-adventure thriller, "Snow Trail", directed by Senkichi Taniguchi from Kurosawa's screenplay. It marked the debut of the intense young actor Toshiro Mifune. It was Kurosawa who, with his mentor Yamamoto, had intervened to persuade Toho to sign Mifune, during an audition in which the young man greatly impressed Kurosawa, but managed to alienate most of the other judges.
"Drunken Angel" is often considered the director's first major work. Although the script, like all of Kurosawa's occupation-era works, had to go through forced rewrites due to American censorship, Kurosawa felt that this was the first film in which he was able to express himself freely. A grittily realistic story of a doctor who tries to save a gangster (yakuza) with tuberculosis, it was also the director's first film with Toshiro Mifune, who would proceed to play either the main or a major characters in all but one ("Ikiru") of the director's next 16 films. While Mifune was not cast as the protagonist in "Drunken Angel", his explosive performance as the gangster so dominates the drama that he shifted the focus from the title character, the alcoholic doctor played by Takashi Shimura, who had already appeared in several Kurosawa movies. However, Kurosawa did not want to smother the young actor's immense vitality, and Mifune's rebellious character electrified audiences in much the way that Marlon Brando's defiant stance would startle American film audiences a few years later. The film premiered in Tokyo in April 1948 to rave reviews and was chosen by the prestigious Kinema Junpo critics poll as the best film of its year, the first of three Kurosawa movies to be so honored.
Kurosawa, with producer Sōjirō Motoki and fellow directors and friends Kajiro Yamamoto, Mikio Naruse and Senkichi Taniguchi, formed a new independent production unit called Film Art Association (Eiga Geijutsu Kyōkai). For this organization's debut work, and first film for Daiei studios, Kurosawa turned to a contemporary play by Kazuo Kikuta and, together with Taniguchi, adapted it for the screen. "The Quiet Duel" starred Toshiro Mifune as an idealistic young doctor struggling with syphilis, a deliberate attempt by Kurosawa to break the actor away from being typecast as gangsters. Released in March 1949, it was a box office success, but is generally considered one of the director's lesser achievements.
His second film of 1949, also produced by Film Art Association and released by Shintoho, was "Stray Dog". The most celebrated of Kurosawa's works from this period, it is a detective movie (perhaps the first important Japanese film in that genre) that explores the mood of Japan during its painful postwar recovery through the story of a young detective, played by Mifune, and his obsession over his handgun, stolen by a penniless young man who proceeds to use it to rob and murder. Adapted from an unpublished novel by Kurosawa in the style of a favorite writer of his, Georges Simenon, it was the director's first collaboration with screenwriter Ryuzo Kikushima, who would later help to script eight other Kurosawa films. A famous, virtually wordless sequence, lasting over eight minutes, shows the detective, disguised as an impoverished veteran, wandering the streets in search of the gun thief; it employed actual documentary footage of war-ravaged Tokyo neighborhoods shot by Kurosawa's friend, Ishirō Honda, the future director of "Gojira" (aka, "Godzilla"). The film is considered a precursor to the contemporary police procedural and buddy cop film genres.
"Scandal", released by Shochiku in April 1950, was inspired by the director's personal experiences with, and anger towards, Japanese yellow journalism. The work is an ambitious mixture of courtroom drama and social problem film about free speech and personal responsibility, but even Kurosawa regarded the finished product as dramatically unfocused and unsatisfactory, and almost all critics agree.
However, it would be Kurosawa's "second" film of 1950, "Rashomon", that would ultimately win him a whole new audience.
International recognition (1950–1958).
After finishing "Scandal", Kurosawa was approached by Daiei studios, which asked the director to make another film for them. Kurosawa picked a script by an aspiring young screenwriter, Shinobu Hashimoto. (They would eventually write nine films together.) It was based on Ryūnosuke Akutagawa's experimental short story "In a Grove", which recounts the murder of a samurai and the rape of his wife from various different and conflicting points-of-view. Kurosawa saw potential in the script, and with Hashimoto's help, polished and expanded it and then pitched it to Daiei, who were happy to accept the project due to its low budget.
Shooting of "Rashomon" began on July 7, 1950 and, after extensive location work in the primeval forest of Nara, wrapped on August 17. Just one week was spent in hurried post-production, hampered by a studio fire, and the finished film premiered at Tokyo's Imperial Theatre on August 25, expanding nationwide the following day. The movie was met by lukewarm reviews, with many critics puzzled by its unique theme and treatment, but it was nevertheless a moderate financial success for Daiei.
Kurosawa's next film, for Shochiku, was "The Idiot", an adaptation of the novel by the director's favorite writer, Fyodor Dostoyevsky. The filmmaker relocated the story from Russia to Hokkaido, but it is otherwise very faithful to the original, a fact seen by many critics as detrimental to the work. A studio-mandated edit shortened it from Kurosawa's original cut of 265 minutes (nearly four-and-a-half hours) to just 166 minutes, making the resulting narrative exceedingly difficult to follow. It is widely considered today to be one of the director's least successful works. Contemporary reviews were very negative, but the film was a moderate success at the box office, largely because of the popularity of one of its stars, Setsuko Hara.
Meanwhile, unbeknownst to Kurosawa, "Rashomon" had been entered in the prestigious Venice Film Festival, due to the efforts of Giuliana Stramigioli, a Japan-based representative of an Italian film company, who had seen and admired the movie and convinced Daiei to submit it. On September 10, 1951, "Rashomon" was awarded the festival's highest prize, the Golden Lion, shocking not only Daiei but the international film world, which at the time was largely unaware of Japan's decades-old cinematic tradition.
After Daiei very briefly exhibited a subtitled print of the film in Los Angeles, RKO purchased distribution rights to "Rashomon" in the United States. The company was taking a considerable gamble. It had put out only one prior subtitled film in the American market, and the only previous Japanese talkie commercially released in New York had been Mikio Naruse's comedy, "Wife! Be Like a Rose", in 1937: a critical and box-office flop. However, "Rashomon"'s commercial run, greatly helped by strong reviews from critics and even the columnist Ed Sullivan, was very successful. (It earned $35,000 in its first three weeks at a single New York theater, an almost unheard-of sum at the time.) This success in turn led to a vogue in America for Japanese movies throughout the 1950s, replacing the enthusiasm for Italian neorealist cinema. (The film was also released, by other distributors, in France, West Germany, Denmark, Sweden and Finland.) Among the Japanese filmmakers whose work, as a result, began to win festival prizes and commercial release in the West were Kenji Mizoguchi ("The Life of Oharu", "Ugetsu", "Sansho the Bailiff") and, somewhat later, Yasujirō Ozu ("Tokyo Story", "An Autumn Afternoon")—artists highly respected in Japan but, prior to this period, almost totally unknown in the West. Later generations of Japanese filmmakers who would find acclaim outside Japan—from Nagisa Oshima and Shohei Imamura to Juzo Itami, Takeshi Kitano and Takashi Miike—were able to pass through the door that Kurosawa was the very first to open.
His career boosted by his sudden international fame, Kurosawa, now reunited with his original film studio, Toho (which would go on to produce his next 11 films), set to work on his next project, "Ikiru". The movie stars Takashi Shimura as a cancer-ridden Tokyo bureaucrat, Watanabe, on a final quest for meaning before his death. For the screenplay, Kurosawa brought in Hashimoto as well as writer Hideo Oguni, who would go on to co-write 12 Kurosawa films. Despite the work's grim subject matter, the screenwriters took a satirical approach, which some have compared to the work of Brecht, to both the bureaucratic world of its hero and the U.S. cultural colonization of Japan. (American pop songs figure prominently in the film.) Because of this strategy, the filmmakers are usually credited with saving the picture from the kind of sentimentality common to dramas about characters with terminal illnesses. "Ikiru" opened in October 1952 to rave reviews—it won Kurosawa his second Kinema Junpo "Best Film" award—and enormous box office success. It remains the most acclaimed of all the artist's films set in the modern era.
In December 1952, Kurosawa took his "Ikiru" screenwriters, Shinobu Hashimoto and Hideo Oguni, for a forty-five day secluded residence at an inn to create the screenplay for his next movie, "Seven Samurai". The ensemble work was Kurosawa's first proper samurai film, the genre for which he would become most famous. The simple story, about a poor farming village in Sengoku period Japan that hires a group of samurai to defend it against an impending attack by bandits, was given a full epic treatment, with a huge cast (largely consisting of veterans of previous Kurosawa productions) and meticulously detailed action, stretching out to almost three-and-a-half hours of screen time.
Three months were spent in pre-production and a month in rehearsals. Shooting took up 148 days spread over almost a year, interrupted by production and financing troubles and Kurosawa's health problems. The film finally opened in April 1954, half a year behind its original release date and about three times over budget, making it at the time the most expensive Japanese film ever made. (However, by Hollywood standards, it was a quite modestly budgeted production, even for that time). The film received positive critical reaction and became a big hit, quickly making back the money invested in it and providing the studio with a product that they could, and did, market internationally—though with extensive edits. Over time—and with the theatrical and home video releases of the uncut version—its reputation has steadily grown. It is now regarded by some commentators as the greatest Japanese film ever made, and in 1979, a poll of Japanese film critics also voted it the best Japanese film ever made.
In 1954, nuclear tests in the Pacific were causing radioactive rainstorms in Japan (the only country ever to have been the victim of an atomic bombing), and one particular incident in March had exposed a Japanese fishing boat to nuclear fallout, with disastrous results. It is in this anxious atmosphere that Kurosawa's next film, "Record of a Living Being", was conceived. The story concerned an elderly factory owner (Toshiro Mifune) so terrified of the prospect of a nuclear attack that he becomes determined to move his entire extended family (both legal and extra-marital) to what he imagines is the safety of a farm in Brazil. Production went much more smoothly than the director's previous film, but a few days before shooting ended, Kurosawa's composer, collaborator and close friend Fumio Hayasaka passed away (of tuberculosis) at the age of only 41. The film's score was finished by Hayasaka's student, Masaru Sato, who would go on to score all of Kurosawa's next eight films. "Record of a Living Being" opened in November 1955 to mixed reviews and muted audience reaction, becoming the first Kurosawa film to lose money during its original theatrical run. Today, it is considered by many to be among the finest films dealing with the psychological effects of the global nuclear stalemate.
Kurosawa's next project, "Throne of Blood", a lavishly produced adaptation of William Shakespeare's "Macbeth"—set, like "Seven Samurai", in the Sengoku Era—represented an ambitious transposition of the English work into an Asian context. Kurosawa instructed his leading actress, Isuzu Yamada, to regard the work as if it were a cinematic version of a "Japanese" rather than a European literary classic. Appropriately, the acting of the players, particularly Yamada, draws heavily on the stylized techniques of the Noh theater. It was filmed in 1956 and released in January 1957 to a slightly less negative domestic response than had been the case with the director's previous film. Abroad, "Throne of Blood", regardless of the liberties it takes with its source material, quickly earned a place among the most celebrated Shakespeare adaptations.
Another adaptation of a classic European theatrical work followed almost immediately, with production of "The Lower Depths", based on a play by Maxim Gorky, taking place in May and June 1957. In contrast to the gigantic scope and sweep of "Throne of Blood", "The Lower Depths" was shot on only two confined sets, the better to emphasize the restricted nature of the characters' lives. Though faithful to the play, this adaptation of Russian material to a completely Japanese setting—in this case, the late Edo period—unlike his earlier "The Idiot", was regarded as artistically successful. The film premiered in September 1957, receiving a mixed response similar to that of "Throne of Blood". However, some critics rank it among the director's most underrated works.
Kurosawa's three consecutive movies after "Seven Samurai" had not managed to capture Japanese audiences in the way that that film had. The mood of the director's work had been growing increasingly pessimistic and dark, with the possibility of redemption through personal responsibility now very much questioned, particularly in "Throne of Blood" and "The Lower Depths". He recognized this, and deliberately aimed for a more light-hearted and entertaining film for his next production, while switching to the new widescreen format that had been gaining popularity in Japan. The resulting film, "The Hidden Fortress", is an action-adventure comedy-drama about a medieval princess, her loyal general and two peasants who all need to travel through enemy lines in order to reach their home region. Released in December 1958, "The Hidden Fortress" became an enormous box office success in Japan and was warmly received by critics. Today, the film is considered one of Kurosawa's most lightweight efforts, though it remains popular, not least because it is one of several major influences (as George Lucas himself has conceded) on Lucas' hugely popular 1977 space opera, "".
Birth of a company and the end of an era (1959–1965).
Starting with "Rashomon", Kurosawa's productions had become increasingly large in scope and so had the director's budgets. Toho, concerned about this development, suggested that he might help finance his own works, therefore making the studio's potential losses smaller, while in turn allowing himself more artistic freedom as co-producer. Kurosawa agreed, and the Kurosawa Production Company was established in April 1959, with Toho as majority shareholder.
Despite now risking his own money, Kurosawa chose a story more directly critical of the Japanese business and political elites than any of his previous works. "The Bad Sleep Well", based on a script by Kurosawa's nephew Mike Inoue, is a revenge drama about a young man who climbs the hierarchy of a corrupt Japanese company with the intention of exposing the men responsible for his father's death. Its theme proved topical: while the film was in production, mass demonstrations were held against the new U.S.-Japan Security treaty, which was seen by many Japanese, particularly the young, as threatening the country's democracy by giving too much power to corporations and politicians. The film opened in September 1960 to positive critical reaction and modest box office success. The 25-minute opening sequence, depicting a corporate wedding reception interrupted by reporters and police (who arrest an executive for corruption), is widely regarded as one of Kurosawa's most skillfully executed set pieces, but the remainder of the film is often perceived as disappointing by comparison. The movie has also been criticized for employing the conventional Kurosawan hero to combat a social evil that cannot be resolved through the actions of individuals, however courageous or cunning.
"Yojimbo" ("The Bodyguard"), Kurosawa Production's second film, centers on a masterless samurai, Sanjuro, who strolls into a 19th century town ruled by two opposing violent factions and provokes them into destroying each other. The director used this work to play with many genre conventions, particularly the Western, while at the same time offering an unprecedentedly (for the Japanese screen) graphic portrayal of violence. Some commentators have seen the Sanjuro character in this film as a fantasy figure who magically reverses the historical triumph of the corrupt merchant class over the samurai class. Featuring Tatsuya Nakadai in his first major role in a Kurosawa movie, and with innovative photography by Kazuo Miyagawa (who shot "Rashomon") and Takao Saito, the film premiered in April 1961 and was an immense success at the box office, earning more than any previous Kurosawa film. Critical reaction was equally positive, and the film proved a major influence on its genre in Japan, ushering in a new era of violent samurai films, known as "cruel films" ("zankoku eiga"). The movie and its blackly comic tone were also widely imitated abroad. Sergio Leone's "A Fistful of Dollars" was a virtual (unauthorized) scene-by-scene remake.
Following the success of "Yojimbo", Kurosawa found himself under pressure from Toho to create a sequel. Kurosawa turned to a script he had written before "Yojimbo", reworking it to include the hero of his previous film. "Sanjuro" was the first of three Kurosawa films to be adapted from the work of the writer Shūgorō Yamamoto (the others would be "Red Beard" and "Dodeskaden"). It is lighter in tone and closer to a conventional period film than "Yojimbo", though its story of a power struggle within a samurai clan is portrayed with strongly comic undertones. The film opened on January 1, 1962, quickly surpassing "Yojimbo"'s box office success and garnering positive reviews.
Kurosawa had meanwhile instructed Toho to purchase the film rights to "King's Ransom", a novel about a kidnapping written by American author and screenwriter Evan Hunter, under his pseudonym of Ed McBain, as one of his 87th Precinct series of crime books. The director intended to create a work condemning kidnapping, which he considered one of the very worst crimes. The suspense film, titled "High and Low", was shot during the latter half of 1962 and released in March 1963. It broke Kurosawa's box office record (the third film in a row to do so), became the highest grossing Japanese film of the year, and won glowing reviews. However, his triumph was somewhat tarnished when, ironically, the film was blamed for a wave of kidnappings which occurred in Japan about this time (he himself received kidnapping threats directed at his young daughter, Kazuko). "High and Low" is considered by many commentators to be among the director's strongest works.
Kurosawa quickly moved on to his next project, "Red Beard". Based on a short story collection by Shūgorō Yamamoto and incorporating elements from Dostoyevsky's novel "The Insulted and Injured", it is a period film, set in a mid-19th century clinic for the poor, in which Kurosawa's humanist themes receive perhaps their fullest statement. A conceited and materialistic, foreign-trained young doctor, Yasumoto, is forced to become an intern at the clinic under the stern tutelage of Doctor Niide, known as "Akahige" ("Red Beard"), played by Mifune. Although he resists Red Beard initially, Yasumoto comes to admire his wisdom and courage, and to perceive the patients at the clinic, whom he at first despised, as worthy of compassion and dignity.
Yūzō Kayama, who plays Yasumoto, was an extremely popular film and music star at the time, particularly for his "Young Guy" ("Wakadaishō") series of musical comedies, so signing him to appear in the film virtually guaranteed Kurosawa strong box-office. The shoot, the filmmaker's longest ever, lasted well over a year (after five months of pre-production), and wrapped in spring 1965, leaving the director, his crew and his actors exhausted. "Red Beard" premiered in April 1965, becoming the year's highest-grossing Japanese production and the third (and last) Kurosawa film to top the prestigious Kinema Jumpo yearly critics poll. It remains one of Kurosawa's best-known and most-loved works in his native country. Outside Japan, critics have been much more divided. Most commentators concede its technical merits and some praise it as among Kurosawa's best, while others insist that it lacks complexity and genuine narrative power, with still others claiming that it represents a retreat from the artist's previous commitment to social and political change.
The film marked something of an end of an era for its creator. The director himself recognized this at the time of its release, telling critic Donald Richie that a cycle of some kind had just come to an end and that his future films and production methods would be different. His prediction proved quite accurate. Beginning in the late 1950s, television began increasingly to dominate the leisure time of the formerly large and loyal Japanese cinema audience. And as film company revenues dropped, so did their appetite for risk—particularly the risk represented by Kurosawa's costly production methods.
"Red Beard" also marked the midway point, chronologically, in the artist's career. During his previous twenty-nine years in the film industry (which includes his five years as assistant director), he had directed twenty-three films, while during the remaining twenty-eight years, for many and complex reasons, he would complete only seven more. Also, for reasons never adequately explained, "Red Beard" would be his final film starring Toshiro Mifune. Yu Fujiki, an actor who worked on "The Lower Depths", observed, regarding the closeness of the two men on the set, "Mr. Kurosawa's heart was in Mr. Mifune's body." Donald Richie has described the rapport between them as a unique "symbiosis." Virtually all critics agree that the strongest period of Kurosawa's career was the one between 1950 and 1965—bookended by "Rashomon" and "Red Beard"—and that it is not a coincidence that this phase corresponds almost exactly to the time that he and Mifune worked together.
Hollywood detour (1966–1968).
When Kurosawa's exclusive contract with Toho came to an end in 1966, the 56-year-old director was seriously contemplating change. Observing the troubled state of the domestic film industry, and having already received dozens of offers from abroad, the idea of working outside Japan appealed to him as never before.
For his first foreign project, Kurosawa chose a story based on a Life magazine article. The Embassy Pictures action thriller, to be filmed in English and called simply "Runaway Train", would have been his first in color. But the language barrier proved a major problem, and the English version of the screenplay was not even finished by the time filming was to begin in autumn 1966. The shoot, which required snow, was moved to autumn 1967, then canceled in 1968. Almost twenty years later, another foreigner working in Hollywood, Andrei Konchalovsky, would finally make "Runaway Train", though from a script totally different from Kurosawa's.
The director meanwhile had become involved in a much more ambitious Hollywood project. "Tora! Tora! Tora!", produced by 20th Century Fox and Kurosawa Production, would be a portrayal of the Japanese attack on Pearl Harbor from both the American and the Japanese points-of-view, with Kurosawa helming the Japanese half and an English-speaking filmmaker directing the American half. He spent several months working on the script with Ryuzo Kikushima and Hideo Oguni, but very soon the project began to unravel. The director chosen to film the American sequences turned out not to be the prestigious English filmmaker David Lean, as the producers had led Kurosawa to believe, but the much less celebrated special effects expert, Richard Fleischer. The budget was also cut, and the screen time allocated for the Japanese segment would now be no longer than 90 minutes—a major problem, considering that Kurosawa's script ran over four hours. After numerous revisions, a more or less finalized cut screenplay was agreed upon in May 1968. Shooting began in early December, but Kurosawa would last only a little over three weeks as director. He struggled to work with an unfamiliar crew and the requirements of a Hollywood production, while his working methods puzzled his American producers, who ultimately concluded that the director must be mentally ill. On Christmas Eve 1968, the Americans announced that Kurosawa had left the production due to "fatigue", effectively firing him. (He was ultimately replaced, for the film's Japanese sequences, with two directors, Kinji Fukasaku and Toshio Masuda.)
"Tora! Tora! Tora!", finally released to unenthusiastic reviews in September 1970, was, as Donald Richie put it, an "almost unmitigated tragedy" in Kurosawa's career. He had spent years of his life on a logistically nightmarish project to which he ultimately did not contribute a foot of film shot by himself. (He had his name removed from the credits, though the script used for the Japanese half was still his and his co-writers'.) He became estranged from his longtime collaborator, writer Ryuzo Kikushima, and never worked with him again. The project had inadvertently exposed corruption in his own production company (a situation reminiscent of his own movie, "The Bad Sleep Well"). His very sanity had been called into question. Worst of all, the Japanese film industry—and perhaps the man himself—began to suspect that he would never make another film.
A difficult decade (1969–1977).
Knowing that his reputation was at stake following the much publicised "Tora! Tora! Tora!" debacle, Kurosawa moved quickly to a new project to prove he was still viable. To his aid came friends and famed directors Keisuke Kinoshita, Masaki Kobayashi and Kon Ichikawa, who together with Kurosawa established in July 1969 a production company called the Club of the Four Knights (Yonki no kai). Although the plan was for the four directors to create a film each, it has been suggested that the real motivation for the other three directors was to make it easier for Kurosawa to successfully complete a film, and therefore find his way back into the business.
The first project proposed and worked on was a period film to be called "Dora-Heita", but when this was deemed too expensive, attention shifted to "Dodesukaden", an adaptation of yet another Shūgorō Yamamoto work, again about the poor and destitute. The film was shot quickly (by Kurosawa's standards) in about nine weeks, with Kurosawa determined to show he was still capable of working quickly and efficiently within a limited budget. For his first work in color, the dynamic editing and complex compositions of his earlier pictures were set aside, with the artist focusing on the creation of a bold, almost surreal palette of primary colors, in order to reveal the toxic environment in which the characters live. It was released in Japan in October 1970, but though a minor critical success, it was greeted with audience indifference. The picture lost money and caused the Club of the Four Knights to dissolve. Initial reception abroad was somewhat more favorable, but "Dodesukaden" has since been typically considered an interesting experiment not comparable to the director's best work.
Unable to secure funding for further work and allegedly suffering from health problems, Kurosawa apparently reached the breaking point: on December 22, 1971, he slit his wrists and throat multiple times. The suicide attempt proved unsuccessful and the director's health recovered fairly quickly, with Kurosawa now taking refuge in domestic life, uncertain if he would ever direct another film.
In early 1973, the Soviet studio Mosfilm approached the filmmaker to ask if he would be interested in working with them. Kurosawa proposed an adaptation of Russian explorer Vladimir Arsenyev's autobiographical work "Dersu Uzala". The book, about a Goldi hunter who lives in harmony with nature until destroyed by encroaching civilization, was one that he had wanted to make since the 1930s. In December 1973, the 63-year-old Kurosawa set off for the Soviet Union with four of his closest aides, beginning a year-and-a-half stay in the country. Shooting began in May 1974 in Siberia, with filming in exceedingly harsh natural conditions proving very difficult and demanding. The picture wrapped in April 1975, with a thoroughly exhausted and homesick Kurosawa returning to Japan and his family in June. "Dersu Uzala" had its world premiere in Japan on August 2, 1975, and did well at the box office. While critical reception in Japan was muted, the film was better reviewed abroad, winning the Golden Prize at the 9th Moscow International Film Festival, as well as an Academy Award for Best Foreign Language Film. Today, critics remain divided over the film: some see it as an example of Kurosawa's alleged artistic decline, while others count it among his finest works.
Although proposals for television projects were submitted to him, he had no interest in working outside the film world. Nevertheless, the hard-drinking director did agree to appear in a series of television ads for Suntory whiskey, which aired in 1976. While fearing that he might never be able to make another film, the director nevertheless continued working on various projects, writing scripts and creating detailed illustrations, intending to leave behind a visual record of his plans in case he would never be able to film his stories.
Two epics (1978–1986).
In 1977, American director George Lucas had released "", a wildly successful science fiction film influenced by Kurosawa's "The Hidden Fortress", among other works. Lucas, like many other New Hollywood directors, revered Kurosawa and considered him a role model, and was shocked to discover that the Japanese filmmaker was unable to secure financing for any new work. The two met in San Francisco in July 1978 to discuss the project Kurosawa considered most financially viable: "Kagemusha", the epic story of a thief hired as the double of a medieval Japanese lord of a great clan. Lucas, enthralled by the screenplay and Kurosawa's illustrations, leveraged his influence over 20th Century Fox to coerce the studio that had fired Kurosawa just ten years earlier to produce "Kagemusha", then recruited fellow fan Francis Ford Coppola as co-producer.
Production began the following April, with Kurosawa in high spirits. Shooting lasted from June 1979 through March 1980 and was plagued with problems, not the least of which was the firing of the original lead actor, Shintaro Katsu—creator of the very popular Zatoichi character—due to an incident in which the actor insisted, against the director's wishes, on videotaping his own performance. (He was replaced by Tatsuya Nakadai, in his first of two consecutive leading roles in a Kurosawa movie.) The film was completed only a few weeks behind schedule and opened in Tokyo in April 1980. It quickly became a massive hit in Japan. The film was also a critical and box office success abroad, winning the coveted Palme d'Or at the 1980 Cannes Film Festival in May, though some critics, then and now, have faulted the film for its alleged coldness. Kurosawa spent much of the rest of the year in Europe and America promoting "Kagemusha", collecting awards and accolades, and exhibiting as art the drawings he had made to serve as storyboards for the film.
The international success of "Kagemusha" allowed Kurosawa to proceed with his next project, "Ran", another epic in a similar vein. The script, partly based on William Shakespeare's "King Lear", depicted a ruthless, bloodthirsty daimyo (warlord), played by Tatsuya Nakadai, who, after foolishly banishing his one loyal son, surrenders his kingdom to his other two sons, who then betray him, thus plunging the entire kingdom into war. As Japanese studios still felt wary about producing another film that would rank among the most expensive ever made in the country, international help was again needed. This time it came from French producer Serge Silberman, who had produced Luis Buñuel's final movies. Filming did not begin until December 1983 and lasted more than a year.
In January 1985, production of "Ran" was halted as Kurosawa's 64-year-old wife Yōko fell ill. She died on February 1. Kurosawa returned to finish his film and "Ran" premiered at the Tokyo Film Festival on May 31, with a wide release the next day. The film was a moderate financial success in Japan, but a larger one abroad and, as he had done with "Kagemusha", Kurosawa embarked on a trip to Europe and America, where he attended the film's premieres in September and October.
"Ran" won several awards in Japan, but was not quite as honored there as many of the director's best films of the 1950s and 1960s had been. The film world was shocked, however, when Japan passed over the film in favor of another as its official entry to compete for an Oscar nomination in the Best Foreign Film category. Both the producer and Kurosawa himself attributed this to a misunderstanding: because of the Academy's arcane rules, no one was sure whether "Ran" qualified as a "Japanese" film, a "French" film (due to its financing), or both, so it was not submitted at all. In response to what at least appeared to be a blatant snub by his own countrymen, the director Sidney Lumet led a successful campaign to have Kurosawa receive an Oscar nomination for Best Director that year (Sydney Pollack ultimately won the award for directing Out of Africa). "Ran"'s costume designer, Emi Wada, won the movie's only Oscar.
"Kagemusha" and "Ran", particularly the latter, are often considered to be among Kurosawa's finest works. After "Ran"'s release, Kurosawa would point to it as his best film, a major change of attitude for the director who, when asked which of his works was his best, had always previously answered "my next one."
Final works and last years (1987–1998).
For his next movie, Kurosawa chose a subject very different from any that he had ever filmed before. While some of his previous pictures (for example, "Drunken Angel" and "Kagemusha") had included brief dream sequences, "Dreams" was to be entirely based upon the director's own dreams. Significantly, for the first time in over forty years, Kurosawa, for this deeply personal project, wrote the screenplay alone. Although its estimated budget was lower than the films immediately preceding it, Japanese studios were still unwilling to back one of his productions, so Kurosawa turned to another famous American fan, Steven Spielberg, who convinced Warner Bros. to buy the international rights to the completed film. This made it easier for Kurosawa's son, Hisao, as co-producer and soon-to-be head of Kurosawa Production, to negotiate a loan in Japan that would cover the film's production costs. Shooting took more than eight months to complete, and "Dreams" premiered at Cannes in May 1990 to a polite but muted reception, similar to the reaction the picture would generate elsewhere in the world.
Kurosawa now turned to a more conventional story with "Rhapsody in August"—the director's first film fully produced in Japan since "Dodeskaden" over twenty years before—which explored the scars of the nuclear bombing which destroyed Nagasaki at the very end of World War II. It was adapted from a Kiyoko Murata novel, but the film's references to the Nagasaki bombing came from the director rather than from the book. This was his only movie to include a role for an American movie star: Richard Gere, who plays a small role as the nephew of the elderly heroine. Shooting took place in early 1991, with the film opening on May 25 that year to a largely negative critical reaction, especially in the United States, where the director was accused of promulgating naïvely anti-American sentiments.
Kurosawa wasted no time moving onto his next project: "Madadayo", or "Not Yet". Based on autobiographical essays by Hyakken Uchida, the film follows the life of a Japanese professor of German through the Second World War and beyond. The narrative centers on yearly birthday celebrations with his former students, during which the protagonist declares his unwillingness to die just yet—a theme that was becoming increasingly relevant for the film's 81-year-old creator. Filming began in February 1992 and wrapped by the end of September. Its release on April 17, 1993, was greeted by an even more disappointed reaction than had been the case with his two preceding works.
Kurosawa nevertheless continued to work. He wrote the original screenplays "The Sea is Watching" in 1993 and "After the Rain" in 1995. While putting finishing touches on the latter work in 1995, Kurosawa slipped and broke the base of his spine. Following the accident, he would use a wheelchair for the rest of his life, putting an end to any hopes of him directing another film. His longtime wish—to die on the set while shooting a movie—was never to be fulfilled.
Death and posthumous works.
Following his accident in 1995, Kurosawa's health began to deteriorate. While his mind remained sharp and lively, his body was giving up, and for the last half year of his life, the director was largely confined to bed, listening to music and watching television at home. On September 6, 1998, Kurosawa died of a stroke in Setagaya, Tokyo, at the age of 88.
Following Kurosawa's death, several posthumous works based on his unfilmed screenplays have been produced. "After the Rain", directed by Takashi Koizumi, was released in 1998, and "The Sea is Watching", directed by Kei Kumai, premiered in 2002. A script created by the Yonki no Kai ("Club of the Four Knights") (Kurosawa, Keisuke Kinoshita, Masaki Kobayashi, and Kon Ichikawa), around the time that "Dodeskaden" was made, finally was filmed and released (in 2000) as "Dora-Heita", by the only surviving founding member of the club, Kon Ichikawa.
Working methods, style and themes.
Working methods.
All biographical sources, as well as the filmmaker's own comments, confirm that Kurosawa was a completely "hands-on" director, passionately involved in every aspect of the filmmaking process. As one interviewer summarized, "he (co-)writes his scripts, oversees the design, rehearses the actors, sets up all the shots and then does the editing." His active participation extended from the initial concept to the editing and scoring of the final product.
Script.
Kurosawa emphasized time and again that the screenplay was the absolute foundation of a successful film and that, though a mediocre director can sometimes make a passable film out of a "good" script, even an excellent director can never make a good film out of a "bad" script. During the postwar period, he began the practice of collaborating with a rotating group of five screenwriters: Eijirō Hisaita, Ryuzo Kikushima, Shinobu Hashimoto, Hideo Oguni, and Masato Ide. Whichever members of this group happened to be working on a particular film would gather around a table, often at a hot-springs resort, where they would not be distracted by the outside world. ("Seven Samurai", for example, was written in this fashion.) Often they all (except Oguni, who acted as "referee") would work on exactly the same pages of the script, and Kurosawa would choose the best-written version from the different drafts of each particular scene. This method was adopted "so that each contributor might function as a kind of foil, checking the dominance of any one person's point-of-view."
In addition to the actual script, Kurosawa at this stage often produced extensive, fantastically detailed notes to elaborate his vision. For example, for "Seven Samurai", he created six notebooks in which he created (among many other things) detailed biographies of the samurai, including what they wore and ate, how they walked, talked and behaved when greeted, and even how each tied his shoes. For the 101 peasant characters in the film, he created a registry consisting of 23 families and instructed the performers playing these roles to live and work as these "families" for the duration of shooting.
Shooting.
For his early films, although they were consistently well photographed, Kurosawa generally used standard lenses and deep-focus photography. Beginning with "Seven Samurai" (1954), however, Kurosawa's cinematic technique changed drastically with his extensive use of long lens and multiple cameras. The director claimed that he used these lenses and several cameras rolling at once to help the actors—allowing them to be photographed at some distance from the lens, and without any knowledge of which particular camera's image would be utilized in the final cut—making their performances much more natural. (In fact, Tatsuya Nakadai agreed that the multiple cameras greatly helped his performances with the director.) But these changes had a powerful effect as well on the look of the action scenes in that film, particularly the final battle in the rain. Says Stephen Prince: "He can use the telephoto lenses to get under the horses, in between their hooves, to plunge us into the chaos of that battle in a visual way that is really quite unprecedented, both in Kurosawa's own work and in the samurai genre as a whole."
With "The Hidden Fortress", Kurosawa began to utilize the widescreen (anamorphic) process for the first time in his work. These three techniques—long lenses, multiple cameras and widescreen—were in later works fully exploited, even in sequences with little or no overt action, such as the early scenes of "High and Low" that take place in the central character's home, in which they are employed to dramatize tensions and power relationships between the characters within a highly confined space.
For all his films, but particularly for his "jidaigeki", Kurosawa insisted on absolute authenticity of sets, costumes and props. Numerous instances of his fanatical devotion to detail have been recorded, of which the following are only a few examples.
For "Throne of Blood", in the scene where Washizu (Mifune) is attacked with arrows by his own men, the director had archers shoot real arrows, hollowed out and running along wires, toward Toshiro Mifune from a distance of about ten feet, with the actor carefully following chalk marks on the ground to avoid being hit. (Some of the arrows missed him by an inch; the actor, who admitted that he was not merely "acting" terrified in the film, suffered nightmares afterward).
For "Red Beard", to construct the gate for the clinic set, Kurosawa had his assistants dismantle rotten wood from old sets and then create the prop from scratch with this old wood, so the gate would look properly ravaged by time. For the same film, for teacups that appeared in the movie, he ordered his crew to pour fifty years’ worth of tea into the cups so they would appear appropriately stained.
For "Ran", art director Yoshirō Muraki, constructing the "third castle" set under the director's supervision, created the "stones" of that castle by having photographs taken of actual stones from a celebrated castle, then painting Styrofoam blocks to exactly resemble those stones and gluing them to the castle "wall" through a process known as "rough-stone piling", which required months of work. Later, before shooting the famous scene in which the castle is attacked and set on fire, in order to prevent the Styrofoam "stones" from melting in the heat, the art department coated the surface with four layers of cement, then painted the colors of the ancient stones onto the cement.
Editing.
Kurosawa both directed and edited most of his films, which is nearly unique among prominent filmmakers. Kurosawa often remarked that he shot a film simply in order to have material to edit, because the editing of a picture was the most important and creatively interesting part of the process for him. Kurosawa's creative team believed that the director's skill with editing was his greatest talent. Hiroshi Nezu, a longtime production supervisor on his films, said, "Among ourselves, we think that he is Toho's best director, that he is Japan's best scenarist, and that he is the best editor in the world. He is most concerned with the flowing quality which a film must have... The Kurosawa film flows "over" the cut, as it were."
The director's frequent crew member Teruyo Nogami confirms this view. "Akira Kurosawa's editing was exceptional, the inimitable work of a genius... No one was a match for him." She claimed that Kurosawa carried in his head all the information about all shots filmed, and if, in the editing room, he asked for a piece of film and she handed him the wrong one, he would immediately recognize the error, though she had taken detailed notes on each shot and he had not. She compared his mind to a computer, which could do with edited segments of film what computers do today.
Kurosawa's habitual method was to edit a film daily, bit by bit, during production. This helped particularly when he started using multiple cameras, which resulted in a large amount of film to assemble. "I always edit in the evening if we have a fair amount of footage in the can. After watching the rushes, I usually go to the editing room and work." Because of this practice of editing as he went along, the post-production period for a Kurosawa film could be startlingly brief: "Yojimbo" had its Japanese premiere on April 20, 1961, "four days" after shooting concluded on April 16.
The "Kurosawa-gumi".
Composers: Fumio Hayasaka ("Drunken Angel", "Stray Dog", "Scandal", "Rashomon", "The Idiot", "Ikiru", "Seven Samurai", "Record of a Living Being"); Masaru Sato ("Throne of Blood", "The Lower Depths", "The Hidden Fortress", "The Bad Sleep Well", "Yojimbo", "Sanjuro", "High and Low", "Red Beard"); Tōru Takemitsu ("Dodeskaden", "Ran"); Shin-ichirō Ikebe ("Kagemusha", "Dreams", "Rhapsody in August", "Madadayo").
Cinematographers: Asakazu Nakai ("No Regrets for Our Youth", "One Wonderful Sunday", "Stray Dog", "Ikiru", "Seven Samurai", "Record of a Living Being", "Throne of Blood", "High and Low", "Red Beard", "Dersu Uzala", "Ran"); Kazuo Miyagawa ("Rashomon", "Yojimbo"); Takao Saitō ("Sanjuro", "High and Low", "Red Beard", "Dodeskaden", "Kagemusha", "Ran", "Dreams", "Rhapsody in August", "Madadayo").
Art Department: Yoshirō Muraki served as either assistant art director, art director or production designer for all Kurosawa's films (except for "Dersu Uzala") from "Drunken Angel" until the end of the director's career.
Production Crew: Teruyo Nogami served as script supervisor, production manager, associate director or assistant to the producer on all Kurosawa's films from "Rashomon" to the end of the director's career. Hiroshi Nezu was production supervisor or unit production manager on all the films from "Seven Samurai" to "Dodeskaden", except "Sanjuro". After retiring as a director, Ishirō Honda returned more than 30 years later to work again for his friend and former mentor as a directorial advisor, production coordinator and creative consultant on Kurosawa's last five films ("Kagemusha", "Ran", "Dreams", "Rhapsody in August" and "Madadayo"). Allegedly one segment of "Dreams" was actually directed by Honda following Kurosawa's detailed storyboards.
Actors: "Leading actors": Takashi Shimura (21 films); Toshiro Mifune (16 films), Susumu Fujita (8 films), Tatsuya Nakadai (6 films) and Masayuki Mori (5 films).
"Supporting performers" (in alphabetical order): Minoru Chiaki, Kamatari Fujiwara, Bokuzen Hidari, Fumiko Homma, Hisashi Igawa, Yunosuke Ito, Kyoko Kagawa, Daisuke Kato, Isao Kimura, Kokuten Kodo, Akitake Kono, Yoshio Kosugi, Koji Mitsui, Seiji Miyaguchi, Eiko Miyoshi, Nobuo Nakamura, Akemi Negishi, Denjiro Okochi, Noriko Sengoku, Gen Shimizu, Ichiro Sugai, Haruo Tanaka, Akira Terao, Eijiro Tono, Yoshio Tsuchiya, Kichijiro Ueda, Atsushi Watanabe, Isuzu Yamada, Tsutomu Yamazaki and Yoshitaka Zushi.
Style.
Virtually all commentators have noted Kurosawa's bold, dynamic style, which many have compared to the traditional Hollywood style of narrative moviemaking, one that emphasizes, in the words of one such scholar, "chronological, causal, linear and historical thinking." But it has also been claimed that, from his very first film, the director displayed a technique quite distinct from the seamless style of classic Hollywood. This technique involved a disruptive depiction of screen space through the use of numerous unrepeated camera setups, a disregard for the traditional 180-degree axis of action around which Hollywood scenes have usually been constructed, and an approach in which "narrative time becomes spatialized", with fluid camera movement often replacing conventional editing. The following are some idiosyncratic aspects of the artist's style.
The axial cut.
In his films of the 1940s and 1950s, Kurosawa frequently employs the "axial cut," in which the camera moves closer to, or further away from, the subject, not through the use of tracking shots or dissolves, but through a series of matched jump cuts. For example, in "Sanshiro Sugata II", the hero takes leave of the woman he loves, but then, after walking away a short distance, turns and bows to her, and then, after walking further, turns and bows once more. This sequence of shots is illustrated on film scholar David Bordwell's blog. The three shots are not connected in the film by camera movements or dissolves, but by a series of two jump cuts. The effect is to stress the duration of Sanshiro's departure.
In the opening sequence of "Seven Samurai" in the peasant village, the axial cut is used twice. When the villagers are outdoors, gathered in a circle, weeping and lamenting the imminent arrival of the bandits, they are glimpsed from above in extreme long shot, then, after the cut, in a much closer shot, then in an even closer shot at ground level as the dialogue begins. A few minutes later, when the villagers go to the mill to ask the village elder's advice, there is a long shot of the mill, with a slowly turning wheel in the river, then a closer shot of this wheel, and then a still closer shot of it. (As the mill is where the elder lives, these shots forge a mental association in the viewer's mind between that character and the mill.)
Cutting on motion.
A number of scholars have pointed out Kurosawa's tendency to "cut on motion": that is, to edit a sequence of a character or characters in motion so that an action is depicted in two or more separate shots, rather than one uninterrupted shot. One scholar, as an example, describes a tense scene in "Seven Samurai" in which the samurai Shichirôji, who is standing, wishes to console the peasant Manzo, who is sitting on the ground, and he gets down on one knee to talk to him. Kurosawa chooses to film this simple action in two shots rather than one (cutting between the two only "after" the action of kneeling has begun) to fully convey Shichirôji's humility. Numerous other instances of this device are evident in the movie. "Kurosawa breaks up the action, fragments it, in order to create an emotional effect."
The wipe.
A form of cinematic punctuation very strongly identified with Kurosawa is the wipe. This is an effect created through an optical printer, in which, when a scene ends, a line or bar appears to move across the screen, "wiping" away the image while simultaneously revealing the first image of the subsequent scene. As a transitional device, it is used as a substitute for the straight cut or the dissolve (though Kurosawa, of course, often used both of those devices as well). In his mature work, Kurosawa employed the wipe so frequently that it became a kind of signature. For example, one blogger has counted no fewer than 12 instances of the wipe in "Drunken Angel".
There are a number of theories concerning the purpose of this device, which, as James Goodwin notes, was common in silent cinema but became considerably rarer in the more "realistic" sound cinema. Goodwin claims that the wipes in "Rashomon", for instance, fulfill one of three purposes: emphasizing motion in traveling shots, marking narrative shifts in the courtyard scenes and marking temporal ellipses between actions (e.g., between the end of one character's testimony and the beginning of another's).
An instance of the wipe used as a satirical device can be seen in "Ikiru". A group of women visit the local government office to petition the bureaucrats to turn a waste area into a children's playground. The viewer is then shown a series of point of view shots of various bureaucrats, connected by wipe transitions, each of whom refers the group to another department. Nora Tennessen comments in her blog (which shows one example) that "the wipe technique makes sequence funnier—images of bureaucrats are stacked like cards, each more punctilious than the last."
Image-sound counterpoint.
Kurosawa by all accounts always gave great attention to the soundtracks of his films (Teruyo Nogami's memoir gives many such examples). In the late 1940s, he began to employ music for what he called "counterpoint" to the emotional content of a scene, rather than merely to reinforce the emotion, as Hollywood traditionally did (and still does). The inspiration for this innovation came from a family tragedy. When news reached Kurosawa of his father's death in 1948, he wandered aimlessly through the streets of Tokyo. His sorrow was magnified rather than diminished when he suddenly heard the cheerful, vapid song "The Cuckoo Waltz", and he hurried to escape from this "awful music." He then told his composer, Fumio Hayasaka, with whom he was working on "Drunken Angel", to use "The Cuckoo Waltz" as ironic accompaniment to the scene in which the dying gangster, Matsunaga, sinks to his lowest point in the narrative.
This ironic approach to music can also be found in "Stray Dog", a film released a year after "Drunken Angel". In the climactic scene, the detective Murakami is fighting furiously with the murderer Yusa in a muddy field. The sound of a Mozart piece is suddenly heard, played on the piano by a woman in a nearby house. As one commentator notes, "In contrast to this scene of primitive violence, the serenity of the Mozart is, literally, other-worldly" and "the power of this elemental encounter is heightened by the music." Nor was Kurosawa's "ironic" use of the soundtrack limited to music. One critic observes that, in "Seven Samurai", "During episodes of murder and mayhem, birds chirp in the background, as they do in the first scene when the farmers lament their seemingly hopeless fate."
Recurring themes.
The master–disciple relationship.
Many commentators have noted the frequent occurrence in Kurosawa's work of the complex relationship between an older and a younger man, who serve each other as master and disciple, respectively. This theme was clearly an expression of the director's life experience. "Kurosawa revered his teachers, in particular Kajiro Yamamoto, his mentor at Toho", according to Joan Mellen. "The salutary image of an older person instructing the young evokes always in Kurosawa's films high moments of pathos." The critic Tadao Sato considers the recurring character of the "master" to be a type of surrogate father, whose role it is to witness the young protagonist's moral growth and approve of it.
In his very first film, "Sanshiro Sugata", after the Judo master Yano becomes the title character's teacher and spiritual guide, "the narrative cast in the form of a chronicle studying the stages of the hero's growing mastery and maturity." The master-pupil relationship in the films of the postwar era—as depicted in such works as "Drunken Angel", "Stray Dog", "Seven Samurai", "Red Beard" and "Dersu Uzala"—involves very little direct instruction, but much learning through experience and example; Stephen Prince relates this tendency to the private and nonverbal nature of the concept of Zen enlightenment.
By the time of "Kagemusha", however, according to Prince, the meaning of this relationship has changed. A thief chosen to act as the double of a great lord continues his impersonation even after his master's death: "the relationship has become spectral and is generated from beyond the grave with the master maintaining a ghostly presence. Its end is death, not the renewal of commitment to the living that typified its outcome in earlier films." However, according to the director's biographer, in his final film, "Madadayo"—which deals with a teacher and his relationship with an entire group of ex-pupils—a sunnier vision of the theme emerges. "The students hold an annual party for their professor, attended by dozens of former students, now adults of varying age... This extended sequence... expresses, as only Kurosawa can, the simple joys of student-teacher relationships, of kinship, of being alive."
The heroic champion.
Kurosawa's is a "heroic" cinema, a series of dramas (mostly) concerned with the deeds and fates of larger-than-life heroes. Stephen Prince has identified the emergence of the unique Kurosawa protagonist with the immediate post-World War II period. The goal of the American Occupation to replace Japanese feudalism with individualism coincided with the director's artistic and social agenda: "Kurosawa welcomed the changed political climate and sought to fashion his own mature cinematic voice." The Japanese critic Tadao Sato concurs: "With defeat in World War II, many Japanese... were dumbfounded to find that the government had lied to them and was neither just nor dependable. During this uncertain time Akira Kurosawa, in a series of first-rate films, sustained the people by his consistent assertion that the meaning of life is not dictated by the nation but something each individual should discover for himself through suffering." The filmmaker himself remarked that, during this period, "I felt that without the establishment of the self as a positive value there could be no freedom and no democracy."
The first such postwar hero was, atypically for the artist, a heroine—Yukie, played by Setsuko Hara, in "No Regrets for Our Youth". According to Prince, her "desertion of family and class background to assist a poor village, her perseverance in the face of enormous obstacles, her assumption of responsibility for her own life and for the well-being of others, and her existential loneliness... are essential to Kurosawan heroism and make of Yukie the first coherent... example." This "existential loneliness" is also exemplified by Dr. Sanada (Takashi Shimura) in "Drunken Angel": "Kurosawa insists that his heroes take their stand, alone, against tradition and battle for a better world, even if the path there is not clear. Separation from a corrupt social system in order to alleviate human suffering, as Sanada does, is the only honorable course."
Many commentators regard "Seven Samurai" as the ultimate expression of the artist's heroic ideal. Joan Mellen's comments are typical of this view: "Seven Samurai is above all a homage to the samurai class at its most noble... Samurai for Kurosawa represent the best of Japanese tradition and integrity." Ironically, it is because of, not in spite of, the chaotic times of civil war depicted in the film that the seven rise to greatness. "Kurosawa locates the unexpected benefits no less than the tragedy of this historical moment. The upheaval forces samurai to channel the selflessness of their credo of loyal service into working for peasants." However, this heroism is futile because "there was already rising... a merchant class which would supplant the warrior aristocracy." So the courage and supreme skill of the central characters will not prevent the ultimate destruction of themselves or their class.
As Kurosawa's career progressed he seemed to find it increasingly difficult to sustain the heroic ideal. As Prince notes, "Kurosawa's is an essentially tragic vision of life, and this sensibility... impedes his efforts to realize a socially committed mode of filmmaking." Furthermore, the director's ideal of heroism is subverted by history itself: "When history is articulated as it is in "Throne of Blood", as a blind force... heroism ceases to be a problem or a reality." According to Prince, the filmmaker's vision eventually became so bleak that he would come to view history merely as eternally recurring patterns of violence, within which the individual is depicted as not only unheroic, but utterly helpless (see "Cycles of violence" below).
Nature and weather.
Nature is a crucial element in Kurosawa's films. According to Stephen Prince, "Kurosawa's sensibility, like that of many Japanese artists, is keenly sensitive to the subtleties and beauties of season and scenery." He has never hesitated to exploit climate and weather as plot elements, to the point where they become "active participants in the drama... The oppressive heat in "Stray Dog" and "Record of a Living Being" is omnipresent and becomes thematized as a signifier of a world disjointed by economic collapse and the atomic threat." The director himself once said, "I like hot summers, cold winters, heavy rains and snows, and I think most of my pictures show this. I like extremes because I find them most alive."
Wind is also a powerful symbol: "The persistent metaphor of Kurosawa's work is that of wind, the winds of change, of fortune and adversity." "The visually flamboyant battle [of "Yojimbo" takes place in the main street, as huge clouds of dust swirl around the combatants... The winds that stir the dust... have brought firearms to the town along with the culture of the West, which will end the warrior tradition."
It is also difficult not to notice the importance of rain to Kurosawa: "Rain in Kurosawa's films is never treated neutrally. When it occurs... it is never a drizzle or a light mist but always a frenzied downpour, a driving storm." "The final battle "Seven Samurai" is a supreme spiritual and physical struggle, and it is fought in a blinding rainstorm, which enables Kurosawa to visualize an ultimate fusion of social groups... but this climactic vision of classlessness, with typical Kurosawan ambivalence, has become a vision of horror. The battle is a vortex of swirling rain and mud... The ultimate fusion of social identity emerges as an expression of hellish chaos."
Cycles of violence.
Beginning with "Throne of Blood" (1957), an obsession with historical cycles of inexorable savage violence—what Stephen Prince calls "the countertradition to the committed, heroic mode of Kurosawa's cinema"—first appears. According to Donald Richie, within the world of that film, "Cause and effect is the only law. Freedom does not exist." and Prince claims that its events "are inscribed in a cycle of time that infinitely repeats." (He uses as evidence the fact that Washizu's lord, unlike the kindly King Duncan of Shakespeare's play, had murdered his own lord years before to seize power, and is then murdered in turn by Washizu (the Macbeth character) for the same reason.) The following epic, "Ran", is "a relentless chronicle of base lust for power, betrayal of the father by his sons, and pervasive wars and murders." The historical setting of the film is used as "a commentary on what Kurosawa now perceives as the timelessness of human impulses toward violence and self-destruction." "Kurosawa has found hell to be both the inevitable outcome of human behavior and the appropriate visualization of his own bitterness and disappointment."
Criticisms.
Despite the extraordinary acclaim that Kurosawa's work has received in Japan and abroad, his films, as well as Kurosawa as an individual, have also been subject to considerable criticism, much of it harsh. Below are summarized some of the more common criticisms of the director, both those made generally and those that are primarily voiced in Japan.
In general.
In the early to mid-1950s, a number of critics belonging to the French New Wave championed the films of the older Japanese master, Kenji Mizoguchi, at the expense of Kurosawa's work. New Wave critic-filmmaker Jacques Rivette, said: "You can compare only what is comparable and that which aims high enough... seems to be the only Japanese director who is completely Japanese and yet is also the only one that achieves a true universality, that of an individual." According to such French commentators, Mizoguchi seemed, of the two artists, the more authentically Japanese. But at least one film scholar has questioned the validity of this dichotomy between "Japanese" Mizoguchi and "Western" Kurosawa by pointing out that "Mizo" had been as influenced by Western cinema and Western culture in general as Kurosawa, and that this is reflected in his work.
A criticism frequently directed at Kurosawa's films is that the director's preoccupation with ethical and moral themes led him at times to create what some commentators regard as sentimental or naïve work. Speaking of the postwar "slice of life" drama "One Wonderful Sunday", for example, film scholar (and future politician) Audie Bock claimed that not even Kurosawa's celebrated prowess as an editor could save one particular scene from bathos: "The last sequence... is an excruciating twelve minutes of the boy conducting an imaginary orchestra in an empty amphitheater while his girlfriend appeals directly to the camera for the viewer to join in. Angles and focal lengths change, details of leaves scattering in the wind are intercut, but nothing makes the scene go any faster."
Some controversy exists about the extent to which Kurosawa's films of the Second World War period could be considered fascist propaganda. The cultural historian Peter B. High sees Kurosawa's wartime cinema as part of the propagandistic trend of Japan at war and as an example of many of these wartime conventions. High refers to his second film, "The Most Beautiful", as a "dark and gloomy rendition of the standard formulas of the front genre." Another controversy centers on his alleged refusal to acknowledge Japan's wartime guilt. In one of Kurosawa's last films, "Rhapsody in August", an elderly survivor of the atomic attack on Nagasaki is visited by her half-Japanese, half-American nephew, Clark (Richard Gere), who appears (at least to some viewers) to apologize, as an American, for the city's wartime destruction. The "New York Times" critic Vincent Canby wrote about this film: "A lot of people at Cannes were outraged that the film makes no mention of Pearl Harbor and Japan's atrocities in China... If Clark can apologize for bombing Nagasaki, why can't Granny apologize for the raid on Pearl Harbor?"
A number of critics have reacted negatively to the female characters in Kurosawa's movies. Joan Mellen, in her examination of this subject, has maintained that, by the time of "Red Beard" (1965), "women in Kurosawa have become not only unreal and incapable of kindness, but totally bereft of autonomy, whether physical, intellectual, or emotional... Women at their best may only imitate the truths men discover." Kurosawa scholar Stephen Prince concurs with Mellen's view, though less censoriously: "Unlike a male-oriented director like Sam Peckinpah, Kurosawa is not hostile to women, but his general lack of interest in them should be regarded as a major limitation of his work."
In Japan.
In Japan, both critics and other filmmakers have sometimes accused his work of elitism, because of his focus on exceptional, heroic individuals and groups of men. In her commentary on the deluxe DVD edition of "Seven Samurai", Joan Mellen maintains that certain shots of the samurai characters Kambei and Kyuzo, which to her reveal Kurosawa "privileging" these samurai, "support the argument voiced by several Japanese critics that Kurosawa was an elitist... Kurosawa was hardly a progressive director, they argued, since his peasants could not discover among their own ranks leaders who might rescue the village. Instead, justifying the inequitable class structure of their society and ours, the peasants must rely on the aristocracy, the upper class, and in particular samurai, to ensure their survival... Kurosawa defended himself against this charge in his interview with me. 'I wanted to say that after everything the peasants were the stronger, closely clinging to the earth... It was the samurai who were weak because they were being blown by the winds of time.'"
Because of Kurosawa's popularity with European and American audiences from the early 1950s onward, he has not escaped the charge of deliberately catering to the tastes of Westerners to achieve or maintain that popularity. Joan Mellen, recording the violently negative reaction (in the 1970s) of the left-wing director Nagisa Oshima to Kurosawa and his work, states: "That Kurosawa had brought Japanese film to a Western audience meant Oshima that he must be pandering to Western values and politics." Kurosawa always strongly denied pandering to Western tastes: "He has never catered to a foreign audience" writes Audie Bock, "and has condemned those who do."
Kurosawa was often criticized by his countrymen for perceived "arrogant" behavior. It was in Japan that the (initially) disparaging nickname "Kurosawa Tennō"—"The Emperor Kurosawa"—was coined. "Like tennō", Yoshimoto claimed, "Kurosawa is said to cloister himself in his own small world, which is completely cut off from the everyday reality of the majority of Japanese. The nickname tennō is used in this sense to create an image of Kurosawa as a director who abuses his power solely for the purpose of self-indulgence."
Worldwide impact.
Reputation among filmmakers.
Many celebrated directors have been influenced by Kurosawa and/or have expressed admiration for his work. The filmmakers cited below are grouped according to three categories: a) those who, like Kurosawa himself, established international critical reputations in the 1950s and early 1960s; b) the so-called "New Hollywood" directors, that is, American moviemakers who, for the most part, established their reputations in the early to mid-1970s; and c) other Asian directors.
Ingmar Bergman called his own film "The Virgin Spring" "touristic, a lousy imitation of Kurosawa", and added, "At that time my admiration for the Japanese cinema was at its height. I was almost a samurai myself!" Federico Fellini in an interview declared the director "the greatest living example of all that an author of the cinema should be"—despite admitting to having seen only one of his films, "Seven Samurai". Roman Polanski in 1965 cited Kurosawa as one of his three favorite filmmakers (with Fellini and Orson Welles), singling out "Seven Samurai", "Throne of Blood" and "The Hidden Fortress" for praise. Bernardo Bertolucci considered the Japanese master's influence to be seminal: "Kurosawa's movies and "La Dolce Vita" of Fellini are the things that pushed me, sucked me into being a film director."
Kurosawa's "New Hollywood" admirers have included Robert Altman, Francis Ford Coppola, Steven Spielberg, Martin Scorsese, and John Milius. Robert Altman, when he first saw "Rashomon" (during the period when he worked regularly in television rather than feature films), was so impressed by its cinematographer's achievement of shooting several shots with the camera aimed directly at the sun—allegedly it was the first film in which this was done successfully—that he claims he was inspired the very next day to begin incorporating shots of the sun into his television work. It was Coppola who said of Kurosawa, "One thing that distinguishes is that he didn't make one masterpiece or two masterpieces. He made, you know, "eight" masterpieces." Both Spielberg and Scorsese have praised the older man's role as teacher and role model—as a "sensei", to use the Japanese term. Spielberg has declared, "I have learned more from him than from almost any other filmmaker on the face of the earth", Other Asian admirers include the Japanese actor and director Takeshi Kitano, Hong Kong filmmaker John Woo and mainland Chinese director Zhang Yimou, who called Kurosawa "the quintessential Asian director."
Legacy.
Kurosawa Production Co., established in 1959, continues to oversee much of Kurosawa's legacy. The director's son, Hisao Kurosawa, is the current head of the company. Its American subsidiary, Kurosawa Enterprises, is located in Los Angeles. Rights to Kurosawa's works are held by Kurosawa Production and the film studios under which he worked, most notably Toho. Kurosawa Production works closely with the Akira Kurosawa Foundation, established in December 2003 and also run by Hisao Kurosawa. The foundation organizes an annual short film competition and spearheads Kurosawa-related projects, including a recently shelved one to build a memorial museum for the director.
In 1981, the Kurosawa Film Studio was opened in Yokohama; two additional locations have since been launched in Japan. A large collection of archive material, including scanned screenplays, photos and news articles, has been made available through the Akira Kurosawa Digital Archive, a Japanese website maintained by Ryukoku University Digital Archives Research Center in collaboration with Kurosawa Production. Anaheim University's Akira Kurosawa School of Film was launched in spring 2009 with the backing of Kurosawa Production. It offers online programs in digital film making, with headquarters in Anaheim and a learning center in Tokyo.
Two film awards have also been named in Kurosawa's honor. The Akira Kurosawa Award for Lifetime Achievement in Film Directing is awarded during the San Francisco International Film Festival, while the Akira Kurosawa Award is given during the Tokyo International Film Festival. In commemoration of the 100th anniversary of Kurosawa's birth in 2010, a project called AK100 was launched in 2008. The AK100 Project aims to "expose young people who are the representatives of the next generation, and all people everywhere, to the light and spirit of Akira Kurosawa and the wonderful world he created."
Anaheim University in cooperation with the Kurosawa Family established the Anaheim University Akira Kurosawa School of Film to offer online and blended learning programs on Akira Kurosawa and filmmaking.
Filmography.
On home video.
All thirty films directed by Kurosawa are available on DVD worldwide, most of them from more than one distributor and in more than one region code. His films have begun to be released on Blu-ray.

</doc>
<doc id="874" url="http://it.wikipedia.org/wiki/?curid=874" title="Ancient Egypt">
Ancient Egypt

Ancient Egypt was an ancient civilization of Northeastern Africa, concentrated along the lower reaches of the Nile River in what is now the modern country of Egypt. Egyptian civilization coalesced around 3150 BC (according to conventional Egyptian chronology) with the political unification of Upper and Lower Egypt under the first pharaoh. The history of ancient Egypt occurred in a series of stable "Kingdoms", separated by periods of relative instability known as "Intermediate Periods": the Old Kingdom of the Early Bronze Age, the Middle Kingdom of the Middle Bronze Age and the New Kingdom of the Late Bronze Age. 
Egypt reached the pinnacle of its power during the New Kingdom, in the Ramesside period where it rivalled the Hittite Empire, Assyrian Empire and Mitanni Empire, after which it entered a period of slow decline. Egypt was invaded or conquered by a succession of foreign powers (such as the Canaanites/Hyksos, Libyans, Nubians, Assyria, Babylonia, Persian rule and Macedonian Greece) in the Third Intermediate Period of Egypt and Late Period. In the aftermath of Alexander the Great's death, one of his generals, Ptolemy Soter, established himself as the new ruler of Egypt. This Greek Ptolemaic Dynasty ruled Egypt until 30 BC, when, under Cleopatra, it fell to the Roman Empire and became a Roman province.
The success of ancient Egyptian civilization came partly from its ability to adapt to the conditions of the Nile River Valley. The predictable flooding and controlled irrigation of the fertile valley produced surplus crops, which fueled social development and culture. With resources to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military intended to defeat foreign enemies and assert Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of a Pharaoh who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.
The many achievements of the ancient Egyptians include the quarrying, surveying and construction techniques that facilitated the building of monumental pyramids, temples, and obelisks; a system of mathematics, a practical and effective system of medicine, irrigation systems and agricultural production techniques, the first known ships, Egypt left a lasting legacy. Its art and architecture were widely copied, and its antiquities carried off to far corners of the world. Its monumental ruins have inspired the imaginations of travellers and writers for centuries. A new-found respect for antiquities and excavations in the early modern period led to the scientific investigation of Egyptian civilization and a greater appreciation of its cultural legacy.
History.
The Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization. Nomadic modern human hunter-gatherers began living in the Nile valley through the end of the Middle Pleistocene some 120 thousand years ago. By the late Paleolithic period, the arid climate of Northern Africa became increasingly hot and dry, forcing the populations of the area to concentrate along the region.
Predynastic period.
In Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were covered in treed savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.
By about 5500 BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt, the Badari which probably originated in the Western Desert, was known for its high quality ceramics, stone tools, and its use of copper.
The Badari was followed by the Amratian (Naqada I) and Gerzeh (Naqada II) cultures, which brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. In Naqada II times, early evidence exists of contact with the Near East, particularly Canaan and the Byblos coast. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Hierakonpolis, and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east.
The Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually evolved into a full system of hieroglyphs for writing the ancient Egyptian language.
Early Dynastic Period (c. 3050 –2686 BC).
The transition to a unified state actually happened more gradually than ancient Egyptian writers would have us believe, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have actually been the pharaoh Narmer, who is depicted wearing royal regalia on the ceremonial Narmer Palette in a symbolic act of unification. In the Early Dynastic Period about 3150 BC, the first of the Dynastic pharaohs solidified their control over lower Egypt by establishing a capital at Memphis, from which they could control the labour force and agriculture of the fertile delta region as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the pharaohs during the early dynastic period was reflected in their elaborate mastaba tombs and mortuary cult structures at Abydos, which were used to celebrate the deified pharaoh after his death. The strong institution of kingship developed by the pharaohs served to legitimize state control over the land, labour, and resources that were essential to the survival and growth of ancient Egyptian civilization.
[[File:NarmerPalette ROM-gamma.jpg|thumb|The Narmer Palette depicts the unification
of the Two Lands.]]
Old Kingdom (2686–2181 BC).
 advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity made possible by a well-developed central administration. Some of Ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, drafted peasants to work on construction projects, and established a justice system to maintain peace and order. 
Along with the rising importance of a central administration arose a new class of educated scribes and officials who were granted estates by the pharaoh in payment for their services. Pharaohs also made land grants to their mortuary cults and local temples to ensure that these institutions had the resources to worship the pharaoh after his death. It is believed that five centuries of these practices slowly eroded the economic power of the pharaoh, and that the economy could no longer afford to support a large centralized administration. As the power of the pharaoh diminished, regional governors called nomarchs began to challenge the supremacy of the pharaoh. This, coupled with severe droughts between 2200 and 2150 BC, is assumed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.
First Intermediate Period (2181–1991 BC).
After Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. Regional governors could not rely on the king for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the pharaoh, used their newfound independence to establish a thriving culture in the provinces. Once in control of their own resources, the provinces became economically richer—a fact demonstrated by larger and better burials among all social classes. In bursts of creativity, provincial artisans adopted and adapted cultural motifs formerly restricted to the royalty of the Old Kingdom, and scribes developed literary styles that expressed the optimism and originality of the period.
Free from their loyalties to the pharaoh, local rulers began competing with each other for territorial control and political power. By 2160 BC, rulers in Herakleopolis controlled Lower Egypt in the north, while a rival clan based in Thebes, the Intef family, took control of Upper Egypt in the south. As the Intefs grew in power and expanded their control northward, a clash between the two rival dynasties became inevitable. Around 2055 BC the northern Theban forces under Nebhepetre Mentuhotep II finally defeated the Herakleopolitan rulers, reuniting the Two Lands and inaugurating a period of economic and cultural renaissance known as the Middle Kingdom.
Middle Kingdom (2134–1690 BC).
The pharaohs of the Middle Kingdom restored the country's prosperity and stability, thereby stimulating a resurgence of art, literature, and monumental building projects. Mentuhotep II and his 11th Dynasty successors ruled from Thebes, but the vizier Amenemhat I, upon assuming kingship at the beginning of the 12th Dynasty around 1985 BC, shifted the nation's capital to the city of Itjtawy located in Faiyum. From Itjtawy, the pharaohs of the 12th Dynasty undertook a far-sighted land reclamation and irrigation scheme to increase agricultural output in the region. Moreover, the military reconquered territory in Nubia rich in quarries and gold mines, while laborers built a defensive structure in the Eastern Delta, called the "Walls-of-the-Ruler", to defend against foreign attack.
Having secured military and political security and vast agricultural and mineral wealth, the nation's population, arts, and religion flourished. In contrast to elitist Old Kingdom attitudes towards the gods, the Middle Kingdom experienced an increase in expressions of personal piety and what could be called a democratization of the afterlife, in which all people possessed a soul and could be welcomed into the company of the gods after death. Middle Kingdom literature featured sophisticated themes and characters written in a confident, eloquent style,
The last great ruler of the Middle Kingdom, Amenemhat III, allowed Semitic speaking Canaanite settlers from the Near East into the delta region to provide a sufficient labour force for his especially active mining and building campaigns. These ambitious building and mining activities, however, combined with severe Nile floods later in his reign, strained the economy and precipitated the slow decline into the Second Intermediate Period during the later 13th and 14th dynasties. During this decline, the Canaanite settlers began to seize control of the delta region, eventually coming to power in Egypt as the Hyksos.
Second Intermediate Period (1674–1549 BC) and the Hyksos.
Around 1785 BC, as the power of the Middle Kingdom pharaohs weakened, a Semitic Canaanite people called the Hyksos had already settled in the Eastern Delta town of Avaris seized control of Egypt, and forced the central government to retreat to Thebes, where the pharaoh was treated as a vassal and expected to pay tribute. The Hyksos ("foreign rulers") retained Egyptian models of government and portrayed themselves as pharaohs, thus integrating Egyptian elements into their culture. They and Semitic invaders introduced new tools of warfare into Egypt, most notably the composite bow and the horse-drawn chariot.
After their retreat, the native Theban kings found themselves trapped between the Canaanite Hyksos ruling the north and the Hyksos' Nubian allies, the Kushites, to the south of Egypt. After years of vassalage, Thebes gathered enough strength to challenge the Hyksos in a conflict that lasted more than 30 years, until 1555 BC 
New Kingdom (1549–1069 BC).
The New Kingdom pharaohs established a period of unprecedented prosperity by securing their borders and strengthening diplomatic ties with their neighbours, including the Mitanni Empire, Assyria, and Canaan. Military campaigns waged under Tuthmosis I and his grandson Tuthmosis III extended the influence of the pharaohs to the largest empire Egypt had ever seen. Between their reigns, Hatshepsut generally promoted peace and extended trade routes back to those lost during the Hyksos occupation, as well as venturing to new regions. When Tuthmosis III died in 1425 BC, Egypt had an empire extending from Niya in north west Syria to the fourth waterfall of the Nile in Nubia, cementing loyalties and opening access to critical imports such as bronze and wood. 
The New Kingdom pharaohs began a large-scale building campaign to promote the god Amun, whose growing cult was based in Karnak. They also constructed monuments to glorify their own achievements, both real and imagined. The pharaoh Hatshepsut used such hyperbole and grandeur during her reign of almost twenty-two years. Her reign was very successful, marked by an extended period of peace and wealth-building, trading expeditions to Punt, restoration of foreign trade networks, great building projects including an elegant mortuary temple that rivaled the Greek architecture of a thousand years later, a colossal pair of obelisks, and a chapel at Karnak. Despite her achievements, the heir to Hatshepsut's nephew-stepson Tuthmosis III, Amenhotep II, sought to erase her legacy near the end of his father's reign and throughout his, touting many of her accomplishments as his. He also attempted to change many established traditions that had developed over the centuries, which some suggest was a futile attempt to prevent other women from becoming pharaoh and to curb their influence in the kingdom.
Around 1350 BC, the stability of the New Kingdom seemed threatened further when Amenhotep IV ascended the throne and instituted a series of radical and chaotic reforms. Changing his name to Akhenaten, he touted the previously obscure sun deity Aten as the supreme deity, suppressed the worship of most other deities and attacked the power of the temple that had become dominated by the priests of Amun in Thebes, whom he saw as corrupt. Moving the capital to the new city of Akhetaten (modern-day Amarna), Akhenaten turned a deaf ear to events in the Near East (where the Hittites, Mitanni, and Assyrians were vying for control) and absorbed himself in his new religion and artistic style. After his death, the cult of the Aten was quickly abandoned, the priests of Amun soon regained power and returned the capital to Thebes, and under their influence the subsequent pharaohs Tutankhamun, Ay, and Horemheb attempted to erase all mention of Akhenaten's heresy, now known as the Amarna Period.
Around 1279 BC, Ramesses II, also known as Ramesses the Great, ascended the throne, and went on to build more temples, erect more statues and obelisks, and sire more children than any other pharaoh in history. A bold military leader, Ramesses II led his army against the Hittites in the Battle of Kadesh (in modern Syria) and, after fighting to a stalemate, finally agreed to the first recorded peace treaty, around 1258 BC. With both the Egyptians and Hittite Empire proving unable to gain the upper hand over one another, and both powers also fearful of the expanding Middle Assyrian Empire, Egypt withdraw from much of the Near East. The Hittites were thus left to compete unsuccessfully with the powerful Assyrians and the newly arrived Phrygians. 
Egypt's wealth, however, made it a tempting target for invasion, particularly by the Libyan Berbers to the west, and the Sea Peoples, a powerful confederation of largely Greek, Luwian and Phoenician/Caananite pirates from the Aegean. Initially, the military was able to repel these invasions, but Egypt eventually lost control of its remaining territories in southern Caanan, much of it falling to the Assyrians. The impact of external threats was exacerbated by internal problems such as corruption, tomb robbery, and civil unrest. After regaining their power, the high priests at the temple of Amun in Thebes accumulated vast tracts of land and wealth and their expanded power splintered the country during the Third Intermediate Period.
Third Intermediate Period (1069 – 653 BC).
Following the death of Ramesses XI in 1078 BC, Smendes assumed authority over the northern part of Egypt, ruling from the city of Tanis. The south was effectively controlled by the High Priests of Amun at Thebes, who recognized Smendes in name only. During this time, Berber tribes from what was later to be called Libya had been settling in the western delta and the chieftains of these settlers began increasing their autonomy. Libyan princes took control of the delta under Shoshenq I in 945 BC, founding the so-called Libyan Berber, or Bubastite, dynasty that ruled for some 200 years. Shoshenq also gained control of southern Egypt by placing his family members in important priestly positions. 
In the mid 9th century BC, Egypt made a failed attempt to once more gain a foothold in Western Asia. Osorkon II of Egypt, along with a large alliance of nations and peoples, including; Israel, Hamath, Phoenicia/Caanan, the Arabs, Arameans, and neo Hittites among others engaged in the Battle of Karkar against the powerful Assyrian king Shalmaneser III in 853 BC, however this coalition of powers failed, and the Assyrian Empire continued to dominate the region.
Libyan Berber control began to erode as a rival native dynasty in the delta arose in Leontopolis. Also, the Nubians of the Kushites threatened Egypt from the lands to the south.
Drawing on millennia of interaction (trade, acculturation, occupation, assimilation, and war) with Egypt, the Kushite king Piye left his Nubian capital of Napata and invaded Egypt around 727 BC. Piye easily seized control of Thebes and eventually the Nile Delta. He recorded the episode on his stela of victory. Piye set the stage for subsequent 25th dynasty pharaohs, such as Taharqa, to reunite the "Two lands" of Northern and Southern Egypt. The Nile valley empire was as large as it had been since the New Kingdom. The 25th dynasty ushered in a renaissance period for Ancient Egypt. Religion, the arts, and architecture were restored to their glorious Old, Middle, and New Kingdom forms. Pharaohs, such as Taharqa, built or restored temples and monuments throughout the Nile valley, including at Memphis, Karnak, Kawa, Jebel Barkal, etc. It was during the 25th dynasty that the Nile valley saw the first widespread construction of pyramids (many in modern Sudan) since the Middle Kingdom. 
Piye made various unsuccessful attempts to extend Egyptian influence in the Near East, then controlled by Assyria. In 720 BC he sent an army in support a rebellion against Assyria in Philistia and Gaza, however Piye was defeated by Sargon II, and the rebellion failed. In 711 BC Piye again supported a revolt against the Assyrians by the Israelites of Ashdod, and was once again defeated by the Assyrian king Sargon II, and Piye was forced from the Near East.
Egypt's international prestige declined considerably towards the end of the Third Intermediate Period. From the 10th century BC onwards, its allies in the Southern Levant had fallen to the Assyrian Empire, and by 700 BC war between the two Empires became inevitable. Taharqa enjoyed some initial minor success in his attempts to regain a foothold in the Near East. He aided the Judean King Hezekiah when the latter was attacked by Sennacherib, the Assyrian king, who was besieging Jerusalem (2 Kings 19:9;Isaiah 37:9), however disease among the besiegers appears to have been the primary reason for failing to actually take the city, and Senacherib's annals claim Judah was forced into tribute regardless. Eventually however, the Assyrian King Sennacherib defeated Taharqa and drove the Egyptians and Nubians from the Near East. 
The Assyrians, tiring of Egyptian meddling in its empire, began their invasion of Egypt under king Esarhaddon, successor of Sennacherib, who had been murdered by his own sons for destroying the rebellious city of Babylon. Taharqa was easily routed, and driven from power by Esarhaddon who conquered Egypt with surprising speed, thus destroying the Kushite Empire in the process. Defeated, Taharqa fled back to his Nubian homeland. Esarhaddon describes; "installing local kings and governors" and "All Ethiopians (Nubians/Kushites) I deported from Egypt,leaving not one to do homage to me". However, the native rulers installed by Esarhaddon were unable to retain full control of the whole country for long. Two years later, Taharqa returned from Nubia and seized control of a section of southern Egypt as far north as Memphis. Esarhaddon prepared to return to Egypt and once more eject Taharqa, however he fell ill and died in his capital Nineveh before he left Assyria. His successor, Ashurbanipal, sent a general with a small but well trained army which defeated and ejected Taharqa from Memphis, and once more drove him from Egypt. Taharqa died in Nubia two years later. 
His successor, Tanutamun, also made a failed attempt to regain Egypt for Nubia. He successfully defeated Necho, the puppet ruler installed by Ashurbanipal, taking Thebes in the process. The Assyrians then sent a large army southwards. Tantamani (Tanutamun) was heavily routed and fled back to Nubia. The Assyrian army sacked Thebes to such an extent it never truly recovered. A native ruler, Psammetichus I was placed on the throne, as a vassal of Ashurbanipal, and the Nubians were never again to pose a threat.
Late Period (672 – 332 BC).
With no permanent plans for conquest, the Assyrians left control of Egypt to a series of vassals who became known as the Saite kings of the Twenty-Sixth Dynasty. By 653 BC, the Saite king Psamtik I (taking advantage of the fact that Assyria was involved in a fierce war conquering Elam and that few Assyrian troops were stationed in Egypt) was able to free Egypt relatively peacefully from Assyrian vassalage with the help of Lydian and Greek mercenaries, the latter of who were recruited to form Egypt's first navy. Psamtik and his successors however, were careful to maintain peaceful relations with Assyria. Greek influence expanded greatly as the city of Naukratis became the home of Greeks in the delta. In 609 BC Necho II went to war with Babylonia, the Chaldeans, the Medians and the Scythians in an attempt to save Assyria, which after a brutal internal civil war was being ovverrun by this coalition of powers. However, the attempt to save Egypts former masters failed. The Egyptians delayed intervening too long, and Nineveh had already fallen and King Sin-shar-ishkun was dead by the time Necho II sent his armies northwards. However Necho easily brushed aside the Israelite army under King Josiah but he and the Assyrians then lost a battle at Harran to the Babylonians, Medes and Scythians. Necho II and Ashur-uballit II of Assyria were finally defeated at Carchemish in Aramea (modern Syria) in 605 BC. The Egyptians remained in the area for some dacades, struggling with the Babylonian kings Nabopolassar and Nebuchadnezzar II for control of portions of the former Assyrian Empire in The Levant. However, they were eventually driven back into Egypt, and Nebuchadnezzar II even briefly invaded Egypt itself in 567 BC.
Following its annexation by Persia, Egypt was joined with Cyprus and Phoenicia (modern Lebanon) in the sixth satrapy of the Achaemenid Persian Empire. This first period of Persian rule over Egypt, also known as the Twenty-Seventh dynasty, ended in 402 BC, and from 380–343 BC the Thirtieth Dynasty ruled as the last native royal house of dynastic Egypt, which ended with the kingship of Nectanebo II. A brief restoration of Persian rule, sometimes known as the Thirty-First Dynasty, began in 343 BC, but shortly after, in 332 BC, the Persian ruler Mazaces handed Egypt over to the Macedonian ruler Alexander the Great without a fight.
Ptolemaic dynasty.
In 332 BC, Alexander the Great conquered Egypt with little resistance from the Persians and was welcomed by the Egyptians as a deliverer. The administration established by Alexander's successors, the Macedonian Ptolemaic dynasty, was based on an Egyptian model and based in the new capital city of Alexandria. The city showcased the power and prestige of Hellenistic rule, and became a seat of learning and culture, centered at the famous Library of Alexandria. The Lighthouse of Alexandria lit the way for the many ships that kept trade flowing through the city—as the Ptolemies made commerce and revenue-generating enterprises, such as papyrus manufacturing, their top priority.
Hellenistic culture did not supplant native Egyptian culture, as the Ptolemies supported time-honored traditions in an effort to secure the loyalty of the populace. They built new temples in Egyptian style, supported traditional cults, and portrayed themselves as pharaohs. Some traditions merged, as Greek and Egyptian gods were syncretized into composite deities, such as Serapis, and classical Greek forms of sculpture influenced traditional Egyptian motifs. Despite their efforts to appease the Egyptians, the Ptolemies were challenged by native rebellion, bitter family rivalries, and the powerful mob of Alexandria that formed after the death of Ptolemy IV. In addition, as Rome relied more heavily on imports of grain from Egypt, the Romans took great interest in the political situation in the country. Continued Egyptian revolts, ambitious politicians, and powerful Syriac opponents from the Near East made this situation unstable, leading Rome to send forces to secure the country as a province of its empire.
Roman Period.
Egypt became a province of the Roman Empire in 30 BC, following the defeat of Marc Antony and Ptolemaic Queen Cleopatra VII by Octavian (later Emperor Augustus) in the Battle of Actium. The Romans relied heavily on grain shipments from Egypt, and the Roman army, under the control of a prefect appointed by the Emperor, quelled rebellions, strictly enforced the collection of heavy taxes, and prevented attacks by bandits, which had become a notorious problem during the period. Alexandria became an increasingly important center on the trade route with the orient, as exotic luxuries were in high demand in Rome.
Although the Romans had a more hostile attitude than the Greeks towards the Egyptians, some traditions such as mummification and worship of the traditional gods continued. The art of mummy portraiture flourished, and some of the Roman emperors had themselves depicted as pharaohs, though not to the extent that the Ptolemies had. The former lived outside Egypt and did not perform the ceremonial functions of Egyptian kingship. Local administration became Roman in style and closed to native Egyptians. In 391 the Christian Emperor Theodosius introduced legislation that banned pagan rites and closed temples. Alexandria became the scene of great anti-pagan riots with public and private religious imagery destroyed. As a consequence, Egypt's native religious culture was continually in decline. While the native population certainly continued to speak their language, the ability to read hieroglyphic writing slowly disappeared as the role of the Egyptian temple priests and priestesses diminished. The temples themselves were sometimes converted to churches or abandoned to the desert.
In the 4th century AD, the Roman Empire split into two, and Egypt became part of the Eastern Empire, known as the Byzantine Empire. The Eastern Empire became increasingly "oriental" and "Eastern" in style, as its links with the old Greco-Roman world faded. The Greek system of local government by citizens had now entirely disappeared.
The Sassanid Persians who were involved in a long running and draining war with Byzantium for control of the Near East, Asia Minor, North Africa and the east Mediterranean, briefly recaptured Egypt under King Khosrow II in 618 AD, but were ejected by the Byzantine Emperor Heraclius in 628 AD.
Arab Muslim Period.
An army of 4,000 Arabs led by Amr Ibn Al-Aas was sent by the Caliph Umar, successor to Muhammad, to spread Islamic rule to the west. The Arabs crossed into Egypt from Palestine in December 639 AD, and advanced rapidly into the Nile Delta. The Imperial garrisons, exhausted by constant war with the Persians, retreated into the walled towns, where they successfully held out for a year or more. But the Arabs sent for reinforcements, and in April 641 they captured Alexandria. The Byzantines did assemble a fleet with the aim of recapturing Egypt, and won back Alexandria in 645, but the Muslims retook the city in 646, completing the Arab Muslim conquest of Egypt. Thus ended 975 years of Græco-Roman rule over Egypt.
Local resistance by the native Egyptian Copts however began to materialize shortly thereafter and would last until at least the 9th century.
The Arabs imposed a special tax, known as Jizya, on the Egyptians, who were by this time Coptic Christians. They acquired the status of dhimmis, and all native Egyptians were prohibited from joining the army. The Arabs in the 7th century used the term "quft" to describe the indigenous people of Egypt. Thus, Egyptians became known as Copts, and the non-Chalcedonian Egyptian Church became known as the Coptic Church.
The indigenous population of Egypt was gradually and largely "Arabized" and "Islamicized" over the following centuries, However, native Egyptian identity and language survived among the Copts, who spoke the Coptic language, a direct descendant of the Demotic Egyptian (which itself was an evolution of Ancient Egyptian) spoken in the Roman era. Since the 18th century, Coptic has mostly been limited to liturgical use and today Coptic is extinct as a primary language. Copts still to this day espouse an Egyptian rather than Arab ethnic identity.
Government and economy.
Administration and commerce.
The pharaoh was the absolute monarch of the country and, at least in theory, wielded complete control of the land and its resources. The king was the supreme military commander and head of the government, who relied on a bureaucracy of officials to manage his affairs. In charge of the administration was his second in command, the vizier, who acted as the king's representative and coordinated land surveys, the treasury, building projects, the legal system, and the archives. At a regional level, the country was divided into as many as 42 administrative regions called nomes each governed by a nomarch, who was accountable to the vizier for his jurisdiction. The temples formed the backbone of the economy. Not only were they houses of worship, but were also responsible for collecting and storing the nation's wealth in a system of granaries and treasuries administered by overseers, who redistributed grain and goods.
Much of the economy was centrally organized and strictly controlled. Although the ancient Egyptians did not use coinage until the Late period, they did use a type of money-barter system, with standard sacks of grain and the "deben", a weight of roughly of copper or silver, forming a common denominator. Workers were paid in grain; a simple laborer might earn 5½ sacks (200 kg or 400 lb) of grain per month, while a foreman might earn 7½ sacks (250 kg or 550 lb). Prices were fixed across the country and recorded in lists to facilitate trading; for example a shirt cost five copper deben, while a cow cost 140 deben.
Social status.
Egyptian society was highly stratified, and social status was expressly displayed. Farmers made up the bulk of the population, but agricultural produce was owned directly by the state, temple, or noble family that owned the land. Farmers were also subject to a labor tax and were required to work on irrigation or construction projects in a corvée system. Artists and craftsmen were of higher status than farmers, but they were also under state control, working in the shops attached to the temples and paid directly from the state treasury. Scribes and officials formed the upper class in ancient Egypt, the so-called "white kilt class" in reference to the bleached linen garments that served as a mark of their rank. The upper class prominently displayed their social status in art and literature. Below the nobility were the priests, physicians, and engineers with specialized training in their field. Slavery was known in ancient Egypt, but the extent and prevalence of its practice are unclear. 
The ancient Egyptians viewed men and women, including people from all social classes except slaves, as essentially equal under the law, and even the lowliest peasant was entitled to petition the vizier and his court for redress. Both men and women had the right to own and sell property, make contracts, marry and divorce, receive inheritance, and pursue legal disputes in court. Married couples could own property jointly and protect themselves from divorce by agreeing to marriage contracts, which stipulated the financial obligations of the husband to his wife and children should the marriage end. Compared with their counterparts in ancient Greece, Rome, and even more modern places around the world, ancient Egyptian women had a greater range of personal choices and opportunities for achievement. Women such as Hatshepsut and Cleopatra VI even became pharaohs, while others wielded power as Divine Wives of Amun. Despite these freedoms, ancient Egyptian women did not often take part in official roles in the administration, served only secondary roles in the temples, and were not as likely to be as educated as men. Local councils of elders, known as "Kenbet" in the New Kingdom, were responsible for ruling in court cases involving small claims and minor disputes.
Punishment for minor crimes involved either imposition of fines, beatings, facial mutilation, or exile, depending on the severity of the offense. Serious crimes such as murder and tomb robbery were punished by execution, carried out by decapitation, drowning, or impaling the criminal on a stake. Punishment could also be extended to the criminal's family.
Agriculture.
A combination of favorable geographical features contributed to the success of ancient Egyptian culture, the most important of which was the rich fertile soil resulting from annual inundations of the Nile River. The ancient Egyptians were thus able to produce an abundance of food, allowing the population to devote more time and resources to cultural, technological, and artistic pursuits. Land management was crucial in ancient Egypt because taxes were assessed based on the amount of land a person owned.
Farming in Egypt was dependent on the cycle of the Nile River. The Egyptians recognized three seasons: "Akhet" (flooding), "Peret" (planting), and "Shemu" (harvesting). The flooding season lasted from June to September, depositing on the river's banks a layer of mineral-rich silt ideal for growing crops. After the floodwaters had receded, the growing season lasted from October to February. Farmers plowed and planted seeds in the fields, which were irrigated with ditches and canals. Egypt received little rainfall, so farmers relied on the Nile to water their crops. From March to May, farmers used sickles to harvest their crops, which were then threshed with a flail to separate the straw from the grain. Winnowing removed the chaff from the grain, and the grain was then ground into flour, brewed to make beer, or stored for later use.
The ancient Egyptians cultivated emmer and barley, and several other cereal grains, all of which were used to make the two main food staples of bread and beer. Flax plants, uprooted before they started flowering, were grown for the fibers of their stems. These fibers were split along their length and spun into thread, which was used to weave sheets of linen and to make clothing. Papyrus growing on the banks of the Nile River was used to make paper. Vegetables and fruits were grown in garden plots, close to habitations and on higher ground, and had to be watered by hand. Vegetables included leeks, garlic, melons, squashes, pulses, lettuce, and other crops, in addition to grapes that were made into wine.
Animals.
The Egyptians believed that a balanced relationship between people and animals was an essential element of the cosmic order; thus humans, animals and plants were believed to be members of a single whole. Animals, both domesticated and wild, were therefore a critical source of spirituality, companionship, and sustenance to the ancient Egyptians. Cattle were the most important livestock; the administration collected taxes on livestock in regular censuses, and the size of a herd reflected the prestige and importance of the estate or temple that owned them. In addition to cattle, the ancient Egyptians kept sheep, goats, and pigs. Poultry such as ducks, geese, and pigeons were captured in nets and bred on farms, where they were force-fed with dough to fatten them. The Nile provided a plentiful source of fish. Bees were also domesticated from at least the Old Kingdom, and they provided both honey and wax.
The ancient Egyptians used donkeys and oxen as beasts of burden, and they were responsible for plowing the fields and trampling seed into the soil. The slaughter of a fattened ox was also a central part of an offering ritual.
Natural resources.
Egypt is rich in building and decorative stone, copper and lead ores, gold, and semiprecious stones. These natural resources allowed the ancient Egyptians to build monuments, sculpt statues, make tools, and fashion jewelry. Embalmers used salts from the Wadi Natrun for mummification, which also provided the gypsum needed to make plaster. Ore-bearing rock formations were found in distant, inhospitable wadis in the eastern desert and the Sinai, requiring large, state-controlled expeditions to obtain natural resources found there. There were extensive gold mines in Nubia, and one of the first maps known is of a gold mine in this region. The Wadi Hammamat was a notable source of granite, greywacke, and gold. Flint was the first mineral collected and used to make tools, and flint handaxes are the earliest pieces of evidence of habitation in the Nile valley. Nodules of the mineral were carefully flaked to make blades and arrowheads of moderate hardness and durability even after copper was adopted for this purpose. Ancient Egyptians were among the first to use minerals such as sulfur as cosmetic substances.
The Egyptians worked deposits of the lead ore galena at Gebel Rosas to make net sinkers, plumb bobs, and small figurines. Copper was the most important metal for toolmaking in ancient Egypt and was smelted in furnaces from malachite ore mined in the Sinai. Workers collected gold by washing the nuggets out of sediment in alluvial deposits, or by the more labor-intensive process of grinding and washing gold-bearing quartzite. Iron deposits found in upper Egypt were utilized in the Late Period. High-quality building stones were abundant in Egypt; the ancient Egyptians quarried limestone all along the Nile valley, granite from Aswan, and basalt and sandstone from the wadis of the eastern desert. Deposits of decorative stones such as porphyry, greywacke, alabaster, and carnelian dotted the eastern desert and were collected even before the First Dynasty. In the Ptolemaic and Roman Periods, miners worked deposits of emeralds in Wadi Sikait and amethyst in Wadi el-Hudi.
Trade.
The ancient Egyptians engaged in trade with their foreign neighbors to obtain rare, exotic goods not found in Egypt. In the Predynastic Period, they established trade with Nubia to obtain gold and incense. They also established trade with Palestine, as evidenced by Palestinian-style oil jugs found in the burials of the First Dynasty pharaohs. An Egyptian colony stationed in southern Canaan dates to slightly before the First Dynasty. Narmer had Egyptian pottery produced in Canaan and exported back to Egypt.
By the Second Dynasty at latest, ancient Egyptian trade with Byblos yielded a critical source of quality timber not found in Egypt. By the Fifth Dynasty, trade with Punt provided gold, aromatic resins, ebony, ivory, and wild animals such as monkeys and baboons. Egypt relied on trade with Anatolia for essential quantities of tin as well as supplementary supplies of copper, both metals being necessary for the manufacture of bronze. The ancient Egyptians prized the blue stone lapis lazuli, which had to be imported from far-away Afghanistan. Egypt's Mediterranean trade partners also included Greece and Crete, which provided, among other goods, supplies of olive oil. In exchange for its luxury imports and raw materials, Egypt mainly exported grain, gold, linen, and papyrus, in addition to other finished goods including glass and stone objects.
Language.
Historical development.
The Egyptian language is a northern Afro-Asiatic language closely related to the Berber and Semitic languages. It has the second longest history of any language (after Sumerian), having been written from c. 3200 BC to the Middle Ages and remaining as a spoken language for longer. The phases of Ancient Egyptian are Old Egyptian, Middle Egyptian (Classical Egyptian), Late Egyptian, Demotic and Coptic. Egyptian writings do not show dialect differences before Coptic, but it was probably spoken in regional dialects around Memphis and later Thebes.
Ancient Egyptian was a synthetic language, but it became more analytic later on. Late Egyptian develops prefixal definite and indefinite articles, which replace the older inflectional suffixes. There is a change from the older verb–subject–object word order to subject–verb–object. The Egyptian hieroglyphic, hieratic, and demotic scripts were eventually replaced by the more phonetic Coptic alphabet. Coptic is still used in the liturgy of the Egyptian Orthodox Church, and traces of it are found in modern Egyptian Arabic.
Sounds and grammar.
Ancient Egyptian has 25 consonants similar to those of other Afro-Asiatic languages. These include pharyngeal and emphatic consonants, voiced and voiceless stops, voiceless fricatives and voiced and voiceless affricates. It has three long and three short vowels, which expanded in Later Egyptian to about nine. The basic word in Egyptian, similar to Semitic and Berber, is a triliteral or biliteral root of consonants and semiconsonants. Suffixes are added to form words. The verb conjugation corresponds to the person. For example, the triconsonantal skeleton is the semantic core of the word 'hear'; its basic conjugation is ', 'he hears'. If the subject is a noun, suffixes are not added to the verb: ', 'the woman hears'.
Adjectives are derived from nouns through a process that Egyptologists call "nisbation" because of its similarity with Arabic. The word order is in verbal and adjectival sentences, and in nominal and adverbial sentences. The subject can be moved to the beginning of sentences if it is long and is followed by a resumptive pronoun. Verbs and nouns are negated by the particle "n", but "nn" is used for adverbial and adjectival sentences. Stress falls on the ultimate or penultimate syllable, which can be open (CV) or closed (CVC).
Writing.
Hieroglyphic writing dates from c. 3000 BC, and is composed of hundreds of symbols. A hieroglyph can represent a word, a sound, or a silent determinative; and the same symbol can serve different purposes in different contexts. Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art. In day-to-day writing, scribes used a cursive form of writing, called hieratic, which was quicker and easier. While formal hieroglyphs may be read in rows or columns in either direction (though typically written from right to left), hieratic was always written from right to left, usually in horizontal rows. A new form of writing, Demotic, became the prevalent writing style, and it is this form of writing—along with formal hieroglyphs—that accompany the Greek text on the Rosetta Stone.
Around the 1st century AD, the Coptic alphabet started to be used alongside the Demotic script. Coptic is a modified Greek alphabet with the addition of some Demotic signs. Although formal hieroglyphs were used in a ceremonial role until the 4th century, towards the end only a small handful of priests could still read them. As the traditional religious establishments were disbanded, knowledge of hieroglyphic writing was mostly lost. Attempts to decipher them date to the Byzantine and Islamic periods in Egypt, but only in 1822, after the discovery of the Rosetta stone and years of research by Thomas Young and Jean-François Champollion, were hieroglyphs almost fully deciphered.
Literature.
Writing first appeared in association with kingship on labels and tags for items found in royal tombs. It was primarily an occupation of the scribes, who worked out of the "Per Ankh" institution or the House of Life. The latter comprised offices, libraries (called House of Books), laboratories and observatories. Some of the best-known pieces of ancient Egyptian literature, such as the Pyramid and Coffin Texts, were written in Classical Egyptian, which continued to be the language of writing until about 1300 BC. Later Egyptian was spoken from the New Kingdom onward and is represented in Ramesside administrative documents, love poetry and tales, as well as in Demotic and Coptic texts. During this period, the tradition of writing had evolved into the tomb autobiography, such as those of Harkhuf and Weni. The genre known as "Sebayt" ("Instructions") was developed to communicate teachings and guidance from famous nobles; the Ipuwer papyrus, a poem of lamentations describing natural disasters and social upheaval, is a famous example.
The Story of Sinuhe, written in Middle Egyptian, might be the classic of Egyptian literature. Also written at this time was the Westcar Papyrus, a set of stories told to Khufu by his sons relating the marvels performed by priests. The Instruction of Amenemope is considered a masterpiece of near-eastern literature. Towards the end of the New Kingdom, the vernacular language was more often employed to write popular pieces like the Story of Wenamun and the Instruction of Any. The former tells the story of a noble who is robbed on his way to buy cedar from Lebanon and of his struggle to return to Egypt. From about 700 BC, narrative stories and instructions, such as the popular Instructions of Onchsheshonqy, as well as personal and business documents were written in the demotic script and phase of Egyptian. Many stories written in demotic during the Graeco-Roman period were set in previous historical eras, when Egypt was an independent nation ruled by great pharaohs such as Ramesses II.
Culture.
Daily life.
Most ancient Egyptians were farmers tied to the land. Their dwellings were restricted to immediate family members, and were constructed of mud-brick designed to remain cool in the heat of the day. Each home had a kitchen with an open roof, which contained a grindstone for milling flour and a small oven for baking the bread. Walls were painted white and could be covered with dyed linen wall hangings. Floors were covered with reed mats, while wooden stools, beds raised from the floor and individual tables comprised the furniture.
The ancient Egyptians placed a great value on hygiene and appearance. Most bathed in the Nile and used a pasty soap made from animal fat and chalk. Men shaved their entire bodies for cleanliness; perfumes and aromatic ointments covered bad odors and soothed skin. Clothing was made from simple linen sheets that were bleached white, and both men and women of the upper classes wore wigs, jewelry, and cosmetics. Children went without clothing until maturity, at about age 12, and at this age males were circumcised and had their heads shaved. Mothers were responsible for taking care of the children, while the father provided the family's income.
Music and dance were popular entertainments for those who could afford them. Early instruments included flutes and harps, while instruments similar to trumpets, oboes, and pipes developed later and became popular. In the New Kingdom, the Egyptians played on bells, cymbals, tambourines, drums, and imported lutes and lyres from Asia. The sistrum was a rattle-like musical instrument that was especially important in religious ceremonies.
The ancient Egyptians enjoyed a variety of leisure activities, including games and music. Senet, a board game where pieces moved according to random chance, was particularly popular from the earliest times; another similar game was mehen, which had a circular gaming board. Juggling and ball games were popular with children, and wrestling is also documented in a tomb at Beni Hasan. The wealthy members of ancient Egyptian society enjoyed hunting and boating as well.
The excavation of the workers' village of Deir el-Madinah has resulted in one of the most thoroughly documented accounts of community life in the ancient world that spans almost four hundred years. There is no comparable site in which the organisation, social interactions, working and living conditions of a community were studied in such detail.
Cuisine.
Egyptian cuisine remained remarkably stable over time; indeed, the cuisine of modern Egypt retains some striking similarities to the cuisine of the ancients. The staple diet consisted of bread and beer, supplemented with vegetables such as onions and garlic, and fruit such as dates and figs. Wine and meat were enjoyed by all on feast days while the upper classes indulged on a more regular basis. Fish, meat, and fowl could be salted or dried, and could be cooked in stews or roasted on a grill.
Architecture.
The architecture of ancient Egypt includes some of the most famous structures in the world: the Great Pyramids of Giza and the temples at Thebes. Building projects were organized and funded by the state for religious and commemorative purposes, but also to reinforce the power of the pharaoh. The ancient Egyptians were skilled builders; using simple but effective tools and sighting instruments, architects could build large stone structures with accuracy and precision.
The domestic dwellings of elite and ordinary Egyptians alike were constructed from perishable materials such as mud bricks and wood, and have not survived. Peasants lived in simple homes, while the palaces of the elite were more elaborate structures. A few surviving New Kingdom palaces, such as those in Malkata and Amarna, show richly decorated walls and floors with scenes of people, birds, water pools, deities and geometric designs. Important structures such as temples and tombs that were intended to last forever were constructed of stone instead of bricks. The architectural elements used in the world's first large-scale stone building, Djoser's mortuary complex, include post and lintel supports in the papyrus and lotus motif.
The earliest preserved ancient Egyptian temples, such as those at Giza, consist of single, enclosed halls with roof slabs supported by columns. In the New Kingdom, architects added the pylon, the open courtyard, and the enclosed hypostyle hall to the front of the temple's sanctuary, a style that was standard until the Graeco-Roman period. The earliest and most popular tomb architecture in the Old Kingdom was the mastaba, a flat-roofed rectangular structure of mudbrick or stone built over an underground burial chamber. The step pyramid of Djoser is a series of stone mastabas stacked on top of each other. Pyramids were built during the Old and Middle Kingdoms, but most later rulers abandoned them in favor of less conspicuous rock-cut tombs. The 25th dynasty was a notable exception, as all 25th dynasty pharaohs constructed pyramids. These artistic standards—simple lines, shapes, and flat areas of color combined with the characteristic flat projection of figures with no indication of spatial depth—created a sense of order and balance within a composition. Images and text were intimately interwoven on tomb and temple walls, coffins, stelae, and even statues. The Narmer Palette, for example, displays figures that can also be read as hieroglyphs. Because of the rigid rules that governed its highly stylized and symbolic appearance, ancient Egyptian art served its political and religious purposes with precision and clarity.
Ancient Egyptian artisans used stone to carve statues and fine reliefs, but used wood as a cheap and easily carved substitute. Paints were obtained from minerals such as iron ores (red and yellow ochres), copper ores (blue and green), soot or charcoal (black), and limestone (white). Paints could be mixed with gum arabic as a binder and pressed into cakes, which could be moistened with water when needed. 
Pharaohs used reliefs to record victories in battle, royal decrees, and religious scenes. Common citizens had access to pieces of funerary art, such as shabti statues and books of the dead, which they believed would protect them in the afterlife. During the Middle Kingdom, wooden or clay models depicting scenes from everyday life became popular additions to the tomb. In an attempt to duplicate the activities of the living in the afterlife, these models show laborers, houses, boats, and even military formations that are scale representations of the ideal ancient Egyptian afterlife.
Despite the homogeneity of ancient Egyptian art, the styles of particular times and places sometimes reflected changing cultural or political attitudes. After the invasion of the Hyksos in the Second Intermediate Period, Minoan-style frescoes were found in Avaris. The most striking example of a politically driven change in artistic forms comes from the Amarna period, where figures were radically altered to conform to Akhenaten's revolutionary religious ideas. This style, known as Amarna art, was quickly and thoroughly erased after Akhenaten's death and replaced by the traditional forms.
Religious beliefs.
Beliefs in the divine and in the afterlife were ingrained in ancient Egyptian civilization from its inception; pharaonic rule was based on the divine right of kings. The Egyptian pantheon was populated by gods who had supernatural powers and were called on for help or protection. However, the gods were not always viewed as benevolent, and Egyptians believed they had to be appeased with offerings and prayers. The structure of this pantheon changed continually as new deities were promoted in the hierarchy, but priests made no effort to organize the diverse and sometimes conflicting myths and stories into a coherent system. These various conceptions of divinity were not considered contradictory but rather layers in the multiple facets of reality.
Gods were worshiped in cult temples administered by priests acting on the king's behalf. At the center of the temple was the cult statue in a shrine. Temples were not places of public worship or congregation, and only on select feast days and celebrations was a shrine carrying the statue of the god brought out for public worship. Normally, the god's domain was sealed off from the outside world and was only accessible to temple officials. Common citizens could worship private statues in their homes, and amulets offered protection against the forces of chaos. After the New Kingdom, the pharaoh's role as a spiritual intermediary was de-emphasized as religious customs shifted to direct worship of the gods. As a result, priests developed a system of oracles to communicate the will of the gods directly to the people.
The Egyptians believed that every human being was composed of physical and spiritual parts or "aspects". In addition to the body, each person had a "šwt" (shadow), a "ba" (personality or soul), a "ka" (life-force), and a "name". The heart, rather than the brain, was considered the seat of thoughts and emotions. After death, the spiritual aspects were released from the body and could move at will, but they required the physical remains (or a substitute, such as a statue) as a permanent home. The ultimate goal of the deceased was to rejoin his "ka" and "ba" and become one of the "blessed dead", living on as an "akh", or "effective one". For this to happen, the deceased had to be judged worthy in a trial, in which the heart was weighed against a "feather of truth". If deemed worthy, the deceased could continue their existence on earth in spiritual form.
Burial customs.
The ancient Egyptians maintained an elaborate set of burial customs that they believed were necessary to ensure immortality after death. These customs involved preserving the body by mummification, performing burial ceremonies, and interring with the body goods the deceased would use in the afterlife.
By the New Kingdom, the ancient Egyptians had perfected the art of mummification; the best technique took 70 days and involved removing the internal organs, removing the brain through the nose, and desiccating the body in a mixture of salts called natron. The body was then wrapped in linen with protective amulets inserted between layers and placed in a decorated anthropoid coffin. Mummies of the Late Period were also placed in painted cartonnage mummy cases. Actual preservation practices declined during the Ptolemaic and Roman eras, while greater emphasis was placed on the outer appearance of the mummy, which was decorated.
Wealthy Egyptians were buried with larger quantities of luxury items, but all burials, regardless of social status, included goods for the deceased. Beginning in the New Kingdom, books of the dead were included in the grave, along with shabti statues that were believed to perform manual labor for them in the afterlife. Rituals in which the deceased was magically re-animated accompanied burials. After burial, living relatives were expected to occasionally bring food to the tomb and recite prayers on behalf of the deceased.
Military.
The ancient Egyptian military was responsible for defending Egypt against foreign invasion, and for maintaining Egypt's domination in the ancient Near East. The military protected mining expeditions to the Sinai during the Old Kingdom and fought civil wars during the First and Second Intermediate Periods. The military was responsible for maintaining fortifications along important trade routes, such as those found at the city of Buhen on the way to Nubia. Forts also were constructed to serve as military bases, such as the fortress at Sile, which was a base of operations for expeditions to the Levant. In the New Kingdom, a series of pharaohs used the standing Egyptian army to attack and conquer Kush and parts of the Levant.
Typical military equipment included bows and arrows, spears, and round-topped shields made by stretching animal skin over a wooden frame. In the New Kingdom, the military began using chariots that had earlier been introduced by the Hyksos invaders. Weapons and armor continued to improve after the adoption of bronze: shields were now made from solid wood with a bronze buckle, spears were tipped with a bronze point, and the Khopesh was adopted from Asiatic soldiers. The pharaoh was usually depicted in art and literature riding at the head of the army, it has been suggested that at least a few pharaohs, such as Seqenenre Tao II and his sons, did do so. although it has also been argued that "kings of this period did not personally act as frontline war leaders, fighting alongside their troops." Soldiers were recruited from the general population, but during, and especially after, the New Kingdom, mercenaries from Nubia, Kush, and Libya were hired to fight for Egypt.
Technology, medicine, and mathematics.
Technology.
In technology, medicine and mathematics, ancient Egypt achieved a relatively high standard of productivity and sophistication. Traditional empiricism, as evidenced by the Edwin Smith and Ebers papyri (c. 1600 BC), is first credited to Egypt. The Egyptians created their own alphabet and decimal system.
Faience and glass.
Even before the Old Kingdom, the ancient Egyptians had developed a glassy material known as faience, which they treated as a type of artificial semi-precious stone. Faience is a non-clay ceramic made of silica, small amounts of lime and soda, and a colorant, typically copper. The material was used to make beads, tiles, figurines, and small wares. Several methods can be used to create faience, but typically production involved application of the powdered materials in the form of a paste over a clay core, which was then fired. By a related technique, the ancient Egyptians produced a pigment known as Egyptian Blue, also called blue frit, which is produced by fusing (or sintering) silica, copper, lime, and an alkali such as natron. The product can be ground up and used as a pigment.
The ancient Egyptians could fabricate a wide variety of objects from glass with great skill, but it is not clear whether they developed the process independently. It is also unclear whether they made their own raw glass or merely imported pre-made ingots, which they melted and finished. However, they did have technical expertise in making objects, as well as adding trace elements to control the color of the finished glass. A range of colors could be produced, including yellow, red, green, blue, purple, and white, and the glass could be made either transparent or opaque.
Medicine.
The medical problems of the ancient Egyptians stemmed directly from their environment. Living and working close to the Nile brought hazards from malaria and debilitating schistosomiasis parasites, which caused liver and intestinal damage. Dangerous wildlife such as crocodiles and hippos were also a common threat. The lifelong labors of farming and building put stress on the spine and joints, and traumatic injuries from construction and warfare all took a significant toll on the body. The grit and sand from stone-ground flour abraded teeth, leaving them susceptible to abscesses (though caries were rare).
The diets of the wealthy were rich in sugars, which promoted periodontal disease. Despite the flattering physiques portrayed on tomb walls, the overweight mummies of many of the upper class show the effects of a life of overindulgence. Adult life expectancy was about 35 for men and 30 for women, but reaching adulthood was difficult as about one-third of the population died in infancy.
Ancient Egyptian physicians were renowned in the ancient Near East for their healing skills, and some, such as Imhotep, remained famous long after their deaths. Herodotus remarked that there was a high degree of specialization among Egyptian physicians, with some treating only the head or the stomach, while others were eye-doctors and dentists. Training of physicians took place at the "Per Ankh" or "House of Life" institution, most notably those headquartered in Per-Bastet during the New Kingdom and at Abydos and Saïs in the Late period. Medical papyri show empirical knowledge of anatomy, injuries, and practical treatments.
Wounds were treated by bandaging with raw meat, white linen, sutures, nets, pads, and swabs soaked with honey to prevent infection, while opium was used to relieve pain. Garlic and onions were used regularly to promote good health and were thought to relieve asthma symptoms. Ancient Egyptian surgeons stitched wounds, set broken bones, and amputated diseased limbs, but they recognized that some injuries were so serious that they could only make the patient comfortable until death occurred.
Shipbuilding.
Early Egyptians knew how to assemble planks of wood into a ship hull and had mastered advanced forms of shipbuilding as early as 3000 BC. The Archaeological Institute of America reports that some of the oldest ships yet unearthed are known as the Abydos boats. These are a group of 14 discovered ships in Abydos that were constructed of wooden planks "sewn" together. Discovered by Egyptologist David O'Connor of New York University, woven straps were found to have been used to lash the planks together, The importance of mathematics to an educated Egyptian is suggested by a New Kingdom fictional letter in which the writer proposes a scholarly competition between himself and another scribe regarding everyday calculation tasks such as accounting of land, labor, and grain. Texts such as the Rhind Mathematical Papyrus and the Moscow Mathematical Papyrus show that the ancient Egyptians could perform the four basic mathematical operations—addition, subtraction, multiplication, and division—use fractions, compute the volumes of boxes and pyramids, and calculate the surface areas of rectangles, triangles, and circles. They understood basic concepts of algebra and geometry, and could solve simple sets of simultaneous equations.
Mathematical notation was decimal, and based on hieroglyphic signs for each power of ten up to one million. Each of these could be written as many times as necessary to add up to the desired number; so to write the number eighty or eight hundred, the symbol for ten or one hundred was written eight times respectively. Because their methods of calculation could not handle most fractions with a numerator greater than one, they had to write fractions as the sum of several fractions. For example, they resolved the fraction "two-fifths" into the sum of "one-third" + "one-fifteenth". Standard tables of values facilitated this. Some common fractions, however, were written with a special glyph—the equivalent of the modern two-thirds is shown on the right.
a reasonable approximation of the formula π"r" 2.
The golden ratio seems to be reflected in many Egyptian constructions, including the pyramids, but its use may have been an unintended consequence of the ancient Egyptian practice of combining the use of knotted ropes with an intuitive sense of proportion and harmony.
Legacy.
The culture and monuments of ancient Egypt have left a lasting legacy on the world. The cult of the goddess Isis, for example, became popular in the Roman Empire, as obelisks and other relics were transported back to Rome. The Romans also imported building materials from Egypt to erect Egyptian style structures. Early historians such as Herodotus, Strabo, and Diodorus Siculus studied and wrote about the land, which Romans came to view as a place of mystery.
During the Middle Ages and the Renaissance, Egyptian pagan culture was in decline after the rise of Christianity and later Islam, but interest in Egyptian antiquity continued in the writings of medieval scholars such as Dhul-Nun al-Misri and al-Maqrizi. In the 17th and 18th centuries, European travelers and tourists brought back antiquities and wrote stories of their journeys, leading to a wave of Egyptomania across Europe. This renewed interest sent collectors to Egypt, who took, purchased, or were given many important antiquities.
Although the European colonial occupation of Egypt destroyed a significant portion of the country's historical legacy, some foreigners had more positive results. Napoleon, for example, arranged the first studies in Egyptology when he brought some 150 scientists and artists to study and document Egypt's natural history, which was published in the "Description de l'Ėgypte".
In the 20th century, the Egyptian Government and archaeologists alike recognized the importance of cultural respect and integrity in excavations. The Supreme Council of Antiquities now approves and oversees all excavations, which are aimed at finding information rather than treasure. The council also supervises museums and monument reconstruction programs designed to preserve the historical legacy of Egypt.

</doc>
<doc id="875" url="http://it.wikipedia.org/wiki/?curid=875" title="Analog Brothers">
Analog Brothers

Analog Brothers is an experimental hip-hop crew featuring Ice Oscillator also known as Ice-T (keyboards, drums, vocals), Keith Korg also known as Kool Keith (bass, strings, vocals), Mark Moog also known as Marc Live (drums, "violyns" and vocals), Silver Synth also known as Black Silver (synthesizer, lazar bell and vocals), and Rex Roland also known as Pimp Rex (keyboards, vocals, production). Its album "Pimp to Eat" featured guest appearances by various members of Rhyme Syndicate, Odd Oberheim, Jacky jasper (who appears as Jacky Jasper on the song "We Sleep Days" and H-Bomb on "War"), D.J. Cisco from S.M., the Synth-a-Size Sisters and Teflon. 
While the group only recorded one album together as the Analog Brothers, a few bootlegs of its live concert performances, including freestyles with original lyrics, have occasionally surfaced online. After "Pimp to Eat", the Analog Brothers continued performing together in various line ups. Kool Keith and Marc Live joined with Jacky jasper to release two albums as KHM. Marc Live rapped with Ice T's group SMG. Marc also formed a group with Black Silver called Live Black, but while five of their tracks were released on a demo CD sold at concerts, Live Black's first album has yet to be released.
In 2008, Ice-T and Black Silver toured together as Black Ice, and released an album together called Urban Legends.
In addition to all this, the Analog Brothers continue to make frequent appearances on each other's solo albums.

</doc>
<doc id="876" url="http://it.wikipedia.org/wiki/?curid=876" title="Motor neuron disease">
Motor neuron disease

The motor neuron diseases (MND) are a group of neurological disorders that selectively affect motor neurons, the cells that control voluntary muscle activity including speaking, walking, swallowing, and general movement of the body. They are generally progressive in nature, and cause increasingly debilitating disability and, eventually, death. 
Terminology.
Terms used to describe the motor neuron diseases can be confusing; in the UK "motor neuron disease" (with "neuron" sometimes spelt "neurone") refers to both amyotrophic lateral sclerosis (the most common form of disease) and to the broader spectrum of motor neuron diseases including progressive muscular atrophy, primary lateral sclerosis, and progressive bulbar palsy. In the United States the most common terms used are ALS (both specifically for ALS and as a blanket term) or "Lou Gehrig's disease". To avoid confusion, the annual scientific research conference dedicated to the study of MND is called the International ALS/MND Symposium. Although MND refers to a specific subset of pathologically similar diseases; there are numerous other afflictions of motor neurons that are pathologically distinct from MND and have a different clinical course. Examples of other diseases of the motor neuron that should not be confused with MND include spinobulbar muscular atrophy, spinal muscular atrophy, Charcot-Marie-Tooth disease, and many others.
Classification.
The term "bulbar region" in the above table refers to the mouth, face, and throat.
The disease spinal muscular atrophy (SMA) as well as various other spinal muscular atrophies are classified as motor neuron diseases by the disease terminology classification system Medical Subject Headings (MeSH) but not by the tenth International Statistical Classification of Diseases and Related Health Problems (ICD-10) published in 1992; hence, they are not discussed in this article.

</doc>
<doc id="877" url="http://it.wikipedia.org/wiki/?curid=877" title="Abjad">
Abjad

An abjad is a type of writing system where each symbol always or usually
Origins.
All known abjads belong to the Semitic family of scripts. These scripts are thought to derive from the Proto-Sinaitic alphabet (dated to about 1500 BC), which is thought to derive from Egyptian hieroglyphs. The abjad was significantly simpler than the earlier hieroglyphs. The number of distinct glyphs was reduced tremendously at the cost of increased ambiguity.
The first abjad to gain widespread usage was the Phoenician abjad. Unlike other contemporary scripts, such as Cuneiform and Egyptian hieroglyphs, the Phoenician script consisted of only about two dozen symbols. This made the script easy to learn, and Phoenician seafaring merchants took the script wherever they went. Phoenician gave way to a number of new writing systems, including the Greek alphabet and Aramaic, a widely used abjad. The Greek alphabet evolved into the modern western alphabets, such as Latin and Cyrillic, while Aramaic became the ancestor of many modern abjads and abugidas of Asia.
Aramaic spread across Asia, reaching as far as India and becoming Brahmi, the ancestral abugida to most modern Indian and Southeast Asian scripts. In the Middle East, Aramaic gave rise to the Hebrew and Nabataean abjads, which retained many of the Aramaic letter forms. The Syriac script was a cursive variation of Aramaic. It is unclear whether the Arabic abjad was derived from Nabatean or Syriac.
Impure abjads.
"Impure" abjads have characters for some vowels, optional vowel diacritics, or both. The term "pure" abjad refers to scripts entirely lacking in vowel indicators. However, most modern abjads, such as Arabic, Hebrew, Aramaic and Avestan, are "impure" abjads, that is, they also contain symbols for some of the vowel phonemes. An example of a "pure" abjad is ancient Phoenician.
Addition of vowels.
In the 9th century BC, the Greeks adapted the Phoenician script for use in their own language. The phonetic structure of the Greek language created too many ambiguities when the vowels went unrepresented, so the script was modified. They did not need letters for the guttural sounds represented by aleph, he, heth or ayin, so these symbols were assigned vocalic values. The letters waw and yod were also used. The Greek alphabet thus became the world's first "true" alphabet.
Abugidas developed along a slightly different route. The basic consonantal symbol was considered to have an inherent "a" vowel sound. Hooks or short lines attached to various parts of the basic letter modify the vowel. In this way, the South Arabian alphabet evolved into the Ge'ez alphabet between the 5th century BC and the 5th century AD. Similarly, around the 3rd century BC, the Brāhmī script developed (from the Aramaic abjad, it has been hypothesized).
The other major family of abugidas, Canadian Aboriginal syllabics, was initially developed in the 1840s by missionary and linguist James Evans for the Cree and Ojibwe languages. Evans used features of Devanagari script and Pitman shorthand to create his initial abugida. Later in the 19th century, other missionaries adapted Evans' system to other Canadian aboriginal languages. Canadian syllabics differ from other abugidas in that the vowel is indicated by rotation of the consonantal symbol, with each vowel having a consistent orientation.
Abjads and the structure of Semitic languages.
The abjad form of writing is well-adapted to the morphological structure of the Semitic languages it was developed to write. This is because words in Semitic languages are formed from a root consisting of (usually) three consonants, the vowels being used to indicate inflectional or derived forms. For instance, according to Classical Arabic and Modern Standard Arabic, the Arabic root ' (to sacrifice) can be derived the forms ' (he sacrificed), ' (you (masculine singular) sacrificed), ' (he slaughtered), ' (he slaughters), and ' (slaughterhouse). In each case, the absence of full glyphs for vowels makes the common root clearer, improving word recognition while reading.

</doc>
<doc id="878" url="http://it.wikipedia.org/wiki/?curid=878" title="Abugida">
Abugida

An abugida (from Ge‘ez አቡጊዳ "’äbugida"), also called an alphasyllabary, is a segmental writing system in which consonant–vowel sequences are written as a unit: each unit is based on a consonant letter, and vowel notation is secondary. This contrasts with a full alphabet, in which vowels have status equal to consonants, and with an abjad, in which vowel marking is absent or optional. (In less formal contexts, all three types of script may commonly be termed as alphabets.) Abugidas include the extensive Brahmic family of scripts of South and Southeast Asia.
The term "abugida" was suggested by Peter T. Daniels in his 1990 typology of writing systems. It is an Ethiopian name of the Ge‘ez script, "’ä bu gi da," taken from four letters of that script the way "abecedary" derives from Latin "a be ce de." As Daniels used the word, an abugida contrasts with a syllabary, where letters with shared consonants or vowels show no particular resemblance to each another, and with an alphabet proper, where independent letters are used to denote both consonants and vowels. The term "alphasyllabary" was suggested for the Indic scripts in 1997 by William Bright, following South Asian linguistic usage, to convey the idea that "they share features of both alphabet and syllabary". 
Abugidas were long considered to be syllabaries or intermediate between syllabaries and alphabets, and the term "syllabics" is retained in the name of Canadian Aboriginal Syllabics. Other terms that have been used include "neosyllabary" (Février 1959), "pseudo-alphabet" (Householder 1959), "semisyllabary" (Diringer 1968; a word which has other uses) and "syllabic alphabet" (Coulmas 1996; this term is also a synonym for syllabary).
Tāna of the Maldives has dependent vowels and a zero vowel sign, but no inherent vowel.
Indic (Brahmic).
Indic scripts originated in India and spread to Southeast Asia. All surviving Indic scripts are descendants of the Brahmi alphabet. Today they are used in most languages of South Asia (although replaced by Perso-Arabic in Urdu, Kashmiri and some other languages of Pakistan and India) and mainland Southeast Asia (Burma, Thailand, Laos, Cambodia; but not Malaysia or Vietnam). The primary division is into North Indic scripts used in Northern India, Nepal, Tibet, Bhutan and Southern Indic scripts used in South India, Sri Lanka, and Southeast Asia.
South Indic letter forms are very rounded; North Indic less so, though Oriya, Golmol and Litumol of Nepal script are rounded.
Most North Indic scripts' full letters incorporate a horizontal line at the top, with Gujarati and Oriya script as exception; South Indic scripts do not.
Indic scripts indicate vowels through dependent vowel signs (diacritics) around the consonants, often including a sign that explicitly indicates the lack of a vowel. If a consonant has no vowel sign, this indicates a default vowel. Vowel diacritics may appear above, below, to the left, to the right, or around the consonant. 
The most populous Indic script is Devanagari, used for Hindi, Bhojpuri, Marathi, Nepali, and often Sanskrit. A basic letter such as क in Hindi represents a syllable with the default vowel, in this case "ka" (), or, in final position, a final consonant, in this case "k." This inherent vowel may be changed by adding vowel marks (diacritics), producing syllables such as कि "ki," कु "ku," के "ke," को "ko." The mora a consonant letter represents, either with or without a marked vowel, is called an akshara.
In many of the Brahmic scripts, a syllable beginning with a cluster is treated as a single character for purposes of vowel marking, so a vowel marker like "-i," falling before the character it modifies, may appear several positions before the place where it is pronounced. For example, the game cricket in Hindi is क्रिकेट "krikeţ;" the diacritic for appears before the consonant cluster , not before the . A more unusual example is seen in the Batak alphabet: Here the syllable "bim" is written "ba-ma-i-(virama)". That is, the vowel diacritic and virama are both written after the consonants for the whole syllable.
In many abugidas, there is also a diacritic to suppress the inherent vowel, yielding the bare consonant. In Devanagari, क् is "k," and ल् is "l". This is called the "virāma" or "halantam" in Sanskrit. It may be used to form consonant clusters, or to indicate that a consonant occurs at the end of a word. In Sanskrit, thus, a default vowel consonant such as क does not take on a final consonant sound. Instead, it keeps its vowel. For writing two consonants without a vowel in between, instead of using diacritics on the first consonant to remove its vowel, another popular method of special conjunct forms is used in which two or more consonant characters are merged to express a cluster, such as Devanagari: क्ल "kla." (Note that on some fonts display this as क् followed by ल, rather than forming a conjunct. This expedient is used by ISCII and South Asian scripts of Unicode.) Thus a closed syllable such as "kal" requires two aksharas to write.
The Róng script used for the Lepcha language goes further than other Indic abugidas, in that a single akshara can represent a closed syllable: Not only the vowel, but any final consonant is indicated by a diacritic. For example, the syllable would be written as something like , here with an underring representing and an overcross representing the diacritic for final . Most other Indic abugidas can only indicate a very limited set of final consonants with diacritics, such as or , if they can indicate any at all.
Ethiopic.
In Ethiopic, where the term "abugida" originates, the diacritics have been fused to the consonants to the point that they must be considered modifications of the form of the letters. Children learn each modification separately, as in a syllabary; nonetheless, the graphic similarities between syllables with the same consonant is readily apparent, unlike the case in a true syllabary.
Though now an abugida, the Ge'ez alphabet, until the advent of Christianity ("ca." 350 CE), had originally been what would now be termed an abjad. In the Ge'ez abugida (or 'fidel'), the base form of the letter (also known as 'fidel') may be altered. For example, ሀ "hä" (base form), ሁ "hu" (with a right-side diacritic that doesn't alter the letter), ሂ "hi" (with a subdiacritic that compresses the consonant, so it is the same height), ህ "hə" or (where the letter is modified with a kink in the left arm).
Canadian Aboriginal syllabics.
In the family known as Canadian Aboriginal syllabics which are inspired by the Devanagari script of India, vowels are indicated by changing the orientation of the syllabogram. Each vowel has a consistent orientation; for example, Inuktitut ᐱ "pi," ᐳ "pu," ᐸ "pa;" ᑎ "ti," ᑐ "tu," ᑕ "ta". Although there is a vowel inherent in each, all rotations have equal status and none can be identified as basic. Bare consonants are indicated either by separate diacritics, or by superscript versions of the aksharas; there is no vowel-killer mark.
Borderline cases.
Vowelled abjads.
Consonantal scripts ("abjads") are normally written without indication of many vowels. However in some contexts like teaching materials or scriptures, Arabic and Hebrew are written with full indication of vowels via diacritic marks (harakat, niqqud) making them effectively abugidas. The Brahmic and Ethiopic families are thought to have originated from the Semitic abjads by the addition of vowel marks.
The Arabic-alphabet scripts used for Kurdish in Iraq and for Uighur in Xinjiang, (People's Republic of China) are fully vowelled, but since the vowels are full letters rather than diacritics, and there are no inherent vowels, these are considered alphabets rather than abugidas.
Phagspa.
The imperial Mongol script called Phagspa was derived from the Tibetan abugida, but all vowels are written in-line rather than as diacritics. However, it retains the features of having an inherent vowel /a/ and having distinct initial vowel letters.
Pahawh.
Pahawh Hmong is a non-segmental script that indicates syllable onsets and rimes, such as consonant clusters and vowels with final consonants. Thus it is not segmental and cannot be considered an abugida. However, it superficially resembles an abugida with the roles of consonant and vowel reversed. Most syllables are written with two letters in the order rime–onset (typically vowel-consonant), even though they are pronounced as onset-rime (consonant-vowel), rather like the position of the vowel in Devanagari, which is written before the consonant. Pahawh is also unusual in that, while an inherent rime (with mid tone) is unwritten, it also has an inherent onset . For the syllable , which requires one or the other of the inherent sounds to be overt, it is that is written. Thus it is the rime (vowel) which is basic to the system.
Meroitic.
It is difficult to draw a dividing line between abugidas and other segmental scripts. For example, the Meroitic script of ancient Sudan did not indicate an inherent "a" (one symbol stood for both "m" and "ma," for example), and is thus similar to Brahmic family abugidas. However, the other vowels were indicated with full letters, not diacritics or modification, so the system was essentially an alphabet that did not bother to write the most common vowel.
Shorthand.
Several systems of shorthand use diacritics for vowels, but they do not have an inherent vowel, and are thus more similar to Thaana and Kurdish script than to the Brahmic scripts. The Gabelsberger shorthand system and its derivatives modify the "following" consonant to represent vowels. The Pollard script, which was based on shorthand, also uses diacritics for vowels; the placements of the vowel relative to the consonant indicates tone. Pitman shorthand uses straight strokes and quarter-circle marks in different orientations as the principal "alphabet" of consonants; vowels are shown as light and heavy dots, dashes and other marks in one of 3 possible positions to indicate the various vowel-sounds. However, to increase writing-speed Pitman has rules for "vowel indication" using the positioning or choice of consonant signs so that writing vowel-marks can be dispensed with.
Development.
As the term "alphasyllabary" suggests, abugidas have been considered an intermediate step between alphabets and syllabaries. Historically, abugidas appear to have evolved from abjads (vowelless alphabets). They contrast with syllabaries, where there is a distinct symbol for each syllable or consonant-vowel combination, and where these have no systematic similarity to each other, and typically develop directly from logographic scripts. Compare the Devanagari examples above to sets of syllables in the Japanese hiragana syllabary: か "ka", き "ki", く "ku", け "ke", こ "ko" have nothing in common to indicate "k;" while ら "ra", り "ri", る "ru", れ "re", ろ "ro" have neither anything in common for "r", nor anything to indicate that they have the same vowels as the "k" set.
Most Indian and Indochinese abugidas appear to have first been developed from abjads with the and Brāhmī scripts; the abjad in question is usually considered to be the Aramaic one, but while the link between Aramaic and Kharosthi is more or less undisputed, this is not the case with Brahmi. The Kharosthi family does not survive today, but Brahmi's descendants include most of the modern scripts of South and Southeast Asia. Ge'ez derived from a different abjad, the Sabean script of Yemen; the advent of vowels coincided with the introduction of Christianity about 350 CE.

</doc>
<doc id="880" url="http://it.wikipedia.org/wiki/?curid=880" title="ABBA">
ABBA

ABBA were a Swedish pop group formed in Stockholm in 1972, comprising Agnetha Fältskog, Björn Ulvaeus, Benny Andersson and Anni-Frid Lyngstad. ABBA is an acronym of the first letters of the band members' first names and is sometimes stylized as the registered trademark ᗅᗺᗷᗅ. They became one of the most commercially successful acts in the history of pop music, topping the charts worldwide from 1972 to 1982. They are also known for winning the 1974 Eurovision Song Contest, giving Sweden its first victory in the history of the contest and being the most successful group ever to take part in the contest.
ABBA had sold over 370 million records worldwide and still sells millions of records a year, which makes them one of the best-selling music artists of all time. ABBA was the first pop group to come from a non-English-speaking country that enjoyed consistent success in the charts of English-speaking countries, including the UK, Ireland, the U.S., Canada, Australia, New Zealand, and South Africa. The group also enjoyed significant success in Latin American markets, and recorded a collection of their hit songs in Spanish.
During the band's active years, Fältskog and Ulvaeus were a married couple, as were Lyngstad and Andersson, although both couples later divorced. At the height of their popularity, both relationships were suffering strain which ultimately resulted in the collapse of the Ulvaeus-Fältskog marriage in 1979 and the Andersson-Lyngstad marriage in 1981. These relationship changes were reflected in the group's music, with later compositions including more introspective lyrics.
After ABBA broke up in late 1982, Andersson and Ulvaeus achieved success writing music for the stage while Lyngstad and Fältskog pursued solo careers with mixed success. ABBA's music declined in popularity until several films, notably "Muriel's Wedding" and "The Adventures of Priscilla, Queen of the Desert", revived interest in the group, spawning several tribute bands. In 1999, ABBA's music was adapted into the successful musical "Mamma Mia!" that toured worldwide. A film of the same name released in 2008 became the highest-grossing film in the United Kingdom that year. The group was inducted into the Rock and Roll Hall of Fame on 15 March 2010.
History.
Before ABBA (1960s).
Benny Andersson (born 16 December 1946 in Stockholm, Sweden) became (at age 18) the member of a popular Swedish pop-rock group, The Hep Stars, that performed covers of international hits. The Hep Stars were known as "The Swedish Beatles". They also set up Hep House, their equivalent of Apple Corps. Andersson played the keyboard and eventually started writing original songs for his band, many of which became major hits, including "No Response" that hit number 3 in 1965, "Sunny Girl", "Wedding" and "Consolation", all of which hit number 1 in 1966. Andersson also had a fruitful songwriting collaboration with Lasse Berghagen, with whom he wrote his first Svensktoppen entry "Sagan om lilla Sofi" ("The Story of Little Sophie") in 1968.
Björn Ulvaeus (born 25 April 1945 in Gothenburg/Göteborg, Sweden) also began his musical career at 18 (as a singer and guitarist), when he fronted The Hootenanny Singers, a popular Swedish folk-skiffle group. Ulvaeus started writing English-language songs for his group, and even had a brief solo career alongside. The Hootenanny Singers and The Hep Stars sometimes crossed paths while touring. In June 1966, Ulvaeus and Andersson decided to write a song together. Their first attempt was "Isn't It Easy to Say", a song later recorded by The Hep Stars. Stig Anderson was the manager of The Hootenanny Singers and founder of the Polar Music label. He saw potential in the collaboration, and encouraged them to write more. Both also began playing occasionally with the other's bands on stage and on record, although it was not until 1969 that the pair wrote and produced some of their first real hits together: "Ljuva sextital" ("Merry Sixties"), recorded by Brita Borg, and The Hep Stars' 1969 hit "Speleman" ("Fiddler").
Andersson wrote and submitted the song "Hej, Clown" for the 1969 Melodifestivalen, the national festival to select the Swedish entry to the Eurovision Song Contest. The song tied for first place, but re-voting relegated Andersson's song to second place. On that occasion Andersson briefly met his future spouse, singer Anni-Frid Lyngstad, who also participated in the contest. A month later, the two had become a couple. As their respective bands began to break up during 1969, Andersson and Ulvaeus teamed up and recorded their first album together in 1970, called "Lycka" ("Happiness"), which included original songs sung by both men. Their spouses were often present in the recording studio, and sometimes added backing vocals; Fältskog even co-wrote a song with the two. Ulvaeus still occasionally recorded and performed with The Hootenanny Singers until the summer of 1974, and Andersson took part in producing their records.
Agnetha Fältskog (born 5 April 1950 in Jönköping, Sweden) sang with a local dance band headed by Bernt Enghardt who sent a demo recording of the band to Karl Gerhard Lundkvist. The demo tape featured a song written and sung by Agnetha, "Jag var så kär". Lundkvist was so impressed with her voice that he was convinced she would be a star. After going through considerable effort to locate the singer, he arranged for Agnetha to come to Stockholm and to record two of her own songs. This led to Agnetha having a number 1 record in Sweden with a self composed song and selling more than 80.000 copies while she was still only 17. She was soon noticed by the critics and songwriters as a talented singer/songwriter of schlager style songs. Fältskog's main inspiration in her early years were singers such as Connie Francis. Along with her own compositions, she recorded covers of foreign hits and performed them on tours in Swedish folkparks. Most of her biggest hits were self-composed, which was quite unusual for a female singer in the 1960s. Agnetha released four solo LPs between 1968 and 1971. She had many successful singles in the Swedish charts.
During filming of a Swedish TV special in May 1969, Fältskog met Ulvaeus, and they married on 6 July 1971. Fältskog and Ulvaeus eventually were involved in each other's recording sessions, and soon even Andersson and Lyngstad added backing vocals to her third studio album "Som jag är" ("As I Am") (1970). In 1972, Fältskog starred as Mary Magdalene in the original Swedish production of "Jesus Christ Superstar" and attracted favourable reviews. Between 1967 and 1975, Fältskog released five studio albums.
Anni-Frid "Frida" Lyngstad (born 15 November 1945 in Bjørkåsen in Ballangen, Norway) sang from the age of 13 with various dance bands, and worked mainly in a jazz-oriented cabaret style. She also formed her own band, the Anni-Frid Four. In the summer of 1967, she won a national talent competition with "En ledig dag" ("A Day Off") a Swedish version of the bossa nova song "A Day in Portofino", which is included in the EMI compilation "Frida 1967-1972". The first prize was a recording contract with EMI Sweden and to perform live on the most popular TV shows in the country. This TV performance, amongst many others, is included in the 3½ hour documentary "Frida - The DVD". Lyngstad released several schlager style singles on EMI without much success. When Benny Andersson started to produce her recordings in 1971, she had her first number 1 single, "Min egen stad" ("My Own Town") written by Benny featuring all the future ABBA members on backing vocals. Lyngstad toured and performed regularly in the folkpark circuit and made appearances on radio and TV. She met Ulvaeus briefly in 1963 during a talent contest, and Fältskog during a TV show in early 1968.
Lyngstad finally linked up with her future bandmates in 1969. On 1 March 1969, she participated in the Melodifestivalen, where she met Andersson for the first time. A few weeks later they met again during a concert tour in southern Sweden and they soon became a couple. Andersson produced her single "Peter Pan" in September 1969 — her first collaboration with Benny  Björn, as they had written the song. Andersson would then produce Lyngstad's debut studio album, "Frida", which was released in March 1971. Lyngstad also played in several revues and cabaret shows in Stockholm between 1969 and 1973. After ABBA formed, she recorded another successful album in 1975, "Frida ensam", which included a Swedish rendition of "Fernando", a hit on the Swedish radio charts before the English version was released.
First live performance and the start of "Festfolk".
An attempt at combining their talents occurred in April 1970 when the two couples went on holiday together to the island of Cyprus. What started as singing for fun on the beach ended up as an improvised live performance in front of the United Nations soldiers stationed on the island. Andersson and Ulvaeus were at this time recording their first album together, "Lycka", which was to be released in September 1970. Fältskog and Lyngstad added backing vocals on several tracks during June, and the idea of them working together saw them launch a stage act, "Festfolk" (which translates from Swedish to mean both "Party People" and "Engaged Couples") on 1 November 1970 in Gothenburg. The cabaret show attracted generally negative reviews, except for the performance of the Andersson and Ulvaeus hit "Hej, gamle man" ("Hello, Old Man"); the first Björn and Benny recording to feature all four. They also performed solo numbers from respective albums, but the lukewarm reception convinced the foursome to shelve plans for working together for the time being, and each soon concentrated on individual projects again.
First record together "Hej, gamle man".
"Hej, gamle man", a song about an old Salvation Army soldier, became the quartet's first hit. The record was credited to Björn  Benny and reached number 5 on the sales charts and number 1 on Svensktoppen, staying there for 15 weeks.
During 1971, the four artists began working together more, adding vocals to the others' recordings. Fältskog, Andersson and Ulvaeus toured together in May, while Lyngstad toured on her own. Frequent recording sessions brought the foursome closer together during the summer.
Forming the group (1970–1973).
After the 1970 release of "Lycka", two more singles credited to 'Björn  Benny' were released in Sweden, "Det kan ingen doktor hjälpa" ("No Doctor Can Help with That") and "Tänk om jorden vore ung" ("Imagine If the Earth Were Young"), with more prominent vocals by Fältskog and Lyngstad–and moderate chart success.
Fältskog and Ulvaeus, now married, started performing together with Andersson on a regular basis at the Swedish folkparks during the summer of 1971.
Stig Anderson, founder and owner of Polar Music, was determined to break into the mainstream international market with music by Andersson and Ulvaeus. "One day the pair of you will write a song that becomes a worldwide hit", he predicted. Stig Anderson encouraged Ulvaeus and Andersson to write a song for Melodifestivalen, and after two rejected entries in 1971, Andersson and Ulvaeus submitted their new song "Säg det med en sång" ("Say It with a Song") for the 1972 contest, choosing newcomer Lena Anderson to perform. The song came in third place, encouraging Stig Anderson, and became a hit in Sweden.
The first signs of foreign success came as a surprise, as the Andersson and Ulvaeus single "She's My Kind of Girl" was released through Epic Records in Japan in March 1972, giving the duo a Top 10 hit. Two more singles were released in Japan, "En Carousel" ("En Karusell" in Scandinavia, an earlier version of "Merry-Go-Round") and "Love Has Its Ways" (a song they wrote with Koichi Morita).
First hit as Björn, Benny, Agnetha  Anni-Frid.
Ulvaeus and Andersson persevered with their songwriting and experimented with new sounds and vocal arrangements. "People Need Love" was released in June 1972, featuring guest vocals by the women, who were now given much greater prominence. Stig Anderson released it as a single, credited to "Björn  Benny, Agnetha  Anni-Frid". The song peaked at number 17 in the Swedish combined single and album charts, enough to convince them they were on to something. The single also became the first record to chart for the quartet in the United States, where it peaked at number 114 on the "Cashbox" singles chart and number 117 on the "Record World" singles chart. Labeled as "Björn  Benny (with Svenska Flicka)", it was released there through Playboy Records. However, according to Stig Anderson, "People Need Love" could have been a much bigger American hit, but a small label like Playboy Records did not have the distribution resources to meet the demand for the single from retailers and radio programmers.
The foursome decided to record their first album together in the autumn of 1972, and sessions began on 26 September 1972. The women shared lead vocals on "Nina, Pretty Ballerina" (a top ten hit in Austria) that day, and their voices in harmony for the first time gave the foursome an idea of the quality of their combined talents.
"Ring Ring".
In 1973, the band and their manager Stig Anderson decided to have another try at Melodifestivalen, this time with the song "Ring Ring". The studio sessions were handled by Michael B. Tretow, who experimented with a "wall of sound" production technique that became the wholly new ABBA sound. Stig Anderson arranged an English translation of the lyrics by Neil Sedaka and Phil Cody and they thought this would be a surefire winner. However, on 10 February 1973, the song came third in Melodifestivalen, thus it never reached the Eurovision Song Contest itself. Nevertheless, the group released their debut studio album, also called "Ring Ring". The album did well and the "Ring Ring" single was a hit in many parts of Europe and also in South Africa. However, Stig Anderson felt that the true breakthrough could only come with a UK or US hit.
Though Agnetha Fältskog gave birth to her first child in 1973 she was for a shorter period replaced by Inger Brundin on a trip to West Germany.
Official naming.
In early 1973, Stig Anderson, tired of unwieldy names, started to refer to the group privately and publicly as ABBA. At first, this was a play on words, as Abba is also the name of a well-known fish-canning company in Sweden, and itself an acronym. However, since the fish-canners were unknown outside Sweden, Anderson came to believe the name would work in international markets. A competition to find a suitable name for the group was held in a Gothenburg newspaper. The group was impressed with the names "Alibaba", "FABB", and "Baba", but in the end all the entries were ignored and it was officially announced in the summer that the group were to be known as "ABBA". The group negotiated with the canners for the rights to the name. "ABBA" is an acronym formed from the first letters of each group member's first name: Agnetha, Björn, Benny and Anni-Frid. During a promotional photo, Benny flipped his "B" horizontally for fun, and from 1976 onwards the first 'B' in the logo version of the name was "mirror-image" reversed on the band's promotional material and ᗅᗺᗷᗅ became the group's registered trademark.
The first time "ABBA" is found written on paper is on a recording session sheet from the Metronome Studio in Stockholm, dated 16 October 1973. This was first written as "Björn, Benny, Agnetha  Frida", but was subsequently crossed out with "ABBA" written in large letters on top.
The official logo, using the bold version of the News Gothic typeface, was designed by Rune Söderqvist, and appeared for the first time on the "Dancing Queen" single in August 1976, and subsequently on all later original albums and singles. But the idea for the official logo was made by the German photographer Wolfgang Heilemann on a "Dancing Queen" shoot for the teenage magazine Bravo. On the photo, the ABBA members held a giant initial letter of his/her name. After the pictures were made, Heilemann found out that one of the men held his letter backwards as in ᗅᗺᗷᗅ®. They discussed it and the members of ABBA liked it. Following their acquisition of the group's catalogue, Polygram began using variations of the ABBA logo, using a different font and adding a crown emblem to it in 1992 for the first release of the "ABBA Gold: Greatest Hits" compilation. When Universal Music purchased Polygram (and, thus, ABBA's label Polar Music International), control of the group's catalogue was returned to Stockholm. Since then, the original logo has been reinstated on all official products.
Breakthrough (1973–1976).
Eurovision.
As the group entered the Melodifestivalen with "Ring Ring" but failed to qualify as the 1973 Swedish entry, Stig Anderson immediately started planning for the 1974 contest.
Ulvaeus, Andersson and Stig Anderson believed in the possibilities of using Melodifestivalen and the Eurovision Song Contest as a way to make the music business aware of them as songwriters, as well as the band itself. In late 1973, they were invited by Swedish television to contribute a song for the Melodifestivalen 1974 and from a number of new songs, the upbeat number "Waterloo" was chosen; the group was now inspired by the growing glam rock scene in England. "Waterloo" was an unashamedly glam-style pop track produced with Michael B. Tretow's wall-of-sound approach, and it bears a notable resemblance in both arrangement and production to Wizzard's 1973 UK hit "See My Baby Jive".
ABBA won their national heats on Swedish television on 9 February 1974, and with this third attempt were far more experienced and better prepared for the Eurovision Song Contest. Winning the 1974 Contest on 6 April 1974 gave ABBA the chance to tour Europe and perform on major television shows; thus the band saw the "Waterloo" single chart in many European countries. "Waterloo" was ABBA's first number one single in big markets such as the UK and Germany. In the United States, the song peaked at number six on the "Billboard" Hot 100 chart, paving the way for their first album and their first trip as a group there. Albeit a short promotional visit, it included their first performance on American television, "The Mike Douglas Show". The album "Waterloo" only peaked at number 145 on the "Billboard" 200 chart, but received unanimous high praise from the US critics: "Los Angeles Times" called it "a compelling and fascinating debut album that captures the spirit of mainstream pop quite effectively . . . an immensely enjoyable and pleasant project", while "Creem" characterized it as "a perfect blend of exceptional, lovable compositions".
ABBA's follow-up single, "Honey, Honey", peaked at number 27 on the US "Billboard" Hot 100, and was a number 2 hit in Germany. However, in the United Kingdom, ABBA's British record label, Epic, decided to re-release a remixed version of "Ring Ring" instead of "Honey, Honey", and a cover version of the latter by Sweet Dreams peaked at number 10. Both records debuted on the UK chart within one week of each other. "Ring Ring" failed to reach the Top 30 in the United Kingdom, increasing growing speculation that the group were simply Eurovision one-hit wonders.
Post-Eurovision.
In November 1974, ABBA embarked on their first European tour, playing dates in Denmark, West Germany and Austria. It was not as successful as the band had hoped, since most of the venues did not sell out. Due to a lack of demand, they were even forced to cancel a few shows, including a sole concert scheduled in Switzerland. The second leg of the tour, which took them through Scandinavia in January 1975, was very different. They played to full houses everywhere and finally got the reception they had aimed for. Live performances continued during the summer of 1975 when ABBA embarked on a sixteen open-air date tour of Sweden and Finland. Their Stockholm show at the Gröna Lund amusement park had an estimated audience of 19,200.
In late 1974, "So Long" was released as a single in the United Kingdom but it received no airplay from Radio 1 and failed to chart. In the summer of 1975 ABBA released "I Do, I Do, I Do, I Do, I Do", which again received little airplay on Radio 1 but managed to climb the charts, to number 38. Later in 1975, the release of their self-titled third studio album "ABBA" and single "SOS" brought back their chart presence in the UK, where the single hit number 6 and the album peaked at number 13. "SOS" also became ABBA's second number 1 single in Germany and Australia. Success was further solidified with "Mamma Mia" reaching number 1 in the United Kingdom, Germany and Australia. In the United States, "SOS" peaked at number 10 on the Record World Top 100 singles chart and number 15 on the Billboard Hot 100 chart, picking up the BMI Award along the way as one of the most played songs on American radio in 1975.
The success of the group in the United States had until that time been limited to single releases. By early 1976, the group already had four Top 30 singles on the US charts, but the album market proved to be tough to crack. The eponymous "ABBA " album generated three American hits, but it only peaked at number 165 on the "Cashbox" album chart and number 174 on the "Billboard" 200 chart. Opinions were voiced, by "Creem" in particular, that in the US ABBA had endured "a very sloppy promotional campaign". Nevertheless, the group enjoyed warm reviews from the American press. "Cashbox" went as far as saying that "there is a recurrent thread of taste and artistry inherent in Abba's marketing, creativity and presentation that makes it almost embarrassing to critique their efforts", while "Creem" wrote: "SOS is surrounded on this LP by so many good tunes that the mind boggles".
In Australia, the airing of the music videos for "I Do, I Do, I Do, I Do, I Do" and "Mamma Mia" on the nationally-broadcast TV pop show "Countdown" (which premiered in August 1975) saw the band rapidly gain enormous popularity, and "Countdown" become a key promoter of the group via their distinctive music videos. This started an immense interest for ABBA in Australia, resulting in both the single and album holding down the #1 positions on the charts for months.
Superstardom (1976–1981).
In March 1976, the band released the compilation album "Greatest Hits", despite having had only six Top 40 hits in the United Kingdom and the United States. Nevertheless, it became their first UK number 1 album, and also took ABBA into the Top 50 on the US album charts for the first time, eventually selling more than a million copies there. At the same time, Germany released a compilation named "The Very Best of ABBA", also becoming a number 1 album there whereas the "Greatest Hits" compilation followed a few months later to number 2 on the German charts, despite all similarities with "The Very Best" album. Also included on "Greatest Hits" was a new single, "Fernando", which took the world by storm, hitting number 1 in at least thirteen countries worldwide, including the United Kingdom, Germany and Australia, and the single went on to sell over 10 million copies worldwide. In Australia, the song occupied the top position for 14 weeks (and stayed in the chart for 40 weeks), tying with The Beatles' "Hey Jude" for longest-running number one, and making "Fernando" one of the best-selling singles of all time in Australia. That same year, the group received its first international prize, with "Fernando" being chosen as the "Best Studio Recording of 1975". In the United States, "Fernando" reached the Top 10 of the Cashbox Top 100 singles chart and number 13 on the Billboard Hot 100. It also topped the Billboard Adult Contemporary chart, ABBA's first American number one single.
The group's fourth studio album, "Arrival", a number 1 bestseller in Europe and Australia, represented a new level of accomplishment in both songwriting and studio work, prompting rave reviews from more rock-oriented UK music weeklies such as "Melody Maker" and "New Musical Express", and mostly appreciative notices from American critics. Hit after hit flowed from "Arrival": "Money, Money, Money", another number 1 in Germany and Australia, and "Knowing Me, Knowing You", ABBA's sixth consecutive German number 1 as well as another UK number 1. The real sensation was "Dancing Queen", not only topping the charts in loyal markets the UK, Germany and Australia, but also reaching number 1 in the United States. In South Africa, ABBA had astounding success with "Fernando", "Dancing Queen" and "Knowing Me, Knowing You" being among the top 20 best-selling singles for 1976–77. In 1977, "Arrival" was nominated for the inaugural BRIT Award in the category "Best International Album of the Year". By this time ABBA were popular in the United Kingdom, most of Western Europe, Australia and New Zealand. In "Frida – The DVD", Lyngstad explains how she and Fältskog developed as singers, as ABBA's recordings grew more complex over the years.
The band's popularity in the United States would remain on a comparatively smaller scale, and "Dancing Queen" became the only Billboard Hot 100 number 1 single ABBA had there (they did, however, get three more singles to the number 1 position on other Billboard charts, including Billboard Adult Contemporary and Hot Dance Club Play). Nevertheless, "Arrival" finally became a true breakthrough release for ABBA on the US album market where it peaked at number 20 on the Billboard 200 chart and was certified gold by RIAA.
European and Australian tour.
In January 1977, ABBA embarked on their first major tour. The group's status had changed dramatically and they were clearly regarded as superstars. They opened their much anticipated tour in Oslo, Norway, on 28 January, and mounted a lavishly produced spectacle that included a few scenes from their self-written mini-operetta "The Girl with the Golden Hair". The concert attracted immense media attention from across Europe and Australia. They continued the tour through Western Europe visiting Gothenburg, Copenhagen, Berlin, Cologne, Amsterdam, Antwerp, Essen, Hanover, Hamburg, and ended it with shows in the United Kingdom in Manchester, Birmingham, Glasgow and two sold-out concerts at London's Royal Albert Hall. Tickets for these two shows were available only by mail application and it was later revealed that the box-office received 3.5 million requests for tickets, enough to fill the venue 580 times. Along with praise ("ABBA turn out to be amazingly successful at reproducing their records", wrote "Creem"), there were complaints that "ABBA performed slickly...but with a zero personality coming across from a total of 16 people on stage" ("Melody Maker"). One of the Royal Albert Hall concerts was filmed as a reference for the filming of the Australian tour for what became "", though it is not exactly known how much of the concert was filmed.
After the European leg of the tour, in March 1977, ABBA played eleven dates in Australia before a total of 160,000 people. The opening concert in Sydney at the Sydney Showground on 3 March to an audience of 20,000 was marred by torrential rain, with Lyngstad slipping on the wet stage during the concert. However, all four members would later recall this concert to be the most memorable of their career. Upon their arrival in Melbourne, a civic reception was held at the Melbourne Town Hall and ABBA appeared on the balcony to greet an enthusiastic crowd of 6,000 people. In Melbourne, the group played three concerts at the Sidney Myer Music Bowl with 14,500 at each including the Australian Prime Minister Malcolm Fraser and his family. At the first Melbourne concert, an additional 16,000 people gathered outside the fenced-off area to listen to the concert. In Adelaide, the group performed one concert at West Lakes Football Stadium before 20,000 people with another 10,000 listening outside. During the first of five concerts in Perth, there was a bomb scare with everyone having to evacuate the Entertainment Centre. The trip was accompanied by mass hysteria and unprecedented media attention ("Swedish ABBA stirs box-office in Down Under tour...and the media coverage of the quartet rivals that set to cover the upcoming Royal tour of Australia", wrote "Variety"), and is captured on film in "", directed by Lasse Hallström.
The Australian tour and its subsequent "ABBA: The Movie" produced some ABBA lore, as well. Fältskog's blonde good looks had long made her the band's "pin-up girl", a role she disdained. During the Australian tour, she performed in a skin-tight white jumpsuit, causing one Australian newspaper to use the headline "Agnetha's bottom tops dull show". When asked about this at a news conference, she replied: "Don't they have bottoms in Australia?"
In December 1977, ABBA followed up "Arrival" with the more ambitious fifth album "", released to coincide with the debut of "ABBA: The Movie". Although the album was less well received by UK reviewers, it did spawn more worldwide hits: "The Name of the Game" and "Take a Chance on Me", which both topped the UK charts, and peaked at number 12 and number 3 respectively on the Billboard Hot 100 chart in the US. Although "Take a Chance on Me" did not top the American charts, it proved to be ABBA's biggest hit single there, selling more copies than "Dancing Queen". "The Album" also included "Thank You for the Music", the B-side of "Eagle" in countries where the latter had been released as a single, and was belatedly released as an A-side single in the United Kingdom and Ireland in 1983. "Thank You for the Music" has become one of the best loved and best known ABBA songs without being released as a single during the group's lifetime.
Polar Music Studio formation.
By 1978, ABBA was one of the biggest bands in the world. They converted a vacant movie theatre into the Polar Music Studio, a state-of-the-art studio in Stockholm. The studio was used by several other bands; notably, Genesis' "Duke" and Led Zeppelin's "In Through the Out Door" were recorded there. During May, the group went to the United States for a promotional campaign, performing alongside Andy Gibb on Olivia Newton-John's TV show. Recording sessions for the single "Summer Night City" were an uphill struggle, but upon release the song became another hit for the group. The track would set the stage for ABBA's foray into disco with their next album.
On 9 January 1979, the group performed "Chiquitita" at the Music for UNICEF Concert held at the United Nations General Assembly to celebrate UNICEF's Year of the Child. ABBA donated the copyright of this worldwide hit to the UNICEF; see Music for UNICEF Concert. The single was released the following week, and reached number 1 in ten countries.
North American and European tours.
In mid-January 1979, Ulvaeus and Fältskog announced they were getting divorced. The news caused interest from the media, and led to speculation about the band's future. ABBA assured the press and their fan base they were continuing their work as a group, and that the divorce would not affect them. Nonetheless, the media continued to confront them with this in interviews. To escape the media swirl and concentrate on their writing, Andersson and Ulvaeus secretly travelled to Compass Point Studios in Nassau, Bahamas, where for two weeks they prepared their next album's songs in relative quiet.
The group's sixth studio album, "Voulez-Vous", was released in April 1979, the title track of which was recorded at the famous Criteria Studios in Miami, Florida, with the assistance of recording engineer Tom Dowd amongst others. The album topped the charts across Europe and in Japan and Mexico, hit the Top 10 in Canada and Australia and the Top 20 in the United States. None of the singles from the album reached number 1 on the UK charts, but "Chiquitita", "Does Your Mother Know", "Angeleyes" (with "Voulez-Vous", released as a double A-side) and "I Have a Dream" were all UK Top 5 hits. In Canada, "I Have a Dream" became ABBA's second number 1 on the RPM Adult Contemporary chart (after "Fernando" hit the top previously). Also in 1979, the group released their second compilation album, "Greatest Hits Vol. 2", which featured a brand new track: "Gimme! Gimme! Gimme! (A Man After Midnight)", another number 3 hit in both the UK and Germany. In Russia during the late 1970s, the group were paid in oil commodities because of an embargo on the ruble.
On 13 September 1979, ABBA began their at the Northlands Coliseum in Edmonton, Canada, with a full house of 14,000. "The voices of the band, Agnetha's high sauciness combined with round, rich lower tones of Anni-Frid, were excellent...Technically perfect, melodically correct and always in perfect pitch...The soft lower voice of Anni-Frid and the high, edgy vocals of Agnetha were stunning", raved "Edmonton Journal".
During the next four weeks and with Bjorn wearing skintight pants, they played a total of 17 sold-out dates, 13 in the United States and four in Canada. The last scheduled ABBA concert in the United States in Washington DC was cancelled due to Fältskog's emotional distress suffered during the flight from New York to Boston, when the group's private plane was subjected to extreme weather conditions and was unable to land for an extended period. They appeared at the Boston Music Hall for the performance 90 minutes late. The tour ended with a show in Toronto, Canada at Maple Leaf Gardens before a capacity crowd of 18,000. "ABBA plays with surprising power and volume; but although they are loud, they're also clear, which does justice to the signature vocal sound...Anyone who's been waiting five years to see Abba will be well satisfied", wrote "Record World".
On 19 October 1979, the tour resumed in Western Europe where the band played 23 sold-out gigs, including six sold-out nights at London's Wembley Arena.
Progression.
In March 1980, ABBA travelled to Japan where upon their arrival at Narita International Airport, they were besieged by thousands of fans. The group played eleven concerts to full houses, including six shows at Tokyo's Budokan. This tour was the last "on the road" adventure of their career.
In the summer of 1980, the group released the single "The Winner Takes It All" the group's eighth UK chart topper (and their first since 1978). The song is widely misunderstood as being written about Ulvaeus and Fältskog's marital tribulations; Ulvaeus wrote the lyrics, but has stated they were not about his own divorce; Fältskog has repeatedly stated she was not the loser in their divorce. In the United States, the single peaked at number 8 on the Billboard Hot 100 chart and became ABBA's second Billboard Adult Contemporary number 1. It was also re-recorded by Andersson and Ulvaeus with a slightly different backing track, by French chanteuse Mireille Mathieu at the end of 1980 – as "Bravo Tu As Gagné", with French lyrics by Alain Boublil. November the same year saw the release of ABBA's seventh album "Super Trouper", which reflected a certain change in ABBA's style with more prominent use of synthesizers and increasingly personal lyrics. It set a record for the most pre-orders ever received for a UK album after one million copies were ordered before release. The 2nd single from the album, "Super Trouper", also hit number 1 in the UK, becoming the group's ninth and final UK chart-topper. Another track from the "Super Trouper" album, "Lay All Your Love on Me", released in 1981 as a 12-inch single only in selected territories, managed to top the Billboard Hot Dance Club Play chart and peaked at number 7 on the UK singles chart becoming, at the time, the highest ever charting 12-inch release in UK chart history.
Also in 1980, ABBA recorded a compilation of Spanish-language versions of their hits called "Gracias Por La Música". This was released in Spanish-speaking countries as well as in Japan and Australia. The album became a major success, and along with the Spanish version of "Chiquitita", this signalled the group's breakthrough in Latin America. "ABBA Oro: Grandes Éxitos", the Spanish equivalent of "ABBA Gold: Greatest Hits", was released in 1999.
Final album and performances (1981–1982).
In January 1981, Ulvaeus married Lena Källersjö, and manager Stig Anderson celebrated his 50th birthday with a party. For this occasion, ABBA recorded the track "Hovas Vittne" (a pun on the Swedish name for Jehovah's Witness and Anderson's birthplace, Hova) as a tribute to him, and released it only on 200 red vinyl copies, to be distributed to the guests attending the party. This single has become a sought-after collectible. In mid-February 1981, Andersson and Lyngstad announced they were filing for divorce. Information surfaced that their marriage had been an uphill struggle for years, and Benny had already met another woman, Mona Nörklit, whom he married in November 1981.
Andersson and Ulvaeus had songwriting sessions during the spring of 1981, and recording sessions began in mid-March. At the end of April, the group recorded a TV special, "Dick Cavett Meets ABBA" with the US talk show host Dick Cavett. "The Visitors", ABBA's eighth and final studio album, showed a songwriting maturity and depth of feeling distinctly lacking from their earlier recordings but still placing the band squarely in the pop genre, with catchy tunes and harmonies. Although not revealed at the time of its release, the album's title track, according to Ulvaeus, refers to the secret meetings held against the approval of totalitarian governments in Soviet-dominated states, while other tracks address topics like failed relationships, the threat of war, aging, and loss of innocence. The album's only major single release, "One of Us", proved to be the last of ABBA's nine number 1 singles in Germany in December 1981; and the swansong of their sixteen Top 5 singles on the South African chart. "One of Us" was also ABBA's final Top 10 hit in the UK.
Although it topped the album charts across most of Europe, including the UK and Germany, "The Visitors" was not as commercially successful as its predecessors, showing a commercial decline in previously loyal markets such as France, Australia and Japan. A track from the album, "When All Is Said and Done", was released as a single in North America, Australia and New Zealand, and fittingly became ABBA's final Top 40 hit in the US (debuting on the US charts on 31 December 1981), while also reaching the US Adult Contemporary Top 10, and number 4 on the RPM Adult Contemporary chart in Canada. The song's lyrics, as with "The Winner Takes It All" and "One of Us", dealt with the painful experience of separating from a long-term partner, though it looked at the trauma more optimistically. With the now publicised story of Andersson and Lyngstad's divorce, speculation increased of tension within the band. Also released in the United States was the title track of "The Visitors", which hit the Top Ten on the Billboard Hot Dance Club Play chart.
Last recording sessions.
In the spring of 1982, songwriting sessions had started and the group came together for more recordings. Plans were not completely clear, but a new album was discussed and the prospect of a small tour suggested. The recording sessions in May and June 1982 were a struggle, and only three songs were eventually recorded: "You Owe Me One", "I Am the City" and "Just Like That". Andersson and Ulvaeus were not satisfied with the outcome, so the tapes were shelved and the group took a break for the summer.
Back in the studio again in early August, the group had changed plans for the rest of the year: they settled for a Christmas release of a double album compilation of all their past single releases to be named "". New songwriting and recording sessions took place, and during October and November, they released the singles "The Day Before You Came"/"Cassandra" and "Under Attack"/"You Owe Me One", the A-sides of which were included on the compilation album. Neither single made the Top 20 in the United Kingdom, though "The Day Before You Came" became a Top 5 hit in many European countries such as Germany, the Netherlands and Belgium. The album went to number 1 in the UK and Belgium, Top 5 in the Netherlands and Germany and Top 20 in many other countries. "Under Attack", the group's final release before disbanding, was a Top 5 hit in the Netherlands and Belgium.
"I Am the City" and "Just Like That" were left unreleased on "The Singles: The First Ten Years" for possible inclusion on the next projected studio album, though this never came to fruition. "I Am the City" was eventually released on the compilation album "" in 1993, while "Just Like That" has been recycled in new songs with other artists produced by Andersson and Ulvaeus. A reworked version of the verses ended up in the musical "Chess". The chorus section of "Just Like That" was eventually released on a retrospective box set in 1994. Despite a number of requests from fans, Ulvaeus and Andersson are still refusing to release ABBA's version of "Just Like That" in its entirety, even though the complete version surfaced on bootlegs.
The group travelled to London to promote "The Singles: The First Ten Years" in the first week of November 1982, appearing on "Saturday Superstore" and "The Late, Late Breakfast Show", and also to West Germany in the second week, to perform on Show Express. On 19 November 1982, ABBA appeared for the last time in Sweden on the TV programme Nöjesmaskinen, and on 11 December 1982, they made their last performance ever, transmitted to the UK on Noel Edmonds' "The Late, Late Breakfast Show", through a live link from a TV studio in Stockholm.
Last performances.
Andersson and Ulvaeus began collaborating with Tim Rice in early 1983 on writing songs for the musical project "Chess", while Fältskog and Lyngstad both concentrated on international solo careers. While Andersson and Ulvaeus were working on the musical, a further co-operation between the three of them came with the musical "Abbacadabra" that was produced in France for television. It was a children's musical utilising 14 ABBA songs. Alain and Daniel Boublil, who wrote "Les Misérables", had been in touch with Stig Anderson about the project, and the TV musical was aired over Christmas on French TV and later a Dutch version was also broadcast. Boublil previously also wrote the French lyrics for Mireille Mathieu's version of "The Winner Takes It All".
Lyngstad, who had recently moved to Paris, participated in the French version, and recorded a single, "Belle", a duet with French singer Daniel Balavoine. The song was a cover of ABBA's 1976 instrumental track "Arrival". As the single "Belle" sold well in France, Cameron Mackintosh wanted to stage an English language version of the show in London, with the French lyrics translated by David Wood and Don Black; Andersson and Ulvaeus got involved in the project, and contributed with one new song, "The Seeker". "Abbacadabra" premièred on 8 December 1983 at The Lyric Hammersmith Theatre in London, to mixed reviews and full houses for eight weeks, closing on 21 January 1984. Lyngstad was also involved in this production, recording "Belle" in English as "Time", a duet with actor and singer B. A. Robertson: the single sold well, and was produced and recorded by Andersson and Ulvaeus.
All four members made their last public appearance, as four friends more than as ABBA, in January 1986, when they recorded a video of themselves performing an acoustic version of "Tivedshambo", which was the first song written by their manager, Stig Anderson, for a Swedish TV show honouring Anderson on his 55th birthday. The four had not seen each other for more than two years. That same year they also performed privately at another friend's 40th birthday: their old tour manager, Claes af Geijerstam. They sang a self-written song titled "Der Kleine Franz" that was later to resurface in "Chess". Also in 1986, "ABBA Live" was released, featuring selections of live performances from the group's 1977 and 1979 tours. The four members were guests at the 50th birthday of Görel Hanser in 1999. Hanser was a long-time friend of all four, and also former secretary of Stig Anderson. Honouring Görel, ABBA performed a Swedish birthday song "Med En Enkel Tulipan" a cappella.
Benny Andersson has on several occasions performed old ABBA songs. In June 1992, he and Ulvaeus appeared with U2 at a Stockholm concert, singing the chorus of "Dancing Queen", and a few years later during the final performance of the B  B in Concert in Stockholm, Andersson joined the cast for an encore at the piano. Andersson frequently adds an ABBA song to the playlist when he performs with his BAO band. He also played the piano during new recordings of the ABBA songs "Like an Angel Passing Through My Room" with opera singer Anne Sofie von Otter, and "When All Is Said and Done" with Swede Viktoria Tolstoy. In 2002, Andersson and Ulvaeus both performed an a cappella rendition of the first verse of "Fernando" as they accepted their Ivor Novello award in London. Lyngstad performed and recorded an a cappella version of "Dancing Queen" with the Swedish group The Real Group in 1993, and has also re-recorded "I Have a Dream" with Swiss singer Dan Daniell in 2003.
Breaking up.
ABBA has never officially announced the end of the group, but it has long been considered dissolved. Their last public performance together as ABBA was on the British TV programme "The Late, Late Breakfast Show" (live from Stockholm) on 11 December 1982. In January 1983, Fältskog started recording sessions for a solo album, as Lyngstad had successfully released her album "Something's Going On" some months earlier. Ulvaeus and Andersson, meanwhile, started songwriting sessions for the musical "Chess". In interviews at the time, Björn and Benny denied the split of ABBA ("Who are we without our ladies? Initials of Brigitte Bardot?"), and Lyngstad and Fältskog kept claiming in interviews that ABBA would come together for a new album repeatedly during 1983 and 1984. Internal strife between the group and their manager escalated and the band members sold their shares in Polar Music during 1983. Except for a TV appearance in 1986, the foursome did not come together publicly again until they were reunited at the Swedish premiere of the "Mamma Mia!" movie on 4 July 2008.
In an interview with the "Sunday Telegraph", following the premiere, Ulvaeus and Andersson confirmed that there was nothing that could entice them back on stage again. Ulvaeus said: "We will never appear on stage again. [...] There is simply no motivation to re-group. Money is not a factor and we would like people to remember us as we were. Young, exuberant, full of energy and ambition. I remember Robert Plant saying Led Zeppelin were a cover band now because they cover all their own stuff. I think that hit the nail on the head."
However, on 3 January 2011, Fältskog, who has been long considered to be the most reclusive member of the group and possibly also the major obstacle to any reunion, raised the possibility of reuniting for a one-off engagement. She admitted that she has not yet brought the idea up to the other three members.
After ABBA.
Benny Andersson and Björn Ulvaeus.
In October 1984, Ulvaeus and Andersson together with lyricist Tim Rice released the musical concept double album "Chess". The singles "One Night in Bangkok" (with vocals by Murray Head and Anders Glenmark ) and "I Know Him So Well" (a duet by Barbara Dickson and Elaine Paige, and later also recorded by both Barbra Streisand and Whitney Houston) were both hugely successful. The former reached number 1 in Australia, Germany, Spain and Switzerland; number 2 in Austria, France and New Zealand; number 3 in Canada, Norway, Sweden and the US, as well as reaching the top 10 in a few other countries. In May 1986, the musical premièred in London's West End, and ran for almost three years. "Chess" also opened on Broadway in April 1988, but closed within two months due to bad reviews. In Stockholm, the composers staged "Chess på svenska" ("Chess in Swedish") in 2003, with some new material, including the musical numbers ""Han är en man, han är ett barn"" ("He's a Man, He's a Child") and ""Glöm mig om du kan"" ("Forget Me If You Can"). In 2008, the musical was again revived for a successful staging at London's Royal Albert Hall which was subsequently released on DVD, and then in two successful separate touring productions in the United States and United Kingdom, in 2010.
Andersson and Ulvaeus' next project, "Kristina från Duvemåla", an epic Swedish musical, premiered in Malmö, in southern Sweden in October 1995. The musical ran for five years in Stockholm, and an English version has been in development for some considerable time. It has been reported that a Broadway production is in its earliest stages of pre-production. In the meantime, following some earlier workshops, a full presentation of the English translation of the musical in concert, now with the shortened name of ""Kristina"", took place to capacity crowds in September 2009 at New York's Carnegie Hall, and in April 2010 at London's Royal Albert Hall, followed by a CD release of the New York recordings.
Since 1983, besides "Chess" and "Kristina från Duvemåla", Benny Andersson has continued writing songs with Ulvaeus. The pair produced two English-language pop albums with Swedish duo Gemini in 1985 and 1987. In 1987, Andersson also released his first solo album on his own label, Mono Music, called ""Klinga mina klockor"" ("Ring My Bells"), all new material inspired by Swedish folk music – and followed it with his second album titled "November 1989".
In the 1990s, Andersson wrote music for the popular Swedish cabaret quartet Ainbusk Singers, giving them two hits: "Lassie" and ""Älska mig"" ("Love me"), and later produced "Shapes", an English-language album by the group's Josefin Nilsson with all-new material by Andersson and Ulvaeus. Andersson has also regularly written music for films (most notably to Roy Andersson's "Songs from the Second Floor"). In 2001, Andersson formed his own band, Benny Anderssons Orkester (BAO), which released three successful albums in 2001, 2004 and 2007 respectively. Andersson has the distinction of remaining the longest in the Swedish Radio Svensktoppen charts; the song ""Du är min man"" ("You Are My Man"), sung by Helen Sjöholm, spent 278 weeks there between 2004 and 2009. Andersson released his third album BAO 3 in October 2007, of new material with his band BAO and vocalists Helen Sjöholm and Tommy Körberg, as well as playing to full houses at two of Sweden's largest concert venues in October and November 2007, with an audience of 14,000.
 Ulvaeus has not appeared on stage performing music since ABBA, but had a reunion with his co-members of The Hootenanny Singers on 16 July 2005 at a music festival in his hometown of Västervik, singing their 1966 hit "Marianne".
Andersson and Ulvaeus have been highly involved in the worldwide productions of the musical "Mamma Mia!", alongside Lyngstad who attends premieres. They were also involved in the production of the successful film version of the musical, which opened in July 2008. Andersson produced the soundtrack utilising many of the musicians ABBA used on their albums and tours. Andersson made a cameo appearance in the movie as a 'fisherman' piano player in the "Dancing Queen" scene, while Ulvaeus is seen as a Greek god playing a lyre during the closing credits.
Andersson and Ulvaeus have continuously been writing new material; most recently the two wrote 7 songs for Anderssons 'BAO' 2011 album 'O Klang Och Jubeltid', performed as usual by vocalists Sjöholm, Körberg and Moreus. In July 2009, 'BAO' released their first international release, now named "The Benny Andersson Band", with the album "The Story of a Heart". The album was a compilation of 14 tracks from Andersson's five Swedish-language releases between 1987 and 2007, including five songs now recorded with lyrics by Ulvaeus in English, and the new title song premiered on BBC2's "Ken Bruce Show". A Swedish-language version of the title track, ""Sommaren Du Fick"" ("The Summer You Got"), was released as a single in Sweden prior to the English version, with vocals by Helen Sjöholm.
In the spring of 2009, Andersson also released a single recorded by the staff at his privately owned Stockholm hotel "Hotel Rival", titled "2nd Best to None", accompanied by a video showing the staff at work. In 2008, Andersson and Ulvaeus wrote a song for Swedish singer Sissela Kyle, titled ""Jag vill bli gammal"" ("I Wanna Grow Old"), for her Stockholm stage show ""Your Days Are Numbered"", which was never recorded and released, but did get a TV performance. Ulvaeus also contributed lyrics to ABBA's 1976 instrumental track "Arrival" for Sarah Brightman's cover version recorded for her 2008 album "Winter Symphony". New English lyrics have also been written for Andersson's 1999 song ""Innan Gryningen"" (then also named "Millennium Hymn"), with the new title "The Silence of the Dawn" for Barbara Dickson (performed live, but not yet recorded and released. In 2007, they wrote the new song ""Han som har vunnit allt"" ("He Who's Won It All") for actor/singer Anders Ekborg. Björn wrote English lyrics for two older songs from Benny's solo albums: "I Walk with You Mama" ("Stockholm by Night", 1989) and "After the Rain" ("Efter regnet", 1987) for opera singer Anne Sofie Von Otter, for her Andersson tribute album "I Let the Music Speak". Barbra Dickson recorded (but not yet released) a Björn  Benny song called 'The Day The Wall Came Tumbling Down'; the song eventually was released by Australian 'Mamma Mia!' musical star Anne Wood 201 album of ABBA covers, Divine Discontent. As of October 2012, Björn Ulvaeus has mentioned writing new material with Benny for a 'BAO' Christmas release (also mentioned as a BAO 'box'), and Benny is busy writing music for a Swedish language obscure musical, 'Hjälp Sökes' ('Help is Wanted') together with Kristina Lugn and Lars Rudolfsson, premiering February 8, 2013.
Andersson has also written music for a documentary film about Olof Palme, re-recording the track 'Sorgmarch' from his last album throughout the film.
Agnetha Fältskog and Anni-Frid Lyngstad.
Both female members of ABBA pursued solo careers on the international scene after their work with the group. In 1982, Lyngstad chose Genesis drummer and vocalist Phil Collins to produce the album "Something's Going On" and unveiled the hit single and video "I Know There's Something Going On" in the autumn of that year. The single became a number 1 hit in France (where it spent five weeks at the top), Belgium, Switzerland and Costa Rica. The track reached number 3 in Austria, the Netherlands, Norway, Sweden and Poland, and was also a Top 10 hit in Germany, Italy, Finland, South Africa and Australia. In the United States, the single peaked at number 13 on the Billboard Hot 100. Lyngstad's album sold 1.5 million copies internationally. Sveriges Television documented this historical event, by filming the whole recording process. The result became a one-hour TV documentary, including interviews with Lyngstad, Collins, Ulvaeus and Andersson as well as all the musicians. This documentary and the promotion videos from the album are included in "Frida - The DVD".
Lyngstad's second solo album after ABBA was called "Shine", produced by Steve Lillywhite. "Shine" was recorded in Paris and released in 1984. "Shine" reached the Top 10 on the album charts in Sweden, Norway and Belgium and the Top 20 in the Netherlands. The title track was the album's first single release. "Shine" was Lyngstad's final studio album release for twelve years. It featured "Slowly", the last known Andersson-Ulvaeus composition to have been recorded by one of the former female ABBA vocalists to date. The promotion videos and clips for "Shine" are included in "Frida - The DVD".
In 1983, Fältskog released the solo album "Wrap Your Arms Around Me" which achieved platinum sales in Sweden. This included the single "The Heat Is On", which was a hit all over Europe and Scandinavia. It reached number one in Sweden and Norway and number two in the Netherlands and Belgium. In the United States, Fältskog earned a Billboard Top 30 hit with "Can't Shake Loose". In Europe, the single "Wrap Your Arms Around Me" was another successful hit, topping the charts in Belgium and Denmark, reaching the Top 5 in Sweden, the Netherlands and South Africa, and the Top 20 in Germany and France. The album sold 1,2 million copies worldwide. The album was produced by the highly successful producer and songwriter Mike Chapman, also known for his work with The Sweet, Mud, Suzi Quatro, Blondie, Pat Benatar and The Knack. According to Chapman, the album sold 4 million units worldwide.
"It's So Nice to be Rich" was Agnetha's fourth top ten hit in Sweden in 1983. Her duet with Tomas Ledin, "Never Again" was the first one.
Fältskog's second English-language solo album, "Eyes of a Woman", was released in March 1985, peaking at number 2 in Sweden and another platinum seller and performing reasonably well in Europe. The album was produced by Eric Stewart of 10cc. The first single from the album was her self-penned "I Won't Let You Go". Agnetha's duet with Ola Håkansson "The Way You Are" was a number one hit in Sweden in 1986 and was awarded double platinum. 
In November 1987, Fältskog released her third post-ABBA solo album, the Peter Cetera-produced "I Stand Alone", which also included the Billboard Adult Contemporary duet with Cetera, "I Wasn't the One (Who Said Goodbye)", as well as the European charting singles "The Last Time" and "Let It Shine". The album was extremely successful in Sweden, where it spent eight weeks at number 1 and was awarded double-platinum. Shortly after some minor European promotion for the album in early 1988, Fältskog withdrew from public life and halted her music career. In 1996, she released her autobiography, "As I Am", and a compilation album featuring her solo hits alongside some ABBA classics. In 2004, she made a successful comeback, releasing the critically acclaimed album "My Colouring Book", which debuted at number 1 in Sweden (achieving triple-platinum status), number 6 in Germany, and number 12 in the UK, winning a silver award, and achieving gold status in Finland. The single "If I Thought You'd Ever Change Your Mind" (a cover of the Cilla Black 1960s song) became Fältskog's biggest solo hit in the United Kingdom, reaching number 11. The single peaked at number 2 in Sweden and was a hit throughout Scandinavia and Europe. A further single, "When You Walk in the Room", was released but met with less success, only peaking at number 34 in the United Kingdom. In January 2007, she sang a live duet on stage with Swedish singer Tommy Körberg at the after party for the final performance of the musical, "Mamma Mia!", in Stockholm, at which Benny Andersson and Björn Ulvaeus were also present.
In 1992, Lyngstad had been asked and chosen to be the chairperson for the environmental organisation ""Artister för miljön"" (Artists for the Environment) in Sweden. She became chairwoman for this organisation from 1992 to 1995. To mark her interests for the environment, she recorded the Julian Lennon song "Saltwater" and performed it live in Stockholm. She arranged and financed summer camps for poor children in Sweden, focusing on environmental and ecological issues. Her environmental work for this organisation led up to the decision to record again. The album "Djupa andetag" ("Deep Breaths") was released towards the end of 1996 and became a success in Sweden, where it reached number 1. The lyrics for the single from this album, "Även en blomma" ("Even a Flower"), deal with environmental issues. In 2004, Lyngstad recorded a song called "The Sun Will Shine Again", written especially for her and released with former Deep Purple member Jon Lord. The couple made several TV performances with this song in Germany. Lyngstad lives a relatively low-profile life but occasionally appears at a party or charity function. On 26 August 1992, she married Prince Heinrich Ruzzo Reuss von Plauen, of the German Reuss family. Von Plauen died of lymphoma in 1999 at the age of 49. In addition to losing her husband, Lyngstad had also lost her daughter Lise-Lotte in a car crash a year earlier.
On 15 November 2005, Lyngstad's 60th birthday, Universal released the "Frida Box Set", consisting of the solo albums she recorded for the Polar Label. Also included is the 3-hour documentary "Frida - The DVD". On this DVD, which covers her entire singing career, the viewer is guided by Lyngstad herself through the years from her TV debut in Sweden in 1967 to the TV performances she made in Germany in 2004. Many rare clips are included in the set and each performance is explained by Lyngstad herself. The interview with Lyngstad was filmed in the Swiss Alps in summer 2005.
Lyngstad returned to the recording studio in 2010 with recording the vocals for Morning Has Broken, the Christian Hymn popularised by Cat Stevens, for Swedish guitarist Georg Wadenius October 2010 'Reconnections', an album with invited vocalists, reaching #17 in the Swedish charts.
Fältskog is reported to have started recording sessions as of September 2012 of said newly written material, the record being produced by renowned Jörgen Elofsson.
As at October 2012, only Fältskog and Andersson from the group remain active as recording artists.
Revival.
The same year the members of ABBA went their separate ways, the French production of a "tribute" show (a children's TV musical named "Abbacadabra" using 14 ABBA songs) spawned new interest in the group's music.
After receiving little attention during the mid-to-late-1980s, ABBA's music experienced a resurgence in the early 1990s due to the UK synth-pop duo Erasure, who released a cover extended play featuring versions of ABBA songs which topped the charts in 1992. As U2 arrived in Stockholm for a concert in June of that year, the band paid homage to ABBA by inviting Björn Ulvaeus and Benny Andersson to join them on stage for a rendition of "Dancing Queen", playing guitar and keyboards. September 1992 saw the release of "", a new compilation album. The single "Dancing Queen" received radio airplay in the UK in summer 1992 to promote the album. The song returned to the Top 20 of the UK singles chart in August that year, this time peaking at number 16.
The enormous interest in the "ABBA Gold: Greatest Hits" compilation saw the release of "" in 1993.
In 1994, two Australian cult films caught the attention of the world's media, both focussing on admiration for ABBA: "The Adventures of Priscilla, Queen of the Desert" and "Muriel's Wedding". The same year, "Thank You for the Music", a four-disc box set comprising all the group's hits and stand-out album tracks, was released with the involvement of all four members. "By the end of the twentieth century", American critic Chuck Klosterman wrote a decade later, "it was far more contrarian to hate ABBA than to love them."
ABBA were soon recognized and embraced by other acts: Evan Dando of The Lemonheads recorded a cover version of "Knowing Me, Knowing You"; Sinéad O'Connor and Boyzone's Stephen Gately have recorded "Chiquitita"; Tanita Tikaram, Blancmange and Steven Wilson paid tribute to "The Day Before You Came". Cliff Richard covered "Lay All Your Love On Me", while Dionne Warwick, Peter Cetera, and Celebrity Skin recorded their versions of "SOS". U.S. alternative-rock musician Marshall Crenshaw has also been known to play a version of "Knowing Me, Knowing You" in concert appearances, while legendary English Latin pop songwriter Richard Daniel Roman has recognized ABBA as a major influence. Swedish metal guitarist Yngwie Malmsteen covered "Gimme! Gimme! Gimme! (A Man After Midnight)" with slightly altered lyrics.
Two different compilation albums of ABBA songs have been released. "ABBA: A Tribute" coincided with the 25th anniversary celebration and featured 17 songs, some of which were recorded especially for this release. Notable tracks include Go West's "One of Us", Army of Lovers "Hasta Mañana", Information Society's "Lay All Your Love on Me", Erasure's "Take a Chance on Me" (with MC Kinky), and Lyngstad's a cappella duet with The Real Group of "Dancing Queen". A second 12-track album was released in 1999, entitled "ABBAMANIA", with proceeds going to the Youth Music charity in England. It featured all new cover versions: notable tracks were by Madness ("Money, Money, Money"), Culture Club ("Voulez-Vous"), The Corrs ("The Winner Takes It All"), Steps ("Lay All Your Love on Me", "I Know Him So Well"), and a medley entitled "Thank ABBA for the Music" performed by several artists and as featured on the Brits Awards that same year.
In 1997, an ABBA tribute group was formed, the ABBA Teens, which was subsequently renamed the A*Teens to allow the group some independence. The group's first album, "The ABBA Generation", consisting solely of ABBA covers reimagined as 1990's pop songs, was a worldwide success and so were subsequent albums. The group disbanded in 2004 due to a grueling schedule and intentions to go solo.
In Sweden, the growing recognition of the legacy of Andersson and Ulvaeus resulted in the 1998 "B  B Concerts": a tribute concert (with Swedish singers who had worked with the songwriters through the years) showcasing not only their ABBA years, but hits both before and after ABBA. The concert was a success, and was ultimately released on CD. It later toured Scandinavia and even went to Beijing in the People's Republic of China for two concerts.
In 2000, ABBA were reported to have turned down an offer of approximately US$1,000,000,000 (one billion US dollars) to do a reunion tour consisting of 100 concerts.
For the 2004 semi-final of the Eurovision Song Contest, staged in Istanbul 30 years after ABBA had won the contest in Brighton, all four members made cameo appearances in a special comedy video made for the interval act, entitled "Our Last Video Ever". Others well-known stars such as Rik Mayall, Cher and Iron Maiden's Eddie also made appearances in the video. It was not included in the official DVD release of the Eurovision Contest, but was issued as a separate DVD release, retitled "The Last Video" at the request of the former ABBA members.
In 2005, all four members of ABBA appeared at the Stockholm premiere of the musical "Mamma Mia!".
On 4 July 2008, all four ABBA members were reunited at the Swedish premiere of the film "Mamma Mia!". It was only the second time all of them had appeared together in public since 1986. During the appearance, they re-emphasized that they intended never to officially reunite, citing the opinion of Robert Plant that the re-formed Led Zeppelin was more like a cover band of itself than the original band. Ulvaeus stated that he wanted the band to be remembered as they were during the peak years of their success.
The compilation album "", originally released in 1992, returned to number one in the UK album charts for the fifth time on 3 August 2008. On 14 August 2008, the "Mamma Mia! The Movie" film soundtrack went to number 1 on the US Billboard charts, ABBA's first US chart-topping album. During the band's heyday the highest album chart position they had ever achieved in America was number 14.
In November 2008, all eight studio albums, together with a ninth of rare tracks, was released as "The Albums". It hit several charts, peaking at number 4 in Sweden and reaching the Top 10 in several other European territories.
In 2008, Sony Computer Entertainment Europe, in collaboration with Universal Music Group Sweden AB, released "SingStar ABBA" on both the PlayStation 2 and PlayStation 3 games consoles, as part of the SingStar music video games. The PS2 version features 20 ABBA songs, while 25 songs feature on the PS3 version.
On 22 January 2009, Fältskog and Lyngstad appeared together on stage to receive the Swedish music award ""Rockbjörnen"" (for "lifetime achievement"). In an interview, the two women expressed their gratitude for the honorary award and to thank their fans.
On 25 November 2009, PRS for Music announced that the British public voted ABBA as the band they would most like to see re-form.
On 27 January 2010, ABBAWORLD, a 25-room touring exhibition featuring interactive and audiovisual activities, debuted at Earl's Court Exhibition Centre in London. According to the exhibition's website, ABBAWORLD is "approved and fully supported" by the band members.
Mamma Mia was released as one of the first few non-premium song selections for the online RPG game Bandmaster. On May 17, 2011, Gimme! Gimme! Gimme! has been added as non-premium song selection for Bandmaster Philippines server.
On 15 November 2011, Ubisoft released a dancing game called "", for the Wii.
In January 2012, Universal Music announced the re-release of ABBA's final album 'The Visitors' featuring a previously unheard track 'From a Twinkling Star to a Passing Angel'.
Recording process.
They were perfectionists in the studio and would work on tracks tirelessly until they got them right. Agnetha said they didn't quit and try to pick it back up at a later date, they would work on it until they came up with something better. See Summer Night City as an example of them not being happy with a song and the amount of effort they put into that song.
They would start the basic rhythm track with a drummer, guitarist and bass player. All the other arrangements - vocals, other instruments - would be overlaid onto this basic track. The vocals would be the next and orchestra overdubs were usually left till last.
Success in the United States.
During their active career, from 1972 to 1982, ABBA achieved 14 Top 40 singles on the Billboard Hot 100 (13 on the Cashbox Top 100), ten of which made the Top 20 on both charts, with four singles reaching the Top 10, including "Dancing Queen" which reached number 1.
While "Fernando" and "SOS" did not break the Top 10 on the Billboard Hot 100 chart they did reach the Top 10 on Cashbox ("Fernando") and Record World ("SOS") charts.
The group also had 12 Top 20 singles on the Billboard Adult Contemporary chart with two of them, "Fernando" and "The Winner Takes It All", reaching number 1. "Lay All Your Love on Me" was ABBA's fourth number 1 single on a Billboard chart, topping the Hot Dance Club Play chart. The singles "Dancing Queen" and "Take a Chance on Me" were certified gold (more than 1 million copies sold) by the RIAA.
Nine ABBA albums made their way into the Top 100 on the Billboard 200 album chart, with seven of them reaching the Top 50. Four of those albums reached the Top 20, with "ABBA: The Album" at number 14 being the highest position. Five albums received RIAA gold certification (more than 500,000 copies sold), while three acquired platinum status (selling more than one million copies). In 1993, the "ABBA Gold: Greatest Hits" collection was released in the United States and has since become a seven-time platinum best-seller. It also topped the Bilboard Top Pop Catalog Albums chart (it also peaked at number 11 on a Billboard Comprehensive Albums chart).
Fashion, videos, advertising campaigns.
ABBA were widely noted for the colourful and trend-setting costumes its members wore. The videos that accompanied some of their biggest hits are often cited as being among the earliest examples of the genre. Most of ABBA's videos (and "ABBA: The Movie") were directed by Lasse Hallström, who would later direct the films "My Life as a Dog", "The Cider House Rules" and "Chocolat".
ABBA made videos because their songs were hits in many different countries and personal appearances were not always possible. This was also done in an effort to minimize travelling, particularly to countries that would have required extremely long flights. Fältskog and Ulvaeus had two young children and Fältskog, who was also afraid of flying, was very reluctant to leave her children for such a long time. ABBA's manager, Stig Anderson, realized the potential of showing a simple video clip on television to publicize a single or album, thereby allowing easier and quicker exposure than a concert tour. Some of these videos became classics because of the 1970s-era costumes and early video effects, such as the grouping of the band members in different combinations of pairs, overlapping one singer's profile with the other's full face, and the contrasting of one member against another.
In 1976, ABBA participated in a high-profile advertising campaign by the Matsushita Electric Industrial (today's Panasonic Corporation), which was designed to promote the brand National. This campaign was designed initially for Australia, where "National" was still the primary brand used by Matsushita, who had not introduced the "Panasonic" brand to Australia yet despite its widespread use in other parts of the world such as the United States. However, the campaign was also aired in Japan. Five commercials, each approximately one minute long, were produced, each using the "National Song" sung by ABBA, which used the melody and instrumental arrangement of "Fernando", adapted with new lyrics promoting National, and working in several slogans used by National in their advertising.
Political controversy.
In September 2010, band members Andersson and Ulvaeus criticized the right-wing Danish People's Party (DF) for using the ABBA song "Mamma Mia" (with modified lyrics) at rallies. The band had threatened to file a lawsuit against the DF, saying they never allowed their music to be used politically and that they had absolutely no interest in supporting the party. Their record label Universal Music later said that no legal action would be taken because an agreement had been reached.
References.
Notes
Bibliography
Further reading

</doc>
<doc id="881" url="http://it.wikipedia.org/wiki/?curid=881" title="Allegiance">
Allegiance

An allegiance is a duty of fidelity said to be owed by a subject or a citizen to his/her state or sovereign.
Etymology.
From Middle English "ligeaunce" (see medieval Latin "ligeantia", "a liegance"). The "al-" prefix was probably added through confusion with another legal term, "allegeance", an "allegation" (the French "allegeance" comes from the English). "Allegiance" is formed from "liege," from Old French "liege", "liege, free", of Germanic origin. The connection with Latin "ligare", "to bind," is erroneous.
Usage.
The term "allegiance" was traditionally often used by English legal commentators in a larger sense, divided by them into natural and local, the latter applying to the deference which even a foreigner must pay to the institutions of the country in which he happens to live. However it is in its proper sense, in which it indicates national character and the subjection due to that character, that the word is more important.
In that sense it represents the feudal liege homage, which could be due only to one lord, while simple homage might be due to every lord under whom the person in question held land.
United Kingdom.
The English doctrine, which was at one time adopted in the United States, asserted that allegiance was indelible: "Nemo potest exuere patriam". Accordingly, as the law stood before 1870, every person who by birth or naturalisation satisfied the conditions set forth, though he should be removed in infancy to another country where his family resided, owed an allegiance to the British crown which he could never resign or lose, except by act of parliament or by the recognition of the independence or the cession of the portion of British territory in which he resided. 
This refusal to accept any renunciation of allegiance to the Crown led to conflict with the United States over impressment, and then led to further conflicts even during the War of 1812, when thirteen Irish American prisoners of war were executed as traitors after the Battle of Queenston Heights; Winfield Scott urged American reprisal, but none was carried out. 
Allegiance is the tie which binds the subject to the Sovereign in return for that protection which the Sovereign affords the subject. It was the mutual bond and obligation between monarch and subjects, whereby subjects are called his liege subjects, because they are bound to obey and serve him; and he is called their liege lord, because he should maintain and defend them ("Ex parte Anderson" (1861) 3 El  El 487; 121 ER 525; "China Navigation Co v Attorney-General" (1932) 48 TLR 375; "Attorney-General v Nissan" 1 All ER 629; "Oppenheimer v Cattermole" [1972 3 All ER 1106). The duty of the Crown towards its subjects is to govern and protect. The reciprocal duty of the subject towards the Crown is that of allegiance. 
At common law allegiance is a true and faithful obedience of the subject due to his Sovereign. As the subject owes to his king his true and faithful allegiance and obedience, so the Sovereign 
Natural allegiance and obedience is an incident inseparable to every subject, for parte Anderson" (1861) 3 El  El 487; 121 ER 525). Natural-born subjects owe allegiance wherever they may be. Where territory is occupied in the course of hostilities by an enemy's force, even if the annexation of the occupied country is proclaimed by the enemy, there can be no change of allegiance during the progress of hostilities on the part of a citizen of the occupied country ("R v Vermaak" (1900) 21 NLR 204 (South Africa)). 
Allegiance is owed both to the Sovereign as a natural person and to the Sovereign in the political capacity ("Re Stepney Election Petition, Isaacson v Durant" (1886) 17 QBD 54 (per Lord Coleridge CJ)). Attachment to the person of the reigning Sovereign is not sufficient. Loyalty requires affection also to the office of the Sovereign, attachment to royalty, attachment to the law and to the constitution of the realm, and he who would, by force or by fraud, endeavour to prostrate that law and constitution, though he may retain his affection for its head, can boast but an imperfect and spurious species of loyalty ("R v O'Connell" (1844) 7 ILR 261). 
There were four kinds of allegiances ("Rittson v Stordy" (1855) 3 Sm  G 230; "De Geer v Stone" (1882) 22 Ch D 243; "Isaacson v Durant" (1886) 54 LT 684; "Gibson, Gavin v Gibson" 3 KB 379; "Joyce v DPP" [1946 AC 347; "Collingwood v Pace" (1661) O Bridg 410; "Lane v Bennett" (1836) 1 M  W 70; "Lyons Corp v East India Co" (1836) 1 Moo PCC 175; "Birtwhistle v Vardill" (1840) 7 Cl  Fin 895; "R v Lopez, R v Sattler" (1858) Dears  B 525; Ex p Brown (1864) 5 B  S 280); 
(a) "Ligeantia naturalis, absoluta, pura et indefinita", and this originally is due by nature and birthright, and is called "alta ligeantia", and those that owe this are called "subditus natus";
(b) "Ligeantia acquisita", not by nature but by acquisition or denization, being called a denizen, or rather denizon, because they are "subditus datus"; 
(c) "Ligeantia localis", by operation of law, when a friendly alien enters the country, because so long as they are in the country they are within the Sovereign's protection, therefore they owe the Sovereign a local obedience or allegiance ("R v Cowle" (1759) 2 Burr 834; "Low v Routledge" (1865) 1 Ch App 42; "Re Johnson, Roberts v Attorney-General" 1 Ch 821; "Tingley v Muller" [1917 2 Ch 144; "Rodriguez v Speyer" AC 59; "Johnstone v Pedlar" [1921 2 AC 262; "R v Tucker" (1694) Show Parl Cas 186; "R v Keyn" (1876) 2 Ex D 63; "Re Stepney Election Petn, Isaacson v Durant" (1886) 17 QBD 54);
(d) A legal obedience, where a particular law requires the taking of an oath of allegiance by subject or alien alike.
Natural allegiance was acquired by birth within the Sovereign's dominions (except for the issue of diplomats or of invading forces or of an alien in enemy occupied territory). The natural allegiance and obedience is an incident inseparable to every subject, for as soon as they are born they owe by birthright allegiance and obedience to the Sovereign ("Ex p. Anderson" (1861) 3 E  E 487). A natural-born subject owes allegiance wherever they may be, so that where territory is occupied in the course of hostilities by an enemy's force, even if the annexation of the occupied country is proclaimed by the enemy, there can be no change of allegiance during the progress of hostilities on the part of a citizen of the occupied country ("R v Vermaak" (1900) 21 NLR 204 (South Africa)). 
Acquired allegiance was acquired by naturalisation or denization. Denization, or "ligeantia acquisita", appears to be threefold ("Thomas v Sorrel" (1673) 3 Keb 143); 
Local allegiance was due by an alien while in the protection of the Crown. All friendly resident aliens incurred all the obligations of subjects ("The Angelique" (1801) 3 Ch Rob App 7). An alien, coming into a colony also became, temporarily a subject of the Crown, and acquired rights both within and beyond the colony, and these latter rights could not be affected by the laws of that colony ("Routledge v Low" (1868) LR 3 HL 100; 37 LJ Ch 454; 18 LT 874; 16 WR 1081, HL; "Reid v Maxwell" (1886) 2 TLR 790; "Falcon v Famous Players Film Co" 2 KB 474). 
A resident alien owed allegiance even when the protection of the Crown was withdrawn owing to the occupation of an enemy, because the absence of the Crown's protection was temporary and involuntary ("de Jager v Attorney-Geneneral of Natal" AC 326). 
Legal allegiance was due when an alien took an oath of allegiance required for a particular office under the Crown. 
By the Naturalisation Act 1870, it was made possible for British subjects to renounce their nationality and allegiance, and the ways in which that nationality is lost are defined. So British subjects voluntarily naturalized in a foreign state are deemed aliens from the time of such naturalization, unless, in the case of persons naturalized before the passing of the act, they have declared their desire to remain British subjects within two years from the passing of the act. Persons who from having been born within British territory are British subjects, but who at birth became under the law of any foreign state subjects of such state, and also persons who though born abroad are British subjects by reason of parentage, may by declarations of alienage get rid of British nationality. Emigration to an uncivilized country leaves British nationality unaffected: indeed the right claimed by all states to follow with their authority their subjects so emigrating is one of the usual and recognized means of colonial expansion.
United States.
The doctrine that no man can cast off his native allegiance without the consent of his sovereign was early abandoned in the United States, and Chief Justice John Rutledge also declared in Talbot v. Janson, "a man may, at the same time, enjoy the rights of citizenship under two governments." On July 27, 1868, the day before the Fourteenth Amendment was adopted, U.S. Congress declared in the preamble of the Expatriation Act that "the right of expatriation is a natural and inherent right of all people, indispensable to the enjoyment of the rights of life, liberty and the pursuit of happiness," and (Section I) one of "the fundamental principles of this government" (United States Revised Statutes, sec. 1999). Every natural-born citizen of a foreign state who is also an American citizen and every natural-born American citizen who is a citizen of a foreign land owes a double allegiance, one to the United States, and one to his homeland (in the event of an immigrant becoming a citizen of the US), or to his adopted land (in the event of an emigrant natural born citizen of the US becoming a citizen of another nation). If these allegiances come into conflict, he or she may be guilty of treason against one or both. If the demands of these two sovereigns upon his duty of allegiance come into conflict, those of the United States have the paramount authority in American law; likewise, those of the foreign land have paramount authority in their legal system. In such a situation, it may be incumbent on the individual to renounce one of his citizenships to avoid possibly being forced into situations where countervailing duties are required of him, such as might occur in the event of war.
Oath of allegiance.
The oath of allegiance is an oath of fidelity to the sovereign taken by all persons holding important public office and as a condition of naturalization. By ancient common law it might be required of all persons above the age of 12, and it was repeatedly used as a test for the disaffected. In England it was first imposed by statute in the reign of Elizabeth I of England (1558) and its form has more than once been altered since. Up to the time of the revolution the promise was, "to be true and faithful to the king and his heirs, and truth and faith to bear of life and limb and terrene honour, and not to know or hear of any ill or damage intended him without defending him therefrom." This was thought to favour the doctrine of absolute non-resistance, and accordingly the convention parliament enacted the form that has been in use since that time – "I do sincerely promise and swear that I will be faithful and bear true allegiance to His Majesty ..."
In Islam.
The word used in the Arabic language for allegiance is "bay'at" (Arabic: بيعة), which means "taking hand". The practice is sanctioned in the Qur'an by Surah 48:10: "Verily, those who give thee their allegiance, they give it but to Allah Himself". The word is used for the oath of allegiance to an emir. It is also used for the initiation ceremony specific to many Sufi orders.

</doc>
<doc id="885" url="http://it.wikipedia.org/wiki/?curid=885" title="Altenberg">
Altenberg

See also.
__NOTOC__

</doc>
<doc id="887" url="http://it.wikipedia.org/wiki/?curid=887" title="MessagePad">
MessagePad

The MessagePad is the first series of personal digital assistant devices developed by Apple for the Newton platform in 1993. Some electronic engineering and the manufacture of Apple's MessagePad devices was undertaken in Japan by the Sharp Corporation. The devices were based on the ARM 610 RISC processor and all featured handwriting recognition software and were developed and marketed by Apple. The devices ran the Newton OS.
Details.
Screen and input.
With the MessagePad 120 with Newton OS 2.0, the Newton Keyboard by Apple became available, which can also be used via the dongle on Newton devices with a Newton InterConnect port, most notably the Apple MessagePad 2000/2100 series, as well as the Apple eMate 300.
Newton devices featuring Newton OS 2.1 or higher can be used with the screen turned horizontally ("landscape") as well as vertically ("portrait"). A change of a setting rotates the contents of the display by 90, 180 or 270 degrees. Handwriting recognition still works properly with the display rotated, although display calibration is needed when rotation in any direction is used for the first time or when the Newton device is reset.
Handwriting recognition.
In initial versions (Newton OS 1.x) the handwriting recognition gave extremely mixed results for users and was sometimes inaccurate. The original handwriting recognition engine was called Calligrapher, and was licensed from a Russian company called Paragraph International. Calligrapher's design was quite sophisticated; it attempted to learn the user's natural handwriting, using a database of known words to make guesses as to what the user was writing, and could interpret writing anywhere on the screen, whether hand-printed, in cursive, or a mix of the two. By contrast, Palm Pilot's Graffiti had a less sophisticated design than Calligrapher, but was sometimes found to be more accurate and precise due to its reliance on a fixed, predefined stroke alphabet. The stroke alphabet used letter shapes which resembled standard handwriting, but which were modified to be both simple and very easy to differentiate. Palm Computing also released two versions of Graffiti for Newton devices. Ironically, the Newton version sometimes performed better and could also show strokes as they were being written as input was done on the display itself, rather than on a silkscreen area.
For editing text, Newton had a very intuitive system for handwritten editing, such as scratching out words to be deleted, circling text to be selected, or using written carets to mark inserts.
Later releases of the Newton operating system retained the original recognizer for compatibility, but added a hand-printed-text-only (not cursive) recognizer, called "Rosetta", which was developed by Apple, included in version 2.0 of the Newton operating system, and refined in Newton 2.1. Rosetta is generally considered a significant improvement and many reviewers, testers, and most users consider the Newton 2.1 handwriting recognition software better than any of the alternatives even 10 years after it was introduced. Recognition and computation of handwritten horizontal and vertical formulas such as "1 + 2 =" was also under development but never released. However, users wrote similar programs which could evaluate mathematical formulas using the Newton OS Intelligent Assistant, a unique part of every Newton device.
The handwriting recognition and parts of the user interface for the Newton are best understood in the context of the broad history of Pen computing, which is quite extensive.
A vital feature of the Newton handwriting recognition system is the modeless error correction. That is, correction done in situ without using a separate window or widget, using a minimum of gestures. If a word is recognized improperly, the user could double-tap the word and a list of alternatives would pop up in a menu under the stylus. Most of the time, the correct word will be in the list. If not, a button at the bottom of the list allows the user to edit individual characters in that word. Other pen gestures could do such things as transpose letters (also in situ). The correction popup also allowed the user to revert to the original, un-recognized letter shapes - this would be useful in note-taking scenarios if there was insufficient time to make corrections immediately. To conserve memory and storage space, alternative recognition hypotheses would not be saved indefinitely. If the user returned to a note a week later, for example, they would only see the best match. Error correction in many current handwriting systems provides such functionality but adds more steps to the process, greatly increasing the interruption to a user's workflow that a given correction requires.
User interface.
Text could also be entered by tapping with the stylus on a small on-screen pop-up QWERTY virtual keyboard, although more layouts were developed by users. Newton devices could also accept free-hand "Sketches", "Shapes", and "Ink Text", much like a desktop computer graphics tablet. With "Shapes", Newton could recognize that the user was attempting to draw a circle, a line, a polygon, etc., and it would clean them up into perfect vector representations (with modifiable control points and defined vertices) of what the user was attempting to draw. "Shapes" and "Sketches" could be scaled or deformed once drawn. "Ink text" captured the user's free-hand writing but allowed it to be treated somewhat like recognized text when manipulating for later editing purposes ("ink text" supported word wrap, could be formatted to be bold, italic, etc.). At any time a user could also direct their Newton device to recognize selected "ink text" and turn it into recognized text (deferred recognition). A Newton note (or the notes attached to each contact in Names and each Dates calendar or to-do event) could contain any mix of interleaved text, Ink Text, Shapes, and Sketches.
Connectivity.
The MessagePad 100 series of devices used Macintosh's proprietary serial ports—round Mini-DIN 8 connectors. The MessagePad 2000/2100 models (as well as the eMate 300) have a small, proprietary "Newton InterConnect" port. However, the development of the Newton hardware/software platform was canceled by Steve Jobs on February 27, 1998, so the InterConnect port, while itself very advanced, can only be used to connect a serial dongle. A prototype multi-purpose InterConnect device containing serial, audio in, audio out, and other ports was also discovered. In addition, all Newton devices have infrared connectivity, initially only the Sharp ASK protocol, but later also IrDA, though the Sharp ASK protocol was kept in for compatibility reasons. Unlike the Palm Pilot, all Newton devices are equipped with a standard PC Card expansion slot (two on the 2000/2100). This allows native modem and even Ethernet connectivity; Newton users have also written drivers for 802.11b wireless networking cards and ATA-type flash memory cards (including the popular CompactFlash format), as well as for Bluetooth cards. Newton can also dial a phone number through the built-in speaker of the Newton device by simply holding a telephone handset up to the speaker and transmitting the appropriate tones. Fax and printing support is also built in at the operating system level, although it requires peripherals such as parallel adapters, PCMCIA cards, or serial modems, the most notable of which is the lightweight Newton Fax Modem released by Apple in 1993. It is powered by 2 AA batteries, and can also be used with a power adapter. It provides data transfer at 2400 bit/s, and can also send and receive fax messages at 9600 and 4800 bit/s respectively.
Power options.
The original Apple MessagePad and MessagePad 100 used four AAA batteries. They were eventually replaced by AA batteries with the release of the Apple MessagePad 110.
The use of 4 AA NiCd (MessagePad 110, 120 and 130) and 4x AA NiMH cells (MP2x00 series, eMate 300) give a runtime of up to 30 hours (MP2100 with two 20 MB Linear Flash memory PC Cards, no backlight usage) and up to 24 hours with backlight on. While adding more weight to the handheld Newton devices than AAA batteries or custom battery packs, the choice of an easily replaceable/rechargeable cell format gives the user a still unsurpassed runtime and flexibility of power supply. This, together with the flash memory used as internal storage starting with the Apple MessagePad 120 (if all cells lost their power, no data was lost due to the non-volatility of this storage), gave birth to the slogan "Newton never dies, it only gets new batteries".
Later efforts and improvements.
The Apple MessagePad 2000/2100, with a vastly improved handwriting recognition system, 162 MHz StrongARM SA-110 RISC processor, Newton OS 2.1, and a better, clearer, backlit screen, attracted critical plaudits. 
Cases.
Apple and third parties marketed several "wallets" (cases) for the handheld Newton devices, which would hold them securely along with the owner's credit cards, driver's license, business cards, and cash. Most also protected the LCD screen. 
Market reception.
The original Apple MessagePad and MessagePad 100 were limited by the very short lifetime of their inadequate AAA batteries.
Critics also panned the handwriting recognition that was available in the debut models, which had been trumpeted in the Newton's marketing campaign. It was this problem that was skewered in the Doonesbury comic strips and the animated television series The Simpsons. Not even the word 'freckles' was in the dictionary, though the user could add it themselves. Difficulties were in part caused by the long time requirements for the Calligrapher handwriting recognition software to "learn" the user's handwriting; this process could take anywhere from two weeks to two months.
Another factor which limited the early Newton devices' appeal was that desktop connectivity was not included in the basic retail package, a problem that was later solved with 2.x Newton devices - these were bundled with a serial cable and the appropriate Newton Connection Utilities software.
Later versions of Newton OS offered improved handwriting recognition, quite possibly a leading reason for the continued popularity of the devices among Newton users. Even given the age of the hardware and software, Newtons still demand a sale price on the used market far greater than that of comparatively aged PDAs produced by other companies. In 2006 CNET compared an Apple MessagePad 2000 to a Samsung Q1, and the Newton was declared better. In 2009, CNET compared an Apple MessagePad 2000 to an iPhone, and the Newton was still declared better.
A chain of dedicated Newton only stores called Newton Source existed from 1994 through 1998. Locations included NYC, Los Angeles, San Francisco, Chicago and Boston. The Westwood Village, California, near U.C.L.A. featured the trademark red and yellow lightbulb Newton logo in neon. The stores provided an informative educational venue to learn about the Newton platform in a hands on relaxed fashion. The stores had no traditional computer retail counters and featured oval desktops where interested users could become intimately involved with the New ton product range. The stores were a model for the later Apple Stores. 
Newton device models.
If one removes all patches to the eMate 300 (by replacing the ROM chip, and then putting in the original one again, as the eMate and the MessagePad 2000/2100 devices erase their memory completely after replacing the chip), the result will be the Newton OS saying that this is version 2.2.00. Also, the Original MessagePad and the MessagePad 100 share the same model number, as they only differ in the ROM chip version. (The OMP has OS versions 1.0 to 1.05, or 1.10 to 1.11, while the MP100 has 1.3 that can be upgraded with various patches.)
Other uses.
There were a number of projects that used the Newton as a portable information device in cultural settings such as museums. For example, Visible Interactive created a walking tour in San Francisco's Chinatown but the most significant effort took place in Malaysia at the Petronas Discovery Center, known as Petrosains.
In 1995, an exhibit design firm, DMCD Inc., was awarded the contract to design a new science museum in the Petronas Towers in Kuala Lumpur. A major factor in the award was the concept that visitors would use a Newton device to access additional information, find out where they were in the museum, listen to audio, see animations, control robots and other media, and to bookmark information for printout at the end of the exhibit.
The device became known as the ARIF, a Malay word for "wise man" or "seer" and it was also an acronym for A Resourceful Informative Friend. Some 400 ARIFS were installed and over 300 are still in use today. The development of the ARIF system was extremely complex and required a team of hardware and software engineers, designers, and writers. ARIF is an ancestor of the PDA systems used in museums today and it boasted features that have not been attempted since.

</doc>
<doc id="888" url="http://it.wikipedia.org/wiki/?curid=888" title="A. E. van Vogt">
A. E. van Vogt

Alfred Elton van Vogt (April 26, 1912 – January 26, 2000) was a Canadian-born science fiction author regarded as one of the most popular and complex science fiction writers of the mid-twentieth century: the "Golden Age" of the genre.
Early life and writings.
After starting his writing career by writing for "true confession" style pulp magazines like "True Story", van Vogt decided to switch to writing something he enjoyed, science fiction.
Van Vogt's first published SF story, "Black Destroyer" ("Astounding Science Fiction", July 1939), was inspired by "Voyage of the Beagle" by Charles Darwin. The story depicted a fierce, carnivorous alien, the coeurl, stalking the crew of an exploration spaceship. It was the cover story of the issue of "Astounding" that is sometimes described as having ushered in the "Golden Age" of science fiction. The story served as the inspiration for a number of science fiction movies. In 1950, "Black Destroyer" was combined with "War of Nerves" (1950), "Discord in Scarlet" (1939) and "M33 in Andromeda" (1943) to form the novel "The Voyage of the Space Beagle" (1950). Positing the need for exobiologists who will appreciate the differences between the inhabitants of other planets and ourselves, it stresses the importance of the non-military in the exploration of other cultures.
In 1941, van Vogt decided to become a full-time writer, quitting his job at the Canadian Department of National Defence. Extremely prolific for a few years, van Vogt wrote a large number of short stories. In the 1950s, many of them were retrospectively patched together into novels, or "fixups" as he called them, a term which entered the vocabulary of science fiction criticism. When the original stories were related (e.g., "The War against the Rull") this was often successful. When not (e.g., "Quest for the Future") the disparate stories thrown together generally made for a less coherent plot.
One of van Vogt's best-known novels of this period is "Slan", which was originally serialised in "Astounding Science Fiction" (September - December 1940). Using what became one of van Vogt's recurring themes, it told the story of a 9-year-old superman living in a world in which his kind are slain by "Homo sapiens".
Post-war philosophy.
In 1944, van Vogt moved to Hollywood, California, where his writing took on new dimensions after World War II. Van Vogt was always interested in the idea of all-encompassing systems of knowledge (akin to modern meta-systems) -- the characters in his very first story used a system called 'Nexialism' to analyze the alien's behaviour, and he became interested in the General Semantics of Alfred Korzybski.
He subsequently wrote three novels merging these overarching themes, "The World of Null-A" and "The Pawns of Null-A" in the late 1940s, and "Null-A Three" in the early 1980s. "Null-A", or non-Aristotelian logic, refers to the capacity for, and practice of, using intuitive, inductive reasoning (compare fuzzy logic), rather than reflexive, or conditioned, deductive reasoning.
Van Vogt was also profoundly affected by revelations of totalitarian police states that emerged after World War II. He wrote a mainstream novel that was set in Communist China, "The Violent Man" (1962); he said that to research this book he had read 100 books about China. Into this book he incorporated his view of "the violent male type," which he described as a "man who had to be right," a man who "instantly attracts women" and who he said were the men who "run the world". This was the case, for instance, in the "Weapon Shop" series, the "Mixed Men" series, and in single stories such as "Heir Apparent" (1945), whose protagonist was described as a "benevolent dictator."
Van Vogt systematized his writing method, using scenes of 800 words or so where a new complication was added or something resolved. Several of his stories hinge upon temporal conundra, a favorite theme. He stated that he acquired many of his writing techniques from three books: "Narrative Technique"" by Thomas Uzzell, ""The Only Two Ways to Write a Story"," and ""Twenty Problems of the Short-Story Writer"," these last two by John Gallishaw.
He also claimed many of his ideas came from dreams; throughout his writing life he arranged to be awakened every 90 minutes during his sleep period so he could write down his dreams.
In "The John W. Campbell Letters", Campbell says, "The son-of-a-gun gets hold of you in the first paragraph, ties a knot around you, and keeps it tied in every paragraph thereafter—including the ultimate last one."
Harlan Ellison (who began reading van Vogt as a teenager) wrote, "Van was the first writer to shine light on the restricted ways in which I had been taught to view the universe and the human condition."
Recognition.
In 1946, van Vogt and his first wife, Edna Mayne Hull, were co-Guests of Honor at the fourth World Science Fiction Convention.
It is generally held that the “damnable SFWA politics” relates to Damon Knight, the founder of the SFWA, who abhorred van Vogt’s style and politics and thoroughly demolished his literary reputation in the 1950s.
Harlan Ellison writing in 1999 the introduction
Notable quotes.
Concerning Theodore Sturgeon's death, van Vogt commented: 

</doc>
<doc id="890" url="http://it.wikipedia.org/wiki/?curid=890" title="Anna Kournikova">
Anna Kournikova

Anna Sergeyevna Kournikova (; born 7 June 1981) is a Russian American retired professional tennis player. Her appearance and celebrity status made her one of the best known tennis stars worldwide, despite her never winning a WTA singles title. At the peak of her fame, fans looking for images of Kournikova made her name one of the most common search strings on Google Search.
Although reaching No. 8 in the world in 2000, she never won a WTA Title in singles. Kournikova achieved greater success playing doubles, where she had at times been the World No. 1 player. With Martina Hingis as her partner, she won Grand Slam titles in Australia in 1999 and 2002. The doubles team referred to themselves as the "Spice Girls of Tennis".
Kournikova's professional tennis career ended prematurely at the age of 21 due to serious back and spinal problems, including a herniated disk. She lives in Miami Beach, Florida,
Early life.
Anna Kournikova was born in Moscow, Soviet Union, on 7 June 1981. Her father, Sergei Kournikov (born 1961), was 19 at the time. Sergei, a former Greco-Roman wrestling champion, had earned a PhD and was a professor at the University of Physical Culture and Sport in Moscow. As of 2001, he was still a part-time martial arts instructor there. Her mother Alla (born 1962), who was 18 when Kournikova was born, had been a 400-meter runner. In 1989, at the age of eight, Kournikova began appearing in junior tournaments, and by the following year, was attracting attention from tennis scouts across the world. Kournikova signed a management deal at age ten and went to Bradenton, Florida, to train at Nick Bollettieri's celebrated tennis academy. She debuted in professional tennis at 14 in the Fed Cup for Russia, the youngest player ever to participate and win. where she lost in the first round to World No. 12 Amanda Coetzer. At the Italian Open, Kournikova lost to Amanda Coetzer in the second round. However, she reached the semifinals in the doubles partnering with Elena Likhovtseva, before losing to the sixth seeds Mary Joe Fernández and Patricia Tarabini.
1998–2000: Success and stardom.
In 1998, Kournikova broke into the WTA's top 20 rankings for the first time, when she was ranked No. 16. At the 1998 Australian Open, Kournikova lost in the third round to World No. 1 player Martina Hingis. She also partnered with Larisa Neiland in women's doubles, and they lost to eventual champions Hingis and Mirjana Lučić in the second round. The Race raised funds for children's Hospital Los Angeles. She won that race for women's K-Swiss team. Kournikova and Wilkison defeated Jimmy Arias and Chanda Rubin, and then Kournikova and Novacek defeated Rubin and Wilkison. She played doubles with Andy Roddick (they were coached by David Chang) versus Martina Navratilova and Jesse Levine (coached by Billie Jean King); Kournikova and Roddick won. The exhibition included a mixed doubles match of McEnroe and Austin against Courier and Kournikova.
In 2008, she was named a spokesperson for K-Swiss. In 2005, Kournikova stated that if she were 100% fit, she would like to come back and compete again.
In June 2010, Kournikova reunited with her doubles partner Martina Hingis to participate in competitive tennis for the first time in seven years in the Invitational Ladies Doubles event at Wimbledon. On 29 June 2010 they defeated the British pair Samantha Smith and Anne Hobbs.
Playing style.
As a player, Kournikova was noted for her footspeed and aggressive baseline play, and excellent angles and dropshots; however, her relatively flat, high-risk groundstrokes tended to produce frequent errors, and her serve was sometimes unreliable in singles.
Kournikova plays right-handed with a two-handed backhand. She can hit forceful groundstrokes and also drop shots.
Her playing style fits the profile for a doubles player, and is complemented by her height. She has been compared to such doubles specialists as Pam Shriver and Peter Fleming. Bure and Kournikova were reported to have been engaged in 2000 after a reporter took a photo of them together in a Florida restaurant where Bure supposedly asked Kournikova to marry him. As the story made headlines in Russia, where they were both heavily followed in the media as celebrities, Bure and Kournikova both denied any engagement. Kournikova, 10 years younger than Bure, was 18 years old at the time. The following year, Kournikova and Fedorov were married in Moscow. Kournikova's representatives deny any marriage to Fedorov; however, Fedorov's agent Pat Brisson claims that although he does not know when they got married, he knew "Fedorov was married".
Kournikova started dating pop star Enrique Iglesias in late 2001 (she appeared in his video, "Escape"), and rumors that the couple had secretly married circulated in 2003 and again in 2005. Kournikova herself has consistently refused to directly confirm or deny the status of her personal relationships. In May 2007, Iglesias was quoted in the "New York Sun" that he had no intention of marrying Kournikova and settling down because they had split up. The singer later denied the quote. In June 2008, Iglesias was quoted by the "Daily Star" as having married Kournikova the previous year and subsequently separated. In an interview with Graham Norton in 2010, Kournikova confirmed that she and Iglesias have been together for over eight years but have no plans to marry in the near future. The couple have invested in a $20 million home to be built on a private island in Miami.
Kournikova resides in Miami Beach, Florida.
Media publicity.
Most of Kournikova's fame has come from the publicity surrounding her looks and her personal life. During Kournikova's debut at the 1996 US Open at the age of 15, the world noticed her beauty, and soon pictures of her appeared in numerous magazines worldwide.
In 2000, Kournikova became the new face for Berlei's shock absorber sports bras, and appeared in the "only the ball should bounce" billboard campaign. Following that, she was cast by the Farrelly brothers for a minor role in the 2000 film "Me, Myself  Irene" starring Jim Carrey and Renée Zellweger. Photographs of her scantily clad form have appeared in various men's magazines, including one in the much-publicized 2004 "Sports Illustrated Swimsuit Issue", where she posed in bikinis and swimsuits, and in other men's publications such as "FHM" and "Maxim". Kournikova was named one of "People's" 50 Most Beautiful People in 1998 and was voted "hottest female athlete" on ESPN.com. In 2002 she also placed first in "FHM's 100 Sexiest Women in the World" in US and UK editions. Kournikova was also ranked No. 1 in the ESPN Classic series "Who's number 1?" when the series featured sport's most overrated athletes.
She continued to be the most searched athlete on the Internet through 2008 even though she had retired from the professional tennis circuit years earlier. After slipping from first to sixth among athletes in 2009, she moved back up to third place among athletes in terms of search popularity in 2010. 
In October 2010, Kournikova headed to NBC's "The Biggest Loser" where she led the contestants in a tennis-workout challenge. In May 2011, it was announced that Kournikova would join "The Biggest Loser" as a regular celebrity trainer in season 12. She did not return for season 13.
In November 2010, she became an American citizen. In 2011, "Men's Health" named her one of the "100 Hottest Women of All-Time", ranking her at No. 29.
Influences on popular culture.
A variation of a White Russian made with skim milk is known as an Anna Kournikova. In the lingo of the poker variation Texas Hold 'em, the hole cards Ace–King (unsuited) are sometimes referred to as an "Anna Kournikova", a term introduced by the poker commentator Vince van Patten during a WPT tournament because it "looks great but never wins". A computer virus named the Anna Kournikova virus arose on 12 February 2001.

</doc>
<doc id="892" url="http://it.wikipedia.org/wiki/?curid=892" title="Alfons Maria Jakob">
Alfons Maria Jakob

Alfons Maria Jakob (2 July 1884, Aschaffenburg/Bavaria–17 October 1931, Hamburg) was a German neurologist with important contributions on neuropathology.
Alfons Maria Jakob was the son of a shopkeeper. He studied medicine in Munich, Berlin, and Strasbourg, where obtained his doctorate in 1908. In 1909 he commenced clinical work under the psychiatrist Emil Kraepelin and did laboratory work with Franz Nissl and Alois Alzheimer in Munich.
In 1911 he went to Hamburg to work with Theodor Kaes and became head of the laboratory of anatomical pathology at the psychiatric State Hospital Hamburg-Friedrichsberg. Following the death of Kaes in 1913, Jakob succeeded him as prosector. After serving in the German army in World War I, he returned to Hamburg and climbed the academic ladder. He was habilitated in neurology in 1919 and in 1924 became professor of neurology. Under Jakob's guidance the department grew rapidly. He made notable contributions to knowledge on concussion and secondary nerve degeneration and became a doyen of neuropathology.
Jakob published five monographs and more than 75 papers. His neuropathological studies contributed greatly to the delineation of several diseases, including multiple sclerosis and Friedreich's ataxia. He first recognised and described Alper's disease and Creutzfeldt-Jakob disease (the latter with Hans Gerhard Creutzfeldt). He accumulated immense experience in neurosyphilis, having a 200-bedded ward devoted exclusively to that disorder. Jakob made a lecture tour of the United States and South America where he wrote a paper on the neuropathology of yellow fever.
He suffered from chronic osteomyelitis for the last 7 years of his life. This eventually caused a retroperitoneal abscess and paralytic ileus from which he died following operation.

</doc>
<doc id="894" url="http://it.wikipedia.org/wiki/?curid=894" title="Agnosticism">
Agnosticism

Agnosticism is the view that the existence or non-existence of any deity is unknown and possibly unknowable. More specifically, agnosticism is the view that the truth values of certain claims—especially claims about the existence or non-existence of any deity, as well as other religious and metaphysical claims—are unknown and (so far as can be judged) unknowable.
Agnosticism can be defined in various ways, and is sometimes used to indicate doubt or a skeptical approach to questions. In some senses, agnosticism is a stance about the difference between belief and knowledge, rather than about any specific claim or belief. In the popular sense, an agnostic is someone who neither believes nor disbelieves in the existence of a deity or deities, whereas a theist and an atheist believe and disbelieve, respectively.
However, earlier thinkers and written works have promoted agnostic points of view. They include Protagoras, a 5th-century BCE Greek philosopher, Sanjaya Belatthaputta, a 5th-century BCE Indian philosopher, and the Nasadiya Sukta concerning the origin of the universe in the Rig Veda, an ancient Sanskrit text, which is one of the primary scriptures of Vedic Hinduism.
Since Huxley coined the term, many other thinkers have written extensively about agnosticism.
Defining agnosticism.
Agnosticism often overlaps with other belief systems. Agnostic theists identify themselves both as agnostics and as followers of particular religions, viewing agnosticism as a framework for thinking about the nature of belief and their relation to revealed truths. Some nonreligious people, such as author Philip Pullman, identify as both agnostic and atheist. In contrast, the philosopher William L. Rowe said that in the popular sense, an agnostic is someone who neither believes nor disbelieves in the existence of a deity or deities, whereas a theist and an atheist believe and disbelieve, respectively, and that in the strict sense agnosticism is the view that human reason is incapable of rationally justifying the belief that deities do, or do not, exist.
Etymology.
"Agnostic" () was used by Thomas Henry Huxley in a speech at a meeting of the Metaphysical Society in 1869
to describe his philosophy which rejects all claims of spiritual or mystical knowledge. Early Christian church leaders used the Greek word "gnosis" (knowledge) to describe "spiritual knowledge." Agnosticism is not to be confused with religious views opposing the ancient religious movement of Gnosticism in particular; Huxley used the term in a broader, more abstract sense.
Huxley identified agnosticism not as a creed but rather as a method of skeptical, evidence-based inquiry.
In recent years, scientific literature dealing with neuroscience and psychology has used the word to mean "not knowable".
In technical and marketing literature, "agnostic" often has a meaning close to "independent"—for example, "platform agnostic" or "hardware agnostic."
Qualifying agnosticism.
Scottish Enlightenment philosopher David Hume contended that meaningful statements about the universe are always qualified by some degree of doubt.
He asserted that the fallibility of human beings means that they cannot obtain absolute certainty except in trivial cases where a statement is true by definition (i.e. tautologies such as "all bachelors are unmarried" or "all triangles have three corners"). All rational statements that assert a factual claim about the universe that begin "I believe that ..." are simply shorthand for, "Based on my knowledge, understanding, and interpretation of the prevailing evidence, I tentatively believe that..." For instance, when one says, "I believe that Lee Harvey Oswald shot John F. Kennedy," one is not asserting an absolute truth but a tentative belief based on interpretation of the assembled evidence. Even though one may set an alarm clock prior to the following day, believing that waking up will be possible, that belief is tentative, tempered by a small but finite degree of doubt (the clock or its alarm mechanism might break, or one might die before the alarm goes off).
History.
Since Huxley first used the term, several writers have defended agnosticism as a philosophical viewpoint. A number of earlier thinkers and writings have also explored agnostic thought.
In Hindu philosophy.
Throughout the history of Hinduism there has been a strong tradition of philosophic speculation and skepticism.
In Greek philosophy.
Agnostic thought, in the form of skepticism, emerged as a formal philosophical position in ancient Greece. Its proponents included Protagoras, Pyrrho, Carneades, Sextus Empiricus and, to some degree, Socrates, who was a strong advocate for a skeptical approach to epistemology.
Such thinkers rejected the idea that certainty was possible.
Hume, Kant, and Kierkegaard.
Many philosophers (following the examples of Aristotle, Anselm, Aquinas, and Descartes) presented arguments attempting to rationally prove the existence of God. The skeptical empiricism of David Hume, the antinomies of Immanuel Kant, and the existential philosophy of Søren Kierkegaard convinced many later philosophers to abandon these attempts, regarding it impossible to construct any unassailable proof for the existence or non-existence of God.
Thomas Henry Huxley.
Huxley's agnosticism is believed to be a natural consequence of the intellectual and philosophical conditions of the 1860s, when clerical intolerance was trying to suppress scientific discoveries which appeared to clash with a literal reading of the Book of Genesis and other established Jewish and Christian doctrines. Agnosticism should not, however, be confused with natural theology, deism, pantheism, or other forms of theism.
By way of clarification, Huxley states, "In matters of the intellect, follow your reason as far as it will take you, without regard to any other consideration. And negatively: In matters of the intellect, do not pretend that conclusions are certain which are not demonstrated or demonstrable" (Huxley, "Agnosticism", 1889). Although A. W. Momerie has noted that this is nothing but a definition of honesty, Huxley's usual definition goes beyond mere honesty to insist that these metaphysical issues are fundamentally unknowable.
William Stewart Ross.
William Stewart Ross wrote under the name of Saladin. He championed agnosticism in opposition to the atheism of Charles Bradlaugh as an open-ended spiritual exploration. In "Why I am an Agnostic" (c.1889) he claims that agnosticism is "the very reverse of atheism".
Robert G. Ingersoll.
Robert G. Ingersoll, an Illinois lawyer and politician who evolved into a well-known and sought-after orator in 19th century America, has been referred to as the "Great Agnostic."
Bertrand Russell.
Bertrand Russell's pamphlet, "Why I Am Not a Christian", based on a speech delivered in 1927 and later included in a book of the same title, is considered a classic statement of agnosticism. The essay briefly lays out Russell’s objections to some of the arguments for the existence of God before discussing his moral objections to Christian teachings. He then calls upon his readers to "stand on their own two feet and look fair and square at the world," with a "fearless attitude and a free intelligence."
Demographics.
Demographic research services normally do not differentiate between various types of non-religious respondents, so agnostics are often classified in the same category as atheists or other non-religious people.
Some sources use "agnostic" in the sense of "noncommittal".
A study conducted by the Pew Research Center found that about 16% of the world's people, the third largest group after Christianity and Islam, have no religious affiliation.
In the "U.S. Religious Landscape Survey", conducted by the Pew Research Center, 55% of agnostic respondents expressed "a belief in God or a universal spirit."
41%, however, stated that they thought that they felt a tension "being non-religious in a society where most people are religious."
Criticism.
Agnosticism is criticized from a variety of standpoints. Some religious thinkers see agnosticism as a limitation of the mind's capacity to know reality other than materialism. Some atheists criticize the use of the term "agnosticism" as functionally indistinguishable from atheism. This line of criticism results in frequent criticisms of those who adopt the term as a means of atheism label avoidance.
Religious.
Many theistic thinkers repudiate the validity of agnosticism, or certain forms of agnosticism. Religious scholars in the three Abrahamic religions affirm the possibility of knowledge, even of metaphysical realities such as God and the soul,
because human intelligence, they assert, has a non-material, spiritual element. They affirm that “not being able to see or hold some specific thing does not necessarily negate its existence,” as in the case of gravity, entropy, or reason and thought.
Religious scholars, such as Brown, Tacelli, and Kreeft, argue that agnosticism does not take into account the numerous evidence of his existence that God has placed in his creation.
And for this, Peter Kreeft and Ronald Tacelli cite 20 arguments for God’s existence.
They assert that agnosticism's demand for scientific evidence through laboratory testing is in effect asking God, the supreme being, to become man’s servant.
They argue that the question of God should be treated differently from other knowable objects in that "this question regards not that which is below us, but that which is above us."
"Agnosticism", said Ratzinger, "is always the fruit of a refusal of that knowledge which is in fact offered to man [...] The knowledge of God has always existed."
These scholars believe that each day in a person’s life is an unavoidable step towards death, and thus not to decide for or against God, whom they view as the all-encompassing foundation, , and meaning of life, is to decide in favor of atheism.
The Catholic Church sees merit in examining what it calls Partial Agnosticism, specifically those systems that "do not aim at constructing a complete philosophy of the Unknowable, but at excluding special kinds of truth, notably religious, from the domain of knowledge."
However, the Church is historically opposed to a full denial of the ability of human reason to know God. The Council of the Vatican, relying on biblical scripture, declares that "God, the beginning and end of all, can, by the natural light of human reason, be known with certainty from the works of creation" (Const. De Fide, II, De Rev.)
Atheist.
According to Richard Dawkins, a distinction between agnosticism and atheism is unwieldy and depends on how close to zero we are willing to rate the probability of existence for any given god-like entity. Since in practice it is not worth contrasting a zero probability with one that is nearly indistinguishable from zero, he prefers to categorize himself as a "de facto atheist". He specifies his position by means of a scale of 1 to 7. On this scale, 1 indicates "100 per cent probability of God." A person ranking at 7 on the scale would be a person who says "I know there is no God..." Dawkins places himself at 6 on the scale, which he characterizes as "I cannot know for certain but I think God is very improbable, and I live my life on the assumption that he is not there", but leaning toward 7. About himself, Dawkins continues that "I am agnostic only to the extent that I am agnostic about fairies at the bottom of the garden."
Dawkins also identifies two categories of agnostics; "Temporary Agnostics in Practice" (TAPs), and "Permanent Agnostics in Principle" (PAPs). Dawkins considers temporary agnosticism an entirely reasonable position, but views permanent agnosticism as "fence-sitting, intellectual cowardice."
Related concepts.
Ignosticism is the view that a coherent definition of a deity must be put forward before the question of the existence of a deity can be meaningfully discussed. If the chosen definition is not coherent, the ignostic holds the noncognitivist view that the existence of a deity is meaningless or empirically untestable. A.J. Ayer, Theodore Drange, and other philosophers see both atheism and agnosticism as incompatible with ignosticism on the grounds that atheism and agnosticism accept "a deity exists" as a meaningful proposition which can be argued for or against.

</doc>
<doc id="896" url="http://it.wikipedia.org/wiki/?curid=896" title="Argon">
Argon

Argon is a chemical element with symbol Ar and atomic number 18. It is in group 18 (noble gases) of the periodic table. Argon is the third most common gas in the Earth's atmosphere, at 0.93% (9,300 ppm), making it approximately 23.8 times as abundant as next most common atmospheric gas, carbon dioxide (390 ppm), and more than 500 times as abundant as the next most common noble gas, neon (18 ppm). Nearly all of this argon is radiogenic argon-40 derived from the decay of potassium-40 in the Earth's crust. In the universe, argon-36 is by far the most common argon isotope, being the preferred argon isotope produced by stellar nucleosynthesis in supernovas.
The name "argon" is derived from the Greek word αργον meaning "lazy" or "the inactive one", a reference to the fact that the element undergoes almost no chemical reactions. The complete octet (eight electrons) in the outer atomic shell makes argon stable and resistant to bonding with other elements. Its triple point temperature of 83.8058 K is a defining fixed point in the International Temperature Scale of 1990.
Argon is produced industrially by the fractional distillation of liquid air. Argon is mostly used as an inert shielding gas in welding and other high-temperature industrial processes where ordinarily non-reactive substances become reactive; for example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning. Argon gas also has uses in incandescent and fluorescent lighting, and other types of gas discharge tubes. Argon makes a distinctive blue-green gas laser.
Characteristics.
Argon has approximately the same solubility in water as oxygen and is 2.5 times more soluble in water than nitrogen. Argon is colorless, odorless, and nontoxic as a solid, liquid, and gas. Argon is chemically inert under most conditions and forms no confirmed stable compounds at room temperature.
Although argon is a noble gas, it has been found to have the capability of forming some compounds. For example, the creation of argon fluorohydride (HArF), a marginally stable compound of argon with fluorine and hydrogen, was reported by researchers at the University of Helsinki in 2000. Although the neutral ground-state chemical compounds of argon are presently limited to HArF, argon can form clathrates with water when atoms of it are trapped in a lattice of the water molecules. Argon-containing ions and excited state complexes, such as and ArF, respectively, are known to exist. Theoretical calculations have predicted several argon compounds that should be stable, but for which no synthesis routes are currently known.
History.
"Argon" (αργος, Greek meaning "inactive", in reference to its chemical inactivity) was suspected to be present in air by Henry Cavendish in 1785 but was not isolated until 1894 by Lord Rayleigh and Sir William Ramsay in Scotland in an experiment in which they removed all of the oxygen, carbon dioxide, water and nitrogen from a sample of clean air. They had determined that nitrogen produced from chemical compounds was one-half percent lighter than nitrogen from the atmosphere. The difference seemed insignificant, but it was important enough to attract their attention for many months. They concluded that there was another gas in the air mixed in with the nitrogen. Argon was also encountered in 1882 through independent research of H. F. Newall and W.N. Hartley. Each observed new lines in the color spectrum of air but were unable to identify the element responsible for the lines. Argon became the first member of the noble gases to be discovered. The symbol for argon is now Ar, but up until 1957 it was A.
Occurrence.
Argon constitutes 0.934% by volume and 1.28% by mass of the Earth's atmosphere, and air is the primary raw material used by industry to produce purified argon products. Argon is isolated from air by fractionation, most commonly by cryogenic fractional distillation, a process that also produces purified nitrogen, oxygen, neon, krypton and xenon.
Isotopes.
The main isotopes of argon found on Earth are (99.6%), (0.34%), and (0.06%). Naturally occurring with a half-life of 1.25 years, decays to stable (11.2%) by electron capture or positron emission, and also to stable (88.8%) via beta decay. These properties and ratios are used to determine the age of rocks by the method of K-Ar dating.
In the Earth's atmosphere, is made by cosmic ray activity, primarily with . In the subsurface environment, it is also produced through neutron capture by or alpha emission by calcium. is created from the neutron spallation of as a result of subsurface nuclear explosions. It has a half-life of 35 days.
The predominance of radiogenic is responsible for the fact that the standard atomic weight of terrestrial argon is greater than that of the next element, potassium. This was puzzling at the time when argon was discovered, since Mendeleev had placed the elements in his periodic table in order of atomic weight, although the inertness of argon implies that it must be placed before the reactive alkali metal potassium. Henry Moseley later solved this problem by showing that the periodic table is actually arranged in order of atomic number. (See History of the periodic table).
The much greater atmospheric abundance of argon relative to the other noble gases is also due to the presence of radiogenic . Primordial has an abundance of only 31.5 ppmv (= 9340 ppmv x 0.337%), comparable to that of neon (18.18 ppmv).
The Martian atmosphere contains 1.6% of and 5 ppm of . The Mariner space probe fly-by of the planet Mercury in 1973 found that Mercury has a very thin atmosphere with 70% argon, believed to result from releases of the gas as a decay product from radioactive materials on the planet. In 2005, the "Huygens" probe also discovered the presence of on Titan, the largest moon of Saturn.
Compounds.
Argon's complete octet of electrons indicates full s and p subshells. This full outer energy level makes argon very stable and extremely resistant to bonding with other elements. Before 1962, argon and the other noble gases were considered to be chemically inert and unable to form compounds; however, compounds of the heavier noble gases have since been synthesized. In August 2000, the first argon compound was formed by researchers at the University of Helsinki. By shining ultraviolet light onto frozen argon containing a small amount of hydrogen fluoride with caesium iodide, argon fluorohydride (HArF) was formed. It is stable up to 40 kelvin (−233 °C). The metastable dication, which is valence isoelectronic with carbonyl fluoride, was observed in 2010.
Production.
Industrial.
Argon is produced industrially by the fractional distillation of liquid air in a cryogenic air separation unit; a process that separates liquid nitrogen, which boils at 77.3 K, from argon, which boils at 87.3 K, and liquid oxygen, which boils at 90.2 K. About 700,000 tonnes of argon are produced worldwide every year.
In radioactive decays.
40Ar, the most abundant isotope of argon, is produced by the decay of 40K with a half-life of 1.25 years by electron capture or positron emission. Because of this, it is used in potassium-argon dating to determine the age of rocks.
Applications.
Other noble gases would probably work as well in most of these applications, but argon is by far the cheapest. Argon is inexpensive since it is a byproduct of the production of liquid oxygen and liquid nitrogen from a cryogenic air separation unit, both of which are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful by far, since it has a much higher concentration in the atmosphere. The bulk of argon applications arise simply because it is inert and relatively cheap.
Industrial processes.
Argon is used in some high-temperature industrial processes, where ordinarily non-reactive substances become reactive. For example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning.
For some of these processes, the presence of nitrogen or oxygen gases might cause defects within the material. Argon is used in various types of arc welding such as gas metal arc welding and gas tungsten arc welding, as well as in the processing of titanium and other reactive elements. An argon atmosphere is also used for growing crystals of silicon and germanium.
Argon is an asphyxiant in the poultry industry, either for mass culling following disease outbreaks, or as a means of slaughter more humane than the electric bath. Argon's relatively high density causes it to remain close to the ground during gassing. Its non-reactive nature makes it suitable in a food product, and since it replaces oxygen within the dead bird, argon also enhances shelf life.
Argon is sometimes used for extinguishing fires where damage to equipment is to be avoided.
Scientific research.
Argon is used, primarily in liquid form, as the target for direct dark matter searches. The interaction of a hypothetical WIMP particle with the argon nucleus produces scintillation light that is then detected by photomultiplier tubes. Two-phase detectors also use argon gas to detect the ionized electrons produced during the WIMP-nucleus scattering. As with most other liquefied noble gases, argon has a high scintillation lightyield (~ 51 photons / keV), is transparent to its own scintillation light, and is relatively easy to purify. Compared to xenon, argon is cheaper and has a distinct scintillation time profile which allows the separation of electronic recoils from nuclear recoils. On the other hand, its intrinsic gamma-ray background is larger due to contamination, unless one uses underground argon sources with a low level of radioactivity. Dark matter detectors currently operating with liquid argon include WArP, ArDM, microCLEAN and DEAP-I.
Preservative.
Argon is used to displace oxygen- and moisture-containing air in packaging material to extend the shelf-lives of the contents (argon has the European food additive code of "E938"). Aerial oxidation, hydrolysis, and other chemical reactions which degrade the products are retarded or prevented entirely. Bottles of high-purity chemicals and certain pharmaceutical products are available in sealed bottles or ampoules packed in argon. In wine making, argon is used to top-off barrels to avoid the aerial oxidation of ethanol to acetic acid during the aging process.
Argon is also available in aerosol-type cans, which may be used to preserve compounds such as varnish, polyurethane, paint, etc. for storage after opening.
Since 2002, the American National Archives stores important national documents such as the Declaration of Independence and the Constitution within argon-filled cases to retard their degradation. Using argon reduces gas leakage, compared with the helium used in the preceding five decades.
Laboratory equipment.
Argon may be used as the inert gas within Schlenk lines and gloveboxes. The use of argon over comparatively less expensive nitrogen is preferred where nitrogen may react with the experimental reagents or apparatus.
Argon may be used as the carrier gas in gas chromatography and in electrospray ionization mass spectrometry; it is the gas of choice for the plasma used in ICP spectroscopy. Argon is preferred for the sputter coating of specimens for scanning electron microscopy. Argon ions are also used for sputtering in microelectronics.
Medical use.
Cryosurgery procedures such as cryoablation use liquefied argon to destroy cancer cells. In surgery it is used in a procedure called "argon enhanced coagulation" which is a form of argon plasma beam electrosurgery. The procedure carries a risk of producing gas embolism in the patient and has resulted in the death of one person via this type of accident. Blue argon lasers are used in surgery to weld arteries, destroy tumors, and to correct eye defects. It has also been used experimentally to replace nitrogen in the breathing or decompression mix, to speed the elimination of dissolved nitrogen from the blood. See Argox.
Lighting.
Incandescent lights are filled with argon, to preserve the filaments at high temperature from oxidation. It is used for the specific way it ionizes and emits light, such as in plasma globes and calorimetry in experimental particle physics. Gas-discharge lamps filled with argon provide blue light. Argon is also used for the creation of blue and green laser light.
Miscellaneous uses.
It is used for thermal insulation in energy efficient windows. Argon is also used in technical scuba diving to inflate a dry suit, because it is inert and has low thermal conductivity.
Compressed argon is allowed to expand, to cool the seeker heads of the AIM-9 Sidewinder missile, and other missiles that use cooled thermal seeker heads. The gas is stored at high pressure.
Argon-39, with a half-life of 269 years, has been used for a number of applications, primarily ice core and ground water dating. Also, potassium-argon dating is used in dating igneous rocks.
Safety.
Although argon is non-toxic, it is 38% denser than air and is therefore considered a dangerous asphyxiant in closed areas. It is also difficult to detect because it is colorless, odorless, and tasteless. A 1994 incident in which a man was asphyxiated after entering an argon filled section of oil pipe under construction in Alaska highlights the dangers of argon tank leakage in confined spaces, and emphasizes the need for proper use, storage and handling.

</doc>
<doc id="897" url="http://it.wikipedia.org/wiki/?curid=897" title="Arsenic">
Arsenic

Arsenic is a chemical element with symbol As and atomic number 33. Arsenic occurs in many minerals, usually in conjunction with sulfur and metals, and also as a pure elemental crystal. It was first documented by Albertus Magnus in 1250. Arsenic is a metalloid. It can exist in various allotropes, although only the gray form has important use in industry.
The main use of metallic arsenic is for strengthening alloys of copper and especially lead (for example, in car batteries). Arsenic is a common n-type dopant in semiconductor electronic devices, and the optoelectronic compound gallium arsenide is the most common semiconductor in use after doped silicon. Arsenic and its compounds, especially the trioxide, are used in the production of pesticides, treated wood products, herbicides, and insecticides. These applications are declining, however.
Arsenic is notoriously poisonous to multicellular life, although a few species of bacteria are able to use arsenic compounds as respiratory metabolites. Arsenic contamination of groundwater is a problem that affects millions of people across the world.
Characteristics.
Physical characteristics.
The three most common arsenic allotropes are "metallic gray", "yellow" and "black arsenic", with gray being the most common. "Gray arsenic" (α-As, space group Rm No. 166) adopts a double-layered structure consisting of many interlocked ruffled six-membered rings. Because of weak bonding between the layers, gray arsenic is brittle and has a relatively low Mohs hardness of 3.5. Nearest and next-nearest neighbors form a distorted octahedral complex, with the three atoms in the same double-layer being slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 5.73 g/cm3. "Yellow arsenic" is soft and waxy, and somewhat similar to tetraphosphorus (). Both have four atoms arranged in a tetrahedral structure in which each atom is bound to each of the other three atoms by a single bond. This unstable allotrope, being molecular, is the most volatile, least dense and most toxic. Solid yellow arsenic is produced by rapid cooling of arsenic vapor, . It is rapidly transformed into the gray arsenic by light. The yellow form has a density of 1.97 g/cm3. As of 2003, at least 33 radioisotopes have also been synthesized, ranging in atomic mass from 60 to 92. The most stable of these is 73As with a half-life of 80.3 days. Isotopes that are lighter than the stable 75As tend to decay by β+ decay, and those that are heavier tend to decay by β- decay, with some exceptions.
At least 10 nuclear isomers have been described, ranging in atomic mass from 66 to 84. The most stable of arsenic's isomers is 68mAs with a half-life of 111 seconds.
Compounds.
Arsenic compounds resemble in some respects those of phosphorus, which occupies the same group (column) of the periodic table. Arsenic is less commonly observed in the pentavalent state, however. The most common oxidation states for arsenic are: −3 in the arsenides, such as alloy-like intermetallic compounds; and +3 in the arsenites, arsenates(III), and most organoarsenic compounds. Arsenic also bonds readily to itself as seen in the square As ions in the mineral skutterudite. In the +3 oxidation state, arsenic is typically pyramidal, owing to the influence of the lone pair of electrons.
Inorganic.
Arsenic forms colorless, odorless, crystalline oxides As2O3 ("white arsenic") and As2O5, which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic(V) acid is a weak acid. Its salts are called arsenates, which is the basis of arsenic contamination of groundwater, a problem that affects many people. Synthetic arsenates include Paris Green (copper(II) acetoarsenite), calcium arsenate, and lead hydrogen arsenate. The latter three have been used as agricultural insecticides and poisons.
The protonation steps between the arsenate and arsenic acid are similar to those between phosphate and phosphoric acid. Unlike phosphorus acid, arsenous acid is genuinely tribasic, with the formula As(OH)3.
A broad variety of sulfur compounds of arsenic are known. Orpiment (As2S3) and realgar (As4S4) are somewhat abundant and were formerly used as painting pigments. In As4S10, arsenic has a formal oxidation state of +2 in As4S4, which features As-As bonds so that the total covalency of As is still three.
The trifluoride, trichloride, tribromide, and triiodide of arsenic(III) are well known, whereas only Arsenic pentafluoride (AsF5) is the only important pentahalide. Again reflecting the lower stability of the 5+ oxidation state, the pentachloride is stable only below −50 °C. Cacodylic acid, which is of historic and practical interest, arises from the methylation of arsenic trioxide, a reaction that has no analogy in phosphorus chemistry.
Alloys.
Arsenic is used as the group 5 element in the III-V semiconductors gallium arsenide, indium arsenide, and aluminium arsenide. The valence electron count of GaAs is the same as a pair of Si atoms, but the band structure is completely different, which results distinct bulk properties. Other arsenic alloys include the II-IV semiconductor cadmium arsenide.
Occurrence and production.
Minerals with the formula MAsS and MAs2 (M = Fe, Ni, Co) are the dominant commercial sources of arsenic, together with realgar (an arsenic sulfide mineral) and native arsenic. An illustrative mineral is arsenopyrite (FeAsS), which is structurally related to iron pyrite. Many minor As-containing minerals are known. Arsenic also occurs in various organic forms in the environment. Inorganic arsenic and its compounds, upon entering the food chain, are progressively metabolized to a less toxic form of arsenic through a process of methylation.
Other naturally occurring pathways of exposure include volcanic ash, weathering of arsenic-containing minerals and ores, and dissolved in groundwater. It is also found in food, water, soil, and air. Arsenic is absorbed by all plants, but is more concentrated in leafy vegetables, rice, apple and grape juice, and seafood. An additional route of exposure is through inhalation.
In 2005, China was the top producer of white arsenic with almost 50% world share, followed by Chile, Peru, and Morocco, according to the British Geological Survey and the United States Geological Survey.
History.
The word "arsenic" was borrowed from the Syriac word ܠܐ ܙܐܦܢܝܐ "(al) zarniqa" and the Persian word "Zarnikh", meaning "yellow orpiment", into Greek as "arsenikon" (Αρσενικόν). It is also related to the similar Greek word "arsenikos" (Αρσενικός), meaning "masculine" or "potent". The word was adopted in Latin "arsenicum" and Old French "arsenic," from which the English word "arsenic" is derived. Zosimos (circa 300 AD) describes roasting "sandarach" (realgar) to obtain "cloud of arsenic" (arsenious oxide), which he then reduces to metallic arsenic. As the symptoms of arsenic poisoning were somewhat ill-defined, it was frequently used for murder until the advent of the Marsh test, a sensitive chemical test for its presence. (Another less sensitive but more general test is the Reinsch test.) Owing to its use by the ruling class to murder one another and its potency and discreetness, arsenic has been called the "Poison of Kings" and the "King of Poisons".
During the Bronze Age, arsenic was often included in bronze, which made the alloy harder (so-called "arsenical bronze").
Albertus Magnus (Albert the Great, 1193–1280) is believed to have been the first to isolate the element from a compound in 1250, by heating soap together with arsenic trisulfide. Crystals of elemental (native) arsenic are found in nature, although rare.
Cadet's fuming liquid (impure cacodyl), often claimed as the first synthetic organometallic compound, was synthesized in 1760 by Louis Claude Cadet de Gassicourt by the reaction of potassium acetate with arsenic trioxide.
In the Victorian era, "arsenic" ("white arsenic" or arsenic trioxide) was mixed with vinegar and chalk and eaten by women to improve the complexion of their faces, making their skin paler to show they did not work in the fields. Arsenic was also rubbed into the faces and arms of women to "improve their complexion". The accidental use of arsenic in the adulteration of foodstuffs led to the Bradford sweet poisoning in 1858, which resulted in approximately 20 deaths.
Applications.
Agricultural.
The toxicity of arsenic to insects, bacteria and fungi led to its use as a wood preservative. In the 1950s a process of treating wood with chromated copper arsenate (also known as CCA or Tanalith) was invented, and for decades this treatment was the most extensive industrial use of arsenic. An increased appreciation of the toxicity of arsenic resulted in a ban for the use of CCA in consumer products; the European Union and United States initiated this process in 2004. CCA remains in heavy use in other countries however, e.g. Malaysian rubber plantations. but contact with the compound sometimes resulted in brain damage among those working the sprayers. In the second half of the 20th century, monosodium methyl arsenate (MSMA) and disodium methyl arsenate (DSMA) – less toxic organic forms of arsenic – have replaced lead arsenate in agriculture.
Arsenic is still added to animal food, in particular in the US as a method of disease prevention and growth stimulation. One example is roxarsone, which is used as a broiler starter by about 70% of the broiler growers since 1995. The Poison-Free Poultry Act of 2009 proposes to ban the use of roxarsone in industrial swine and poultry production. Alpharma, a subsidiary of Pfizer Inc., which produces Roxarsone, has voluntarily suspended sales of the drug in response to studies showing elevated levels of arsenic in treated chickens.
Medical use.
During the 18th, 19th, and 20th centuries, a number of arsenic compounds have been used as medicines, including arsphenamine (by Paul Ehrlich) and arsenic trioxide (by Thomas Fowler). Arsphenamine as well as neosalvarsan was indicated for syphilis and trypanosomiasis, but has been superseded by modern antibiotics. Arsenic trioxide has been used in a variety of ways over the past 500 years, but most commonly in the treatment of cancer. The US Food and Drug Administration in 2000 approved this compound for the treatment of patients with acute promyelocytic leukemia that is resistant to ATRA. It was also used as Fowler's solution in psoriasis. Recently new research has been done in locating tumors using arsenic-74 (a positron emitter). The advantages of using this isotope instead of the previously used iodine-124 is that the signal in the PET scan is clearer as the body tends to transport iodine to the thyroid gland producing a lot of noise.
In subtoxic doses, soluble arsenic compounds act as stimulants, and were once popular in small doses as medicine by people in the mid-18th century.
Alloys.
The main use of metallic arsenic is for alloying with lead. Lead components in car batteries are strengthened by the presence of a few percent of arsenic. Dezincification can be strongly reduced by adding arsenic to brass, a copper-zinc alloy. Gallium arsenide is an important semiconductor material, used in integrated circuits. Circuits made from GaAs are much faster (but also much more expensive) than those made in silicon. Unlike silicon it has a direct bandgap, and so can be used in laser diodes and LEDs to directly convert electricity into light. During the Vietnam War the United States used Agent Blue, a mixture of sodium cacodylate and its acid form, as one of the rainbow herbicides to deprive invading North Vietnamese soldiers of foliage cover and rice.
Biological role.
Bacteria.
Some species of bacteria obtain their energy by oxidizing various fuels while reducing arsenate to arsenite. Under oxidative environmental conditions some bacteria use arsenite, which is oxidized to arsenate as fuel for their metabolism. The enzymes involved are known as arsenate reductases (Arr).
In 2008, bacteria were discovered that employ a version of photosynthesis in the absence of oxygen with arsenites as electron donors, producing arsenates (just as ordinary photosynthesis uses water as electron donor, producing molecular oxygen). Researchers conjecture that, over the course of history, these photosynthesizing organisms produced the arsenates that allowed the arsenate-reducing bacteria to thrive. One strain PHS-1 has been isolated and is related to the gammaproteobacterium "Ectothiorhodospira shaposhnikovii". The mechanism is unknown, but an encoded Arr enzyme may function in reverse to its known homologues.
Although the arsenate and phosphate anions are similar structurally, no evidence exists for the replacement of phosphate in ATP or nucleic acids by arsenic.
Heredity.
Arsenic has been linked to epigenetic changes, heritable changes in gene expression that occur without changes in DNA sequence. These include DNA methylation, histone modification, and RNA interference. Toxic levels of arsenic cause significant DNA hypermethylation of tumor suppressor genes p16 and p53, thus increasing risk of carcinogenesis. These epigenetic events have been studied "in vitro" using human kidney cells and "in vivo" using rat liver cells and peripheral blood leukocytes in humans. Inductive coupled plasma mass spectrometry (ICP-MS) is used to detect precise levels of intracellular arsenic and its other bases involved in epigenetic modification of DNA. Studies investigating arsenic as an epigenetic factor will help in developing precise biomarkers of exposure and susceptibility.
The Chinese brake fern ("Pteris vittata") hyperaccumulates arsenic present in the soil into its leaves and has a proposed use in phytoremediation.
Biomethylation.
Inorganic arsenic and its compounds, upon entering the food chain, are progressively metabolized through a process of methylation. For example, the mold "Scopulariopsis brevicaulis" produces significant amounts of trimethylarsine if inorganic arsenic is present. The organic compound arsenobetaine is found in some marine foods such as fish and algae, and also in mushrooms in larger concentrations. The average person's intake is about 10–50 µg/day. Values about 1000 µg are not unusual following consumption of fish or mushrooms, but there is little danger in eating fish because this arsenic compound is nearly non-toxic.
Environmental issues.
Occurrence in drinking water.
Widespread arsenic contamination of groundwater has led to a massive epidemic of arsenic poisoning in Bangladesh and neighboring countries. It is estimated that approximately 57 million people in the Bengal basin are drinking groundwater with arsenic concentrations elevated above the World Health Organization's standard of 10 parts per billion (ppb). However, a study of cancer rates in Taiwan suggested that significant increases in cancer mortality appear only at levels above 150 ppb. The arsenic in the groundwater is of natural origin, and is released from the sediment into the groundwater, owing to the anoxic conditions of the subsurface. This groundwater began to be used after local and western NGOs and the Bangladeshi government undertook a massive shallow tube well drinking-water program in the late twentieth century. This program was designed to prevent drinking of bacteria-contaminated surface waters, but failed to test for arsenic in the groundwater. Many other countries and districts in Southeast Asia, such as Vietnam and Cambodia have geological environments conducive to generation of high-arsenic groundwaters. was reported in Nakhon Si Thammarat, Thailand in 1987, and the Chao Phraya River is suspected of containing high levels of naturally occurring dissolved arsenic, but has not been a public health problem owing to the use of bottled water.
In the United States, arsenic is most commonly found in the ground waters of the southwest. Parts of New England, Michigan, Wisconsin, Minnesota and the Dakotas are also known to have significant concentrations of arsenic in ground water. Increased levels of skin cancer have been associated with arsenic exposure in Wisconsin, even at levels below the 10 part per billion drinking water standard, although this link has not been proven. According to a recent film funded by the US Superfund, millions of private wells have unknown arsenic levels, and in some areas of the US, over 20% of wells may contain levels that exceed established limits.
Low-level exposure to arsenic at concentrations found commonly in US drinking water compromises the initial immune response to H1N1 or swine flu infection according to NIEHS-supported scientists. The study, conducted in laboratory mice, suggests that people exposed to arsenic in their drinking water may be at increased risk for more serious illness or death in response to infection from the virus.
Some Canadians are drinking water that contains inorganic arsenic. Private dug well waters are most at risk for containing inorganic arsenic. Preliminary well water analyses typically does not test for arsenic. Researchers at the Geological Survey of Canada have modelled relative variation in natural arsenic hazard potential for the province of New Brunswick. This study has important implications for potable water and health concerns relating to inorganic arsenic.
Epidemiological evidence from Chile shows a dose-dependent connection between chronic arsenic exposure and various forms of cancer, in particular when other risk factors, such as cigarette smoking, are present. These effects have been demonstrated to persist below 50 ppb.
Analyzing multiple epidemiological studies on inorganic arsenic exposure suggests a small but measurable risk increase for bladder cancer at 10 ppb. According to Peter Ravenscroft of the Department of Geography at the University of Cambridge, roughly 80 million people worldwide consume between 10 and 50 ppb arsenic in their drinking water. If they all consumed exactly 10 ppb arsenic in their drinking water, the previously cited multiple epidemiological study analysis would predict an additional 2,000 cases of bladder cancer alone. This represents a clear underestimate of the overall impact, since it does not include lung or skin cancer, and explicitly underestimates the exposure. Those exposed to levels of arsenic above the current WHO standard should weigh the costs and benefits of arsenic remediation.
Early (1973) evaluations of the removal of dissolved arsenic by drinking water treatment processes demonstrated that arsenic is very effectively removed by co-precipitation with either iron or aluminum oxides. The use of iron as a coagulant, in particular, was found to remove arsenic with efficiencies exceeding 90%. Several adsorptive media systems have been approved for point-of-service use in a study funded by the United States Environmental Protection Agency (US EPA) and the National Science Foundation (NSF). A team of European and Indian scientists and engineers have set up six arsenic treatment plants in West Bengal based on in-situ remediation method (SAR Technology). This technology does not use any chemicals and arsenic is left as an insoluble form (+5 state) in the subterranean zone by recharging aerated water into the aquifer and thus developing an oxidation zone to support arsenic oxidizing micro-organisms. This process does not produce any waste stream or sludge and is relatively cheap.
Another effective and inexpensive method to remove arsenic from contaminated well water is to sink wells 500 feet or deeper to reach purer waters. A recent 2011 study funded by the US National Institute of Environmental Health Sciences' Superfund Research Program shows that deep sediments can remove arsenic and take it out of circulation. Through this process called adsorption in which arsenic sticks to the surfaces of deep sediment particles, arsenic can be naturally removed from well water.
Magnetic separations of arsenic at very low magnetic field gradients have been demonstrated in point-of-use water purification with high-surface-area and monodisperse magnetite (Fe3O4) nanocrystals. Using the high specific surface area of Fe3O4 nanocrystals the mass of waste associated with arsenic removal from water has been dramatically reduced.
Epidemiological studies have suggested a correlation between chronic consumption of drinking water contaminated with arsenic and the incidence of all leading causes of mortality. The literature provides reason to believe arsenic exposure is causative in the pathogenesis of diabetes.
Hungarian engineer László Schremmer has recently discovered that by the use of chaff-based filters it is possible to reduce the arsenic content of water to 3 µg/L. This is especially important in areas where the potable water is provided by filtering the water extracted from the underground aquifer.
Wood preservation in the US.
As of 2002, US-based industries consumed 19,600 metric tons of arsenic. Ninety percent of this was used for treatment of wood with chromated copper arsenate (CCA). In 2007, 50% of the 5,280 metric tons of consumption was still used for this purpose. In the United States, the voluntary phasing-out of arsenic in production of consumer products and residential and general consumer construction products began on December 31, 2003, and alternative chemicals are now used, such as Alkaline Copper Quaternary, borates, copper azole, cyproconazole, and propiconazole.
Although discontinued, this application is also one of the most concern to the general public. The vast majority of older pressure-treated wood was treated with CCA. CCA lumber is still in widespread use in many countries, and was heavily used during the latter half of the 20th century as a structural and outdoor building material. Although the use of CCA lumber was banned in many areas after studies showed that arsenic could leach out of the wood into the surrounding soil (from playground equipment, for instance), a risk is also presented by the burning of older CCA timber. The direct or indirect ingestion of wood ash from burnt CCA lumber has caused fatalities in animals and serious poisonings in humans; the lethal human dose is approximately 20 grams of ash. Scrap CCA lumber from construction and demolition sites may be inadvertently used in commercial and domestic fires. Protocols for safe disposal of CCA lumber do not exist evenly throughout the world; there is also concern in some quarters about the widespread landfill disposal of such timber.
Mapping of industrial releases in the US.
One tool that maps releases of arsenic to particular locations in the United States and also provides additional information about such releases is TOXMAP. TOXMAP is a Geographic Information System (GIS) from the Division of Specialized Information Services of the United States National Library of Medicine (NLM) that uses maps of the United States to help users visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs. TOXMAP is a resource funded by the US Federal Government. TOXMAP's chemical and environmental health information is taken from NLM's Toxicology Data Network (TOXNET) and PubMed, and from other authoritative sources.
Toxicity and precautions.
Arsenic and many of its compounds are especially potent poisons. Many water supplies close to mines are contaminated by these poisons. In the United States, the maximum allowed concentration in drinking water is 10 ppb and 5 ppb for bottled water. The People's Republic of China does have a food standard. However the USA's Agency for Toxic Substances and Disease Registry (ATSDR) states that the long-term effects of arsenic exposure cannot be predicted.
Exposure risks and remediation.
Occupational exposure and arsenic poisoning may occur in persons working in industries involving the use of inorganic arsenic and its compounds, such as wood preservation, glass production, nonferrous metal alloys, and electronic semiconductor manufacturing. Inorganic arsenic is also found in coke oven emissions associated with the smelter industry.
The ability of arsenic to undergo redox conversion between As(III) and As(V) makes its availability in the environment more abundant. According to Croal, Gralnick, Malasarn and Newman, "understanding [of what stimulates As(III) oxidation and/or limits As(V) reduction is relevant for bioremediation of contaminated sites (Croal). The study of chemolithoautotrophic As(III) oxidizers and the heterotrophic As(V) reducers can help the understanding of the oxidation and/or reduction of arsenic.
Biological mechanism.
The high affinity of arsenic(III) oxides for thiols is usually assigned as the cause of the high toxicity. Thiols, usually in the form of cysteine residues, but also in cofactors such as lipoic acid and coenzyme A, are situated at the active sites of many important enzymes.

</doc>
</xml>